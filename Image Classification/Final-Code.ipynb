{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt # to visualize only  \n",
    "import os\n",
    "from six.moves import urllib\n",
    "\n",
    "URL_ENDPOINT = \"http://cs.mcgill.ca/~ksinha4/datasets/kaggle/\"\n",
    "PATH = \"dataset\"\n",
    "\n",
    "def fetch_data(name, url, path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    l_path = os.path.join(path, name)\n",
    "    urllib.request.urlretrieve(url, l_path)\n",
    "\n",
    "fetch_data(\"train_x.csv\", URL_ENDPOINT+\"train_x.csv\", PATH)\n",
    "fetch_data(\"train_y.csv\", URL_ENDPOINT+\"train_y.csv\", PATH)\n",
    "fetch_data(\"test_x.csv\", URL_ENDPOINT+\"test_x.csv\", PATH)\n",
    "\n",
    "x = np.loadtxt(\"dataset/train_x.csv\", delimiter=\",\")\n",
    "y = np.loadtxt(\"dataset/train_y.csv\", delimiter=\",\")\n",
    "x_test = np.loadtxt(\"dataset/test_x.csv\", delimiter=\",\")\n",
    "\n",
    "x = x.reshape(-1, 64, 64) # reshape \n",
    "y = y.reshape(-1, 1)\n",
    "x_test = x_test.reshape(-1, 64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.morphology import label, closing, square\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def preproc(x,shape):\n",
    "    standard = shape\n",
    "    resized = np.zeros(shape=(x.shape[0],standard,standard))\n",
    "\n",
    "    for n in range(x.shape[0]):\n",
    "\n",
    "\n",
    "        # apply threshold\n",
    "        #thresh = threshold_mean(x[n])\n",
    "        t = np.array(x[n])\n",
    "        t[t != 255] = 0\n",
    "        t[t == 255] = 1\n",
    "        bw = t # >= thresh\n",
    "\n",
    "        label_image = label(bw)\n",
    "        num = 0\n",
    "        max_region = regionprops(label_image)\n",
    "\n",
    "        for region in regionprops(label_image):\n",
    "\n",
    "\n",
    "            r0,c0,r1,c1 = region.bbox\n",
    "            length = max(abs(r0-r1),abs(c0-c1))\n",
    "\n",
    "            if length > num:\n",
    "                num = length\n",
    "                max_region = region\n",
    "\n",
    "        # crop largest segment\n",
    "        r0, c0, r1, c1 = max_region['BoundingBox']\n",
    "        cropped = bw[min(r0,r1):max(r0,r1), min(c0,c1):max(c0,c1)]\n",
    "        \n",
    "        # resize to standardized size\n",
    "        resized[n] = resize(cropped, (standard,standard))\n",
    "        if n%5000 == 0:\n",
    "            print(\"On #: \", n)\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHYUNG\\Anaconda3\\envs\\ml\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On #:  0\n",
      "On #:  5000\n",
      "On #:  10000\n",
      "On #:  15000\n",
      "On #:  20000\n",
      "On #:  25000\n",
      "On #:  30000\n",
      "On #:  35000\n",
      "On #:  40000\n",
      "On #:  45000\n",
      "Training preprocessing done!\n",
      "On #:  0\n",
      "On #:  5000\n",
      "Testing preprocessing done!\n"
     ]
    }
   ],
   "source": [
    "# run preproc\n",
    "shape=28\n",
    "re_x = preproc(x,shape)\n",
    "print(\"Training preprocessing done!\")\n",
    "re_xtest = preproc(x_test,shape)\n",
    "print(\"Testing preprocessing done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# increase training data through flips\n",
    "def flip(x,y):\n",
    "    flippedx = np.array(x)\n",
    "    flippedy = np.array(y)\n",
    "    size = 50000\n",
    "\n",
    "    for i in range(size):\n",
    "        if i%5000 == 0:\n",
    "                print(i)\n",
    "                \n",
    "        if int(y[i]) == 1 or int(y[i]) == 8 or int(y[i]) == 0:\n",
    "            new = np.array(np.fliplr(x[i]))\n",
    "            flippedx = np.append(flippedx,new)\n",
    "            flippedy = np.append(flippedy,y[i])\n",
    "            \n",
    "    return flippedx, flippedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from skimage.transform import rotate\n",
    "\n",
    "def rotateim(x,y):\n",
    "    rotatex = np.array(x)\n",
    "    rotatey = np.array(y)\n",
    "    size = 50000\n",
    "    \n",
    "    for i in range(size):\n",
    "        if i%100 == 0:\n",
    "                print(i)\n",
    "        \n",
    "        deg = randint(-15,15)\n",
    "\n",
    "        new = np.array(rotate(x[i],deg))\n",
    "        rotatex = np.append(rotatex,new)\n",
    "        rotatey = np.append(rotatey,y[i])\n",
    "            \n",
    "    return rotatex, rotatey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7076e28d2ac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# image augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mre_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotateim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mre_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-690c84b17d3a>\u001b[0m in \u001b[0;36mrotateim\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdeg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mrotatex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotatex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mrotatey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotatey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5145\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5146\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5147\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# image augmentation  \n",
    "# not fully run for this notebook, but was run for Kaggle + other models\n",
    "re_x, y = rotateim(re_x,y)\n",
    "re_x, y = flip(re_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape data\n",
    "re_x = re_x.reshape(-1,shape**2)\n",
    "y = y.squeeze()\n",
    "re_xtest = re_xtest.reshape(-1,shape**2)\n",
    "\n",
    "# 80-20 split\n",
    "x_train=re_x\n",
    "y_train=y\n",
    "x_test=re_xtest\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save predictions\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def sav(y,name):\n",
    "    f = open(\"predictions/\"+name,\"w\",encoding='utf-8')\n",
    "    f.write(\"Id,Label\\n\")\n",
    "    for i in range(10000):\n",
    "        f.write(str(i)+\",\"+str(int(y[i]))+\"\\n\")\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On C:  0.001\n",
      "Training score:  0.73105\n",
      "Validation score:  0.7154\n",
      "On C:  0.01\n",
      "Training score:  0.765775\n",
      "Validation score:  0.743\n",
      "On C:  0.1\n",
      "Training score:  0.79465\n",
      "Validation score:  0.7542\n",
      "On C:  0.2\n",
      "Training score:  0.796275\n",
      "Validation score:  0.7516\n",
      "On C:  0.4\n",
      "Training score:  0.797275\n",
      "Validation score:  0.7513\n",
      "On C:  0.6\n",
      "Training score:  0.79865\n",
      "Validation score:  0.7518\n",
      "On C:  0.9\n",
      "Training score:  0.7984\n",
      "Validation score:  0.7506\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM w/ sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "c = [0.001, 0.01, 0.1, 0.2, 0.4, 0.6, 0.9]\n",
    "t_results = []\n",
    "v_results = []\n",
    "for i in range(len(c)):\n",
    "    print(\"On C: \", c[i])\n",
    "    clf = LinearSVC(C=c[i],random_state=0, loss='hinge', multi_class='ovr',max_iter=1000)\n",
    "    clf.fit(x_train,y_train)\n",
    "\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    y_pred_valid = clf.predict(x_valid)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    \n",
    "    t_results.append(accuracy_score(y_train,y_pred_train))\n",
    "    v_results.append(accuracy_score(y_valid,y_pred_valid))\n",
    "    \n",
    "    print(\"Training score: \", accuracy_score(y_train,y_pred_train))\n",
    "    print(\"Validation score: \", accuracy_score(y_valid,y_pred_valid))\n",
    "    \n",
    "    sav(y_pred_test,\"linsvm_\"+str(c[i])+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c8e6774a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training vs. validation\n",
    "plt.plot(c, t_results, label='Train')\n",
    "plt.plot(c, v_results, label='Validation')\n",
    "plt.xlabel('C Hyperparameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Linear SVM Hyperparameter Tuning')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('svm_tuning.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# optimized C hyperparameter\n",
    "opt_c = v_results.index(max(v_results))\n",
    "print(\"Optimal C:\", c[opt_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHYUNG\\Anaconda3\\envs\\ml\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On #:  0\n",
      "On #:  5000\n",
      "On #:  10000\n",
      "On #:  15000\n",
      "On #:  20000\n",
      "On #:  25000\n",
      "On #:  30000\n",
      "On #:  35000\n",
      "On #:  40000\n",
      "On #:  45000\n",
      "Train Loss 0: 65.97617184493235\n",
      "Train Loss 1: 65.3261611846257\n",
      "Train Loss 2: 64.69495166447393\n",
      "Train Loss 3: 64.08175327077946\n",
      "Train Loss 4: 63.485635329750515\n",
      "Train Loss 5: 62.9056019142753\n",
      "Train Loss 6: 62.340766384182984\n",
      "Train Loss 7: 61.79064863907992\n",
      "Train Loss 8: 61.25403228237144\n",
      "Train Loss 9: 60.73043625875607\n",
      "Train Loss 10: 60.219737580334694\n",
      "Train Loss 11: 59.721428778242206\n",
      "Train Loss 12: 59.23446149371564\n",
      "Train Loss 13: 58.75900993076232\n",
      "Train Loss 14: 58.29436920494129\n",
      "Train Loss 15: 57.840037531839236\n",
      "Train Loss 16: 57.395682752655986\n",
      "Train Loss 17: 56.960611547447186\n",
      "Train Loss 18: 56.534492013924094\n",
      "Train Loss 19: 56.11699523013917\n",
      "Train Loss 20: 55.70791422096549\n",
      "Train Loss 21: 55.30696420258457\n",
      "Train Loss 22: 54.91347743788435\n",
      "Train Loss 23: 54.52759929452777\n",
      "Train Loss 24: 54.149267413020084\n",
      "Train Loss 25: 53.77800333818808\n",
      "Train Loss 26: 53.413462753586266\n",
      "Train Loss 27: 53.055440064474745\n",
      "Train Loss 28: 52.70399805725984\n",
      "Train Loss 29: 52.358864937510496\n",
      "Train Loss 30: 52.01994575827189\n",
      "Train Loss 31: 51.68706674265795\n",
      "Train Loss 32: 51.35985661794628\n",
      "Train Loss 33: 51.038065230578326\n",
      "Train Loss 34: 50.72167635187064\n",
      "Train Loss 35: 50.410752677002186\n",
      "Train Loss 36: 50.10485786130508\n",
      "Train Loss 37: 49.80408614038123\n",
      "Train Loss 38: 49.50811517885235\n",
      "Train Loss 39: 49.21660606886165\n",
      "Train Loss 40: 48.929698461575214\n",
      "Train Loss 41: 48.64718923111746\n",
      "Train Loss 42: 48.369053570717014\n",
      "Train Loss 43: 48.09504603143125\n",
      "Train Loss 44: 47.82502116704862\n",
      "Train Loss 45: 47.55896636048715\n",
      "Train Loss 46: 47.29685183461104\n",
      "Train Loss 47: 47.03858277045366\n",
      "Train Loss 48: 46.78411448881961\n",
      "Train Loss 49: 46.533241259432835\n",
      "Train Loss 50: 46.2859584490366\n",
      "Train Loss 51: 46.04205654683749\n",
      "Train Loss 52: 45.801397796057344\n",
      "Train Loss 53: 45.56405409276192\n",
      "Train Loss 54: 45.329814957864514\n",
      "Train Loss 55: 45.09888966081257\n",
      "Train Loss 56: 44.87101268318359\n",
      "Train Loss 57: 44.6462597258482\n",
      "Train Loss 58: 44.42435693796236\n",
      "Train Loss 59: 44.20534405346155\n",
      "Train Loss 60: 43.98904315057143\n",
      "Train Loss 61: 43.775422806364496\n",
      "Train Loss 62: 43.564506716517755\n",
      "Train Loss 63: 43.35625104438854\n",
      "Train Loss 64: 43.15056442778024\n",
      "Train Loss 65: 42.94728220577633\n",
      "Train Loss 66: 42.74635171065074\n",
      "Train Loss 67: 42.548058723369934\n",
      "Train Loss 68: 42.35244984524229\n",
      "Train Loss 69: 42.15926305781363\n",
      "Train Loss 70: 41.96840760668777\n",
      "Train Loss 71: 41.779776784004234\n",
      "Train Loss 72: 41.593364443407594\n",
      "Train Loss 73: 41.40925638531344\n",
      "Train Loss 74: 41.22726177648228\n",
      "Train Loss 75: 41.047195732129225\n",
      "Train Loss 76: 40.86925617669134\n",
      "Train Loss 77: 40.69317245953217\n",
      "Train Loss 78: 40.51893911333749\n",
      "Train Loss 79: 40.34653610182284\n",
      "Train Loss 80: 40.1759489655596\n",
      "Train Loss 81: 40.0071999439557\n",
      "Train Loss 82: 39.840227537106706\n",
      "Train Loss 83: 39.67510010917155\n",
      "Train Loss 84: 39.511750262258474\n",
      "Train Loss 85: 39.35009058933677\n",
      "Train Loss 86: 39.19027706978581\n",
      "Train Loss 87: 39.032304494009715\n",
      "Train Loss 88: 38.875871925454035\n",
      "Train Loss 89: 38.720984253363554\n",
      "Train Loss 90: 38.56764992638246\n",
      "Train Loss 91: 38.41596977857553\n",
      "Train Loss 92: 38.26595838621304\n",
      "Train Loss 93: 38.11752769790842\n",
      "Train Loss 94: 37.97055357619428\n",
      "Train Loss 95: 37.82521606573631\n",
      "Train Loss 96: 37.681520557979965\n",
      "Train Loss 97: 37.539312483041584\n",
      "Train Loss 98: 37.398530466820375\n",
      "Train Loss 99: 37.25920926813521\n",
      "Train Loss 100: 37.12134362099323\n",
      "Train Loss 101: 36.98483461315962\n",
      "Train Loss 102: 36.8496769954254\n",
      "Train Loss 103: 36.71581489418095\n",
      "Train Loss 104: 36.58324522750937\n",
      "Train Loss 105: 36.451963158518254\n",
      "Train Loss 106: 36.32201942775065\n",
      "Train Loss 107: 36.19335220832163\n",
      "Train Loss 108: 36.06588515579179\n",
      "Train Loss 109: 35.93964632032939\n",
      "Train Loss 110: 35.8145864081353\n",
      "Train Loss 111: 35.69082847363378\n",
      "Train Loss 112: 35.56828863619914\n",
      "Train Loss 113: 35.44692445088558\n",
      "Train Loss 114: 35.32668393487749\n",
      "Train Loss 115: 35.20765586685218\n",
      "Train Loss 116: 35.08966949784679\n",
      "Train Loss 117: 34.97271747531668\n",
      "Train Loss 118: 34.85693659170812\n",
      "Train Loss 119: 34.74231597009578\n",
      "Train Loss 120: 34.62891828829031\n",
      "Train Loss 121: 34.51673697276068\n",
      "Train Loss 122: 34.405661058535664\n",
      "Train Loss 123: 34.295680757919136\n",
      "Train Loss 124: 34.18679017722204\n",
      "Train Loss 125: 34.079005340443054\n",
      "Train Loss 126: 33.97216581587506\n",
      "Train Loss 127: 33.86632779072646\n",
      "Train Loss 128: 33.76150091532683\n",
      "Train Loss 129: 33.65765053629782\n",
      "Train Loss 130: 33.55471803913471\n",
      "Train Loss 131: 33.45277402267859\n",
      "Train Loss 132: 33.351811853138855\n",
      "Train Loss 133: 33.251786228951026\n",
      "Train Loss 134: 33.152685793912816\n",
      "Train Loss 135: 33.05461492602453\n",
      "Train Loss 136: 32.95753591472939\n",
      "Train Loss 137: 32.86143840407845\n",
      "Train Loss 138: 32.766382357160424\n",
      "Train Loss 139: 32.6723662172669\n",
      "Train Loss 140: 32.57927842180759\n",
      "Train Loss 141: 32.4871103414292\n",
      "Train Loss 142: 32.39580491734852\n",
      "Train Loss 143: 32.30538720738977\n",
      "Train Loss 144: 32.21581864303929\n",
      "Train Loss 145: 32.12711576428656\n",
      "Train Loss 146: 32.039284715217136\n",
      "Train Loss 147: 31.95230013822919\n",
      "Train Loss 148: 31.866144903336007\n",
      "Train Loss 149: 31.78095943595713\n",
      "Train Loss 150: 31.696656722448562\n",
      "Train Loss 151: 31.613127357263437\n",
      "Train Loss 152: 31.530346198383302\n",
      "Train Loss 153: 31.44834219436591\n",
      "Train Loss 154: 31.367168865182897\n",
      "Train Loss 155: 31.28676204469289\n",
      "Train Loss 156: 31.207127018436566\n",
      "Train Loss 157: 31.12832440363667\n",
      "Train Loss 158: 31.050350356333993\n",
      "Train Loss 159: 30.973207621373078\n",
      "Train Loss 160: 30.896856845176934\n",
      "Train Loss 161: 30.8212572058263\n",
      "Train Loss 162: 30.746375439728574\n",
      "Train Loss 163: 30.672264909172938\n",
      "Train Loss 164: 30.59898237634938\n",
      "Train Loss 165: 30.52647464180407\n",
      "Train Loss 166: 30.454708150634232\n",
      "Train Loss 167: 30.38376285868493\n",
      "Train Loss 168: 30.31363672531056\n",
      "Train Loss 169: 30.244162059497654\n",
      "Train Loss 170: 30.175319547730197\n",
      "Train Loss 171: 30.107121469510503\n",
      "Train Loss 172: 30.039613030451747\n",
      "Train Loss 173: 29.97277006511757\n",
      "Train Loss 174: 29.906695443009767\n",
      "Train Loss 175: 29.841322762822507\n",
      "Train Loss 176: 29.776504123780356\n",
      "Train Loss 177: 29.712220889198917\n",
      "Train Loss 178: 29.64854791850313\n",
      "Train Loss 179: 29.585538473118746\n",
      "Train Loss 180: 29.523171728057\n",
      "Train Loss 181: 29.461369646481696\n",
      "Train Loss 182: 29.400175562403486\n",
      "Train Loss 183: 29.339592562053248\n",
      "Train Loss 184: 29.2796023350734\n",
      "Train Loss 185: 29.220184326250727\n",
      "Train Loss 186: 29.161364709886264\n",
      "Train Loss 187: 29.10319210342081\n",
      "Train Loss 188: 29.045661757545687\n",
      "Train Loss 189: 28.988731413673\n",
      "Train Loss 190: 28.932324685630036\n",
      "Train Loss 191: 28.87651355757849\n",
      "Train Loss 192: 28.8212411254619\n",
      "Train Loss 193: 28.766536476935975\n",
      "Train Loss 194: 28.712367045345722\n",
      "Train Loss 195: 28.6587562274605\n",
      "Train Loss 196: 28.605617440761748\n",
      "Train Loss 197: 28.552952978834934\n",
      "Train Loss 198: 28.5008659758486\n",
      "Train Loss 199: 28.44932821152051\n",
      "Train Loss 200: 28.39831530688859\n",
      "Train Loss 201: 28.34783073697934\n",
      "Train Loss 202: 28.297841655198777\n",
      "Train Loss 203: 28.248320343512567\n",
      "Train Loss 204: 28.199365745095026\n",
      "Train Loss 205: 28.15095961452031\n",
      "Train Loss 206: 28.103046668050048\n",
      "Train Loss 207: 28.05560314462152\n",
      "Train Loss 208: 28.008609113349323\n",
      "Train Loss 209: 27.96205487576937\n",
      "Train Loss 210: 27.915929943310545\n",
      "Train Loss 211: 27.870245242749533\n",
      "Train Loss 212: 27.825032486725718\n",
      "Train Loss 213: 27.78028256620832\n",
      "Train Loss 214: 27.735924971983493\n",
      "Train Loss 215: 27.692015687787325\n",
      "Train Loss 216: 27.64854281462506\n",
      "Train Loss 217: 27.605474532244592\n",
      "Train Loss 218: 27.562835273749698\n",
      "Train Loss 219: 27.52060494749207\n",
      "Train Loss 220: 27.478792692539713\n",
      "Train Loss 221: 27.43734797825222\n",
      "Train Loss 222: 27.396443951770166\n",
      "Train Loss 223: 27.356017704841413\n",
      "Train Loss 224: 27.316017411378482\n",
      "Train Loss 225: 27.276431587856283\n",
      "Train Loss 226: 27.237245911552495\n",
      "Train Loss 227: 27.198463292384286\n",
      "Train Loss 228: 27.160026208775903\n",
      "Train Loss 229: 27.121980505183245\n",
      "Train Loss 230: 27.084333936416726\n",
      "Train Loss 231: 27.047059630639122\n",
      "Train Loss 232: 27.01019786646191\n",
      "Train Loss 233: 26.973680633824394\n",
      "Train Loss 234: 26.937565521141668\n",
      "Train Loss 235: 26.901747217239407\n",
      "Train Loss 236: 26.866212241793512\n",
      "Train Loss 237: 26.830968883550383\n",
      "Train Loss 238: 26.796111744766463\n",
      "Train Loss 239: 26.761566538409653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 240: 26.72737405265734\n",
      "Train Loss 241: 26.693499355229783\n",
      "Train Loss 242: 26.659955464791814\n",
      "Train Loss 243: 26.626727152022724\n",
      "Train Loss 244: 26.593801899895016\n",
      "Train Loss 245: 26.56115587235815\n",
      "Train Loss 246: 26.528849270002112\n",
      "Train Loss 247: 26.49691526942189\n",
      "Train Loss 248: 26.465263113654075\n",
      "Train Loss 249: 26.433889240782953\n",
      "Train Loss 250: 26.402785516981506\n",
      "Train Loss 251: 26.371965890803473\n",
      "Train Loss 252: 26.341431427695603\n",
      "Train Loss 253: 26.31121302380256\n",
      "Train Loss 254: 26.281274142458876\n",
      "Train Loss 255: 26.251586451102714\n",
      "Train Loss 256: 26.22219400876947\n",
      "Train Loss 257: 26.19305069663968\n",
      "Train Loss 258: 26.16415066006189\n",
      "Train Loss 259: 26.13547766226\n",
      "Train Loss 260: 26.107068067332886\n",
      "Train Loss 261: 26.078910128589662\n",
      "Train Loss 262: 26.050967117960894\n",
      "Train Loss 263: 26.02325292113555\n",
      "Train Loss 264: 25.995808224393382\n",
      "Train Loss 265: 25.96863531081207\n",
      "Train Loss 266: 25.941714318996137\n",
      "Train Loss 267: 25.915006368561258\n",
      "Train Loss 268: 25.88854546555855\n",
      "Train Loss 269: 25.86231303987632\n",
      "Train Loss 270: 25.836284638177748\n",
      "Train Loss 271: 25.810476259361643\n",
      "Train Loss 272: 25.784855387840437\n",
      "Train Loss 273: 25.759458096758628\n",
      "Train Loss 274: 25.73429200426778\n",
      "Train Loss 275: 25.70931454284603\n",
      "Train Loss 276: 25.684573022827934\n",
      "Train Loss 277: 25.660074979504678\n",
      "Train Loss 278: 25.635819920548663\n",
      "Train Loss 279: 25.611738432025582\n",
      "Train Loss 280: 25.587912910900535\n",
      "Train Loss 281: 25.56429863805874\n",
      "Train Loss 282: 25.54089553186648\n",
      "Train Loss 283: 25.51772208390278\n",
      "Train Loss 284: 25.494804889089206\n",
      "Train Loss 285: 25.472109886018906\n",
      "Train Loss 286: 25.4496238129666\n",
      "Train Loss 287: 25.427394541181112\n",
      "Train Loss 288: 25.405339120629666\n",
      "Train Loss 289: 25.383441365218815\n",
      "Train Loss 290: 25.36172000755133\n",
      "Train Loss 291: 25.340184413768533\n",
      "Train Loss 292: 25.318801022650668\n",
      "Train Loss 293: 25.297596352086764\n",
      "Train Loss 294: 25.276573241849782\n",
      "Train Loss 295: 25.255705152206932\n",
      "Train Loss 296: 25.235001515391385\n",
      "Train Loss 297: 25.21447803303151\n",
      "Train Loss 298: 25.194138602609886\n",
      "Train Loss 299: 25.173963597419807\n",
      "Train Loss 300: 25.15395874847388\n",
      "Train Loss 301: 25.13414354556469\n",
      "Train Loss 302: 25.11448811346431\n",
      "Train Loss 303: 25.09499701002277\n",
      "Train Loss 304: 25.075690151206274\n",
      "Train Loss 305: 25.056546995853118\n",
      "Train Loss 306: 25.037579088066245\n",
      "Train Loss 307: 25.018769884727487\n",
      "Train Loss 308: 25.00012890321681\n",
      "Train Loss 309: 24.981615416549428\n",
      "Train Loss 310: 24.963234267493643\n",
      "Train Loss 311: 24.9449828731496\n",
      "Train Loss 312: 24.92687420825559\n",
      "Train Loss 313: 24.908930881644864\n",
      "Train Loss 314: 24.89114009549785\n",
      "Train Loss 315: 24.873502178698796\n",
      "Train Loss 316: 24.856002695516718\n",
      "Train Loss 317: 24.838653608830747\n",
      "Train Loss 318: 24.82143354722433\n",
      "Train Loss 319: 24.804352559932596\n",
      "Train Loss 320: 24.787393886711868\n",
      "Train Loss 321: 24.77054668886054\n",
      "Train Loss 322: 24.753835585469382\n",
      "Train Loss 323: 24.737269855571256\n",
      "Train Loss 324: 24.720878329610485\n",
      "Train Loss 325: 24.704643275640294\n",
      "Train Loss 326: 24.688562283320863\n",
      "Train Loss 327: 24.672590503251914\n",
      "Train Loss 328: 24.656732485620072\n",
      "Train Loss 329: 24.64102041754314\n",
      "Train Loss 330: 24.62543518899693\n",
      "Train Loss 331: 24.60996581349351\n",
      "Train Loss 332: 24.594616220109003\n",
      "Train Loss 333: 24.579378085433465\n",
      "Train Loss 334: 24.564270386875187\n",
      "Train Loss 335: 24.549276722120165\n",
      "Train Loss 336: 24.534419741431016\n",
      "Train Loss 337: 24.519650875481425\n",
      "Train Loss 338: 24.50500742824124\n",
      "Train Loss 339: 24.49048786475271\n",
      "Train Loss 340: 24.476098091183243\n",
      "Train Loss 341: 24.46182886122171\n",
      "Train Loss 342: 24.447688251875725\n",
      "Train Loss 343: 24.433657188901186\n",
      "Train Loss 344: 24.41974579714367\n",
      "Train Loss 345: 24.405968453895746\n",
      "Train Loss 346: 24.3922924308528\n",
      "Train Loss 347: 24.3787109431786\n",
      "Train Loss 348: 24.365209614545293\n",
      "Train Loss 349: 24.35182614876362\n",
      "Train Loss 350: 24.338562138927543\n",
      "Train Loss 351: 24.32539839970407\n",
      "Train Loss 352: 24.312337379519985\n",
      "Train Loss 353: 24.299378882612533\n",
      "Train Loss 354: 24.28652374041637\n",
      "Train Loss 355: 24.273778739893526\n",
      "Train Loss 356: 24.261146199733613\n",
      "Train Loss 357: 24.248609869609183\n",
      "Train Loss 358: 24.23614208333693\n",
      "Train Loss 359: 24.223755980639275\n",
      "Train Loss 360: 24.21147146873437\n",
      "Train Loss 361: 24.199271948187327\n",
      "Train Loss 362: 24.187184752187022\n",
      "Train Loss 363: 24.175203441730527\n",
      "Train Loss 364: 24.16331306775079\n",
      "Train Loss 365: 24.15150843462848\n",
      "Train Loss 366: 24.13980702399939\n",
      "Train Loss 367: 24.128189583010062\n",
      "Train Loss 368: 24.116654730435\n",
      "Train Loss 369: 24.10520478496952\n",
      "Train Loss 370: 24.09384861236825\n",
      "Train Loss 371: 24.0825644310196\n",
      "Train Loss 372: 24.07136238352085\n",
      "Train Loss 373: 24.060249681813332\n",
      "Train Loss 374: 24.049222936527393\n",
      "Train Loss 375: 24.03827529279183\n",
      "Train Loss 376: 24.027408410405958\n",
      "Train Loss 377: 24.016608010362177\n",
      "Train Loss 378: 24.005899842201007\n",
      "Train Loss 379: 23.995283614834726\n",
      "Train Loss 380: 23.984752634712375\n",
      "Train Loss 381: 23.9742930706374\n",
      "Train Loss 382: 23.963910735033608\n",
      "Train Loss 383: 23.95361889335339\n",
      "Train Loss 384: 23.943405273356145\n",
      "Train Loss 385: 23.93326170519561\n",
      "Train Loss 386: 23.92318977172405\n",
      "Train Loss 387: 23.913200243037853\n",
      "Train Loss 388: 23.903267710958914\n",
      "Train Loss 389: 23.89341394599406\n",
      "Train Loss 390: 23.88364710294584\n",
      "Train Loss 391: 23.873946036438053\n",
      "Train Loss 392: 23.864307162516592\n",
      "Train Loss 393: 23.8547277119214\n",
      "Train Loss 394: 23.84523232399741\n",
      "Train Loss 395: 23.835827961019007\n",
      "Train Loss 396: 23.82649705690356\n",
      "Train Loss 397: 23.817216576341735\n",
      "Train Loss 398: 23.80799877578999\n",
      "Train Loss 399: 23.798856502445716\n",
      "Train Loss 400: 23.78978011708793\n",
      "Train Loss 401: 23.78077186065566\n",
      "Train Loss 402: 23.77182313274037\n",
      "Train Loss 403: 23.762929043205954\n",
      "Train Loss 404: 23.75409321474106\n",
      "Train Loss 405: 23.74531543484482\n",
      "Train Loss 406: 23.736595232661763\n",
      "Train Loss 407: 23.72793056687087\n",
      "Train Loss 408: 23.71932937032073\n",
      "Train Loss 409: 23.710795812443433\n",
      "Train Loss 410: 23.70233094680441\n",
      "Train Loss 411: 23.693939983832294\n",
      "Train Loss 412: 23.68560968436894\n",
      "Train Loss 413: 23.67733597488314\n",
      "Train Loss 414: 23.66911464148115\n",
      "Train Loss 415: 23.66094939990207\n",
      "Train Loss 416: 23.652843514586053\n",
      "Train Loss 417: 23.644793013350352\n",
      "Train Loss 418: 23.63679652591628\n",
      "Train Loss 419: 23.628855597081234\n",
      "Train Loss 420: 23.62096475784513\n",
      "Train Loss 421: 23.613127807080165\n",
      "Train Loss 422: 23.605346110853084\n",
      "Train Loss 423: 23.597621543422665\n",
      "Train Loss 424: 23.589953422239876\n",
      "Train Loss 425: 23.582341834204342\n",
      "Train Loss 426: 23.574773918911294\n",
      "Train Loss 427: 23.567244480001346\n",
      "Train Loss 428: 23.55976859955485\n",
      "Train Loss 429: 23.5523283435425\n",
      "Train Loss 430: 23.54493607719027\n",
      "Train Loss 431: 23.537597191537177\n",
      "Train Loss 432: 23.530319443068883\n",
      "Train Loss 433: 23.523088960390744\n",
      "Train Loss 434: 23.51590276848226\n",
      "Train Loss 435: 23.50875796014722\n",
      "Train Loss 436: 23.501663903749897\n",
      "Train Loss 437: 23.494621682595106\n",
      "Train Loss 438: 23.487632725236057\n",
      "Train Loss 439: 23.48068422126104\n",
      "Train Loss 440: 23.473779600108983\n",
      "Train Loss 441: 23.466931648852405\n",
      "Train Loss 442: 23.460129050769787\n",
      "Train Loss 443: 23.45336533780844\n",
      "Train Loss 444: 23.44664748882876\n",
      "Train Loss 445: 23.439977164841892\n",
      "Train Loss 446: 23.4333549915548\n",
      "Train Loss 447: 23.426788034407654\n",
      "Train Loss 448: 23.420260752166776\n",
      "Train Loss 449: 23.413776298983276\n",
      "Train Loss 450: 23.407335059282495\n",
      "Train Loss 451: 23.400933363733454\n",
      "Train Loss 452: 23.394564521004614\n",
      "Train Loss 453: 23.388228350504278\n",
      "Train Loss 454: 23.381930319984985\n",
      "Train Loss 455: 23.375667669947237\n",
      "Train Loss 456: 23.369442666750885\n",
      "Train Loss 457: 23.363253538755508\n",
      "Train Loss 458: 23.357113652227216\n",
      "Train Loss 459: 23.35101791077855\n",
      "Train Loss 460: 23.344964776936806\n",
      "Train Loss 461: 23.338945156290283\n",
      "Train Loss 462: 23.332964377684924\n",
      "Train Loss 463: 23.32701954248901\n",
      "Train Loss 464: 23.32111018030526\n",
      "Train Loss 465: 23.315235467973892\n",
      "Train Loss 466: 23.30939968955604\n",
      "Train Loss 467: 23.30359984763888\n",
      "Train Loss 468: 23.29784217291364\n",
      "Train Loss 469: 23.292122523788453\n",
      "Train Loss 470: 23.286437907152614\n",
      "Train Loss 471: 23.280789229827082\n",
      "Train Loss 472: 23.27517327156073\n",
      "Train Loss 473: 23.26959588619942\n",
      "Train Loss 474: 23.264052240741112\n",
      "Train Loss 475: 23.258545399330806\n",
      "Train Loss 476: 23.25307097800111\n",
      "Train Loss 477: 23.247627923197925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 478: 23.242222106708596\n",
      "Train Loss 479: 23.236837914447324\n",
      "Train Loss 480: 23.231493558517517\n",
      "Train Loss 481: 23.22618771120038\n",
      "Train Loss 482: 23.220913173756454\n",
      "Train Loss 483: 23.215671508154184\n",
      "Train Loss 484: 23.210467499631356\n",
      "Train Loss 485: 23.205295657829193\n",
      "Train Loss 486: 23.200160661641867\n",
      "Train Loss 487: 23.195056236680465\n",
      "Train Loss 488: 23.189969923594653\n",
      "Train Loss 489: 23.184911116187553\n",
      "Train Loss 490: 23.17988513646084\n",
      "Train Loss 491: 23.17488489935758\n",
      "Train Loss 492: 23.169917190930903\n",
      "Train Loss 493: 23.164978555255512\n",
      "Train Loss 494: 23.16007066754091\n",
      "Train Loss 495: 23.155192927620707\n",
      "Train Loss 496: 23.15034262873428\n",
      "Train Loss 497: 23.14551664222863\n",
      "Train Loss 498: 23.140721984425127\n",
      "Train Loss 499: 23.135958936039064\n",
      "Train Loss 500: 23.131225515854407\n",
      "Train Loss 501: 23.126521811129614\n",
      "Train Loss 502: 23.121839900876665\n",
      "Train Loss 503: 23.11718194824738\n",
      "Train Loss 504: 23.112553834673577\n",
      "Train Loss 505: 23.107949691921714\n",
      "Train Loss 506: 23.103371511885427\n",
      "Train Loss 507: 23.09882100086293\n",
      "Train Loss 508: 23.094296835939485\n",
      "Train Loss 509: 23.089799427031384\n",
      "Train Loss 510: 23.085320521794365\n",
      "Train Loss 511: 23.080860807221846\n",
      "Train Loss 512: 23.076427074667425\n",
      "Train Loss 513: 23.07201763886592\n",
      "Train Loss 514: 23.06763099753177\n",
      "Train Loss 515: 23.063265541913477\n",
      "Train Loss 516: 23.0589270677703\n",
      "Train Loss 517: 23.054618502296286\n",
      "Train Loss 518: 23.050331200400823\n",
      "Train Loss 519: 23.046065829170246\n",
      "Train Loss 520: 23.0418323234476\n",
      "Train Loss 521: 23.03762757081671\n",
      "Train Loss 522: 23.033439918569066\n",
      "Train Loss 523: 23.02927136396025\n",
      "Train Loss 524: 23.02512738010629\n",
      "Train Loss 525: 23.021006970676886\n",
      "Train Loss 526: 23.016911922156996\n",
      "Train Loss 527: 23.01283569997774\n",
      "Train Loss 528: 23.008777425308857\n",
      "Train Loss 529: 23.004743368648196\n",
      "Train Loss 530: 23.000728609767695\n",
      "Train Loss 531: 22.996730089196664\n",
      "Train Loss 532: 22.992753017782263\n",
      "Train Loss 533: 22.98879687243902\n",
      "Train Loss 534: 22.984856261578045\n",
      "Train Loss 535: 22.98093677960358\n",
      "Train Loss 536: 22.97704000041651\n",
      "Train Loss 537: 22.973164132615246\n",
      "Train Loss 538: 22.969311901711755\n",
      "Train Loss 539: 22.965472388762254\n",
      "Train Loss 540: 22.961649134608848\n",
      "Train Loss 541: 22.957846527706785\n",
      "Train Loss 542: 22.954064963882036\n",
      "Train Loss 543: 22.95030125140973\n",
      "Train Loss 544: 22.946555814693397\n",
      "Train Loss 545: 22.94283171882499\n",
      "Train Loss 546: 22.93912695659548\n",
      "Train Loss 547: 22.935441188928817\n",
      "Train Loss 548: 22.931778982621758\n",
      "Train Loss 549: 22.928140424887992\n",
      "Train Loss 550: 22.924519920087235\n",
      "Train Loss 551: 22.920913056305\n",
      "Train Loss 552: 22.917319791890613\n",
      "Train Loss 553: 22.913748368974677\n",
      "Train Loss 554: 22.910192609831185\n",
      "Train Loss 555: 22.90665081366584\n",
      "Train Loss 556: 22.903119203569936\n",
      "Train Loss 557: 22.899598823923213\n",
      "Train Loss 558: 22.896095757051786\n",
      "Train Loss 559: 22.892609582401814\n",
      "Train Loss 560: 22.889143405196787\n",
      "Train Loss 561: 22.885694318681622\n",
      "Train Loss 562: 22.882257482036973\n",
      "Train Loss 563: 22.87883487245347\n",
      "Train Loss 564: 22.87543391090933\n",
      "Train Loss 565: 22.87205107076881\n",
      "Train Loss 566: 22.868680813454745\n",
      "Train Loss 567: 22.8653285692706\n",
      "Train Loss 568: 22.861990176539667\n",
      "Train Loss 569: 22.85867152727711\n",
      "Train Loss 570: 22.85537552389107\n",
      "Train Loss 571: 22.852092917932964\n",
      "Train Loss 572: 22.84882235659924\n",
      "Train Loss 573: 22.845566557072324\n",
      "Train Loss 574: 22.84232401250544\n",
      "Train Loss 575: 22.839095040603592\n",
      "Train Loss 576: 22.835876491382\n",
      "Train Loss 577: 22.832676492278747\n",
      "Train Loss 578: 22.829491710109316\n",
      "Train Loss 579: 22.826325689460706\n",
      "Train Loss 580: 22.823174423018934\n",
      "Train Loss 581: 22.82004053829007\n",
      "Train Loss 582: 22.816925171720534\n",
      "Train Loss 583: 22.813829287911954\n",
      "Train Loss 584: 22.810744530589943\n",
      "Train Loss 585: 22.80767237961287\n",
      "Train Loss 586: 22.80461527960853\n",
      "Train Loss 587: 22.801572008664007\n",
      "Train Loss 588: 22.798542894234355\n",
      "Train Loss 589: 22.795529122854944\n",
      "Train Loss 590: 22.79252724402363\n",
      "Train Loss 591: 22.789539108258506\n",
      "Train Loss 592: 22.786562438911517\n",
      "Train Loss 593: 22.783594015731694\n",
      "Train Loss 594: 22.780641788067992\n",
      "Train Loss 595: 22.777705090853956\n",
      "Train Loss 596: 22.774780350967568\n",
      "Train Loss 597: 22.771867627452934\n",
      "Train Loss 598: 22.768967423244987\n",
      "Train Loss 599: 22.766079345337022\n",
      "Train Loss 600: 22.763198065726012\n",
      "Train Loss 601: 22.760326225634174\n",
      "Train Loss 602: 22.75746554446163\n",
      "Train Loss 603: 22.754614720638447\n",
      "Train Loss 604: 22.751776421335045\n",
      "Train Loss 605: 22.748947018865906\n",
      "Train Loss 606: 22.746132379117274\n",
      "Train Loss 607: 22.743329118824178\n",
      "Train Loss 608: 22.740538643896613\n",
      "Train Loss 609: 22.73776052439889\n",
      "Train Loss 610: 22.73499517759793\n",
      "Train Loss 611: 22.732245402287084\n",
      "Train Loss 612: 22.729509392615576\n",
      "Train Loss 613: 22.726787751291955\n",
      "Train Loss 614: 22.72407573726837\n",
      "Train Loss 615: 22.721373395178187\n",
      "Train Loss 616: 22.71867990797647\n",
      "Train Loss 617: 22.71600387172299\n",
      "Train Loss 618: 22.713338639242803\n",
      "Train Loss 619: 22.710682931605536\n",
      "Train Loss 620: 22.708039134803723\n",
      "Train Loss 621: 22.705404048111816\n",
      "Train Loss 622: 22.702777730805416\n",
      "Train Loss 623: 22.70016101680838\n",
      "Train Loss 624: 22.697557834908864\n",
      "Train Loss 625: 22.69496722811085\n",
      "Train Loss 626: 22.692384686846633\n",
      "Train Loss 627: 22.6898120975887\n",
      "Train Loss 628: 22.68725291324074\n",
      "Train Loss 629: 22.68470592137882\n",
      "Train Loss 630: 22.68217068528384\n",
      "Train Loss 631: 22.6796458777332\n",
      "Train Loss 632: 22.677131256717193\n",
      "Train Loss 633: 22.67462436754557\n",
      "Train Loss 634: 22.672126767658813\n",
      "Train Loss 635: 22.669640194419152\n",
      "Train Loss 636: 22.667165454935823\n",
      "Train Loss 637: 22.664701713723915\n",
      "Train Loss 638: 22.662249022585588\n",
      "Train Loss 639: 22.65980642521863\n",
      "Train Loss 640: 22.657373251299372\n",
      "Train Loss 641: 22.654951196535166\n",
      "Train Loss 642: 22.652536339473905\n",
      "Train Loss 643: 22.65012967763474\n",
      "Train Loss 644: 22.64773190171792\n",
      "Train Loss 645: 22.6453414103106\n",
      "Train Loss 646: 22.642958894462645\n",
      "Train Loss 647: 22.64058339316673\n",
      "Train Loss 648: 22.63821747603042\n",
      "Train Loss 649: 22.635859585812582\n",
      "Train Loss 650: 22.633509908468042\n",
      "Train Loss 651: 22.631167560653452\n",
      "Train Loss 652: 22.628832320089145\n",
      "Train Loss 653: 22.626508260098603\n",
      "Train Loss 654: 22.624193732392083\n",
      "Train Loss 655: 22.62188629423143\n",
      "Train Loss 656: 22.619590674834892\n",
      "Train Loss 657: 22.617301655710044\n",
      "Train Loss 658: 22.61502040328974\n",
      "Train Loss 659: 22.612747925701598\n",
      "Train Loss 660: 22.610483634017747\n",
      "Train Loss 661: 22.608228502496992\n",
      "Train Loss 662: 22.60597752730238\n",
      "Train Loss 663: 22.603734477078625\n",
      "Train Loss 664: 22.60150094131112\n",
      "Train Loss 665: 22.599280032348435\n",
      "Train Loss 666: 22.597069015473764\n",
      "Train Loss 667: 22.594865698798497\n",
      "Train Loss 668: 22.59267127606033\n",
      "Train Loss 669: 22.590485259716846\n",
      "Train Loss 670: 22.58830902013512\n",
      "Train Loss 671: 22.58613986982459\n",
      "Train Loss 672: 22.583978691271934\n",
      "Train Loss 673: 22.58182407318274\n",
      "Train Loss 674: 22.57967348856576\n",
      "Train Loss 675: 22.577526347031647\n",
      "Train Loss 676: 22.575387257419543\n",
      "Train Loss 677: 22.573252381887137\n",
      "Train Loss 678: 22.571123046727912\n",
      "Train Loss 679: 22.56900371555478\n",
      "Train Loss 680: 22.566890172776976\n",
      "Train Loss 681: 22.564779979521642\n",
      "Train Loss 682: 22.562674502883567\n",
      "Train Loss 683: 22.56057834115861\n",
      "Train Loss 684: 22.558488813102855\n",
      "Train Loss 685: 22.556406237684087\n",
      "Train Loss 686: 22.55433302539263\n",
      "Train Loss 687: 22.552263901894392\n",
      "Train Loss 688: 22.550202697550418\n",
      "Train Loss 689: 22.54815065850792\n",
      "Train Loss 690: 22.546104979742193\n",
      "Train Loss 691: 22.544067394729883\n",
      "Train Loss 692: 22.542037322008905\n",
      "Train Loss 693: 22.54001394877789\n",
      "Train Loss 694: 22.537997261787382\n",
      "Train Loss 695: 22.535985992289753\n",
      "Train Loss 696: 22.533981393983254\n",
      "Train Loss 697: 22.53198641047215\n",
      "Train Loss 698: 22.529999712858572\n",
      "Train Loss 699: 22.528019578190307\n",
      "Train Loss 700: 22.526046686329426\n",
      "Train Loss 701: 22.52407994664134\n",
      "Train Loss 702: 22.522119381734708\n",
      "Train Loss 703: 22.520163850087734\n",
      "Train Loss 704: 22.51821465765766\n",
      "Train Loss 705: 22.51627299680754\n",
      "Train Loss 706: 22.514337179402972\n",
      "Train Loss 707: 22.512407743196665\n",
      "Train Loss 708: 22.510483714391402\n",
      "Train Loss 709: 22.50856417533862\n",
      "Train Loss 710: 22.506649564023906\n",
      "Train Loss 711: 22.504741924478505\n",
      "Train Loss 712: 22.502841130177156\n",
      "Train Loss 713: 22.5009464101931\n",
      "Train Loss 714: 22.499055949834116\n",
      "Train Loss 715: 22.49717035345252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 716: 22.495291003274474\n",
      "Train Loss 717: 22.49341749626779\n",
      "Train Loss 718: 22.491550563178752\n",
      "Train Loss 719: 22.489690751811395\n",
      "Train Loss 720: 22.48783824789645\n",
      "Train Loss 721: 22.485991227215386\n",
      "Train Loss 722: 22.484148937354746\n",
      "Train Loss 723: 22.48230990358425\n",
      "Train Loss 724: 22.480475834601236\n",
      "Train Loss 725: 22.478651038820438\n",
      "Train Loss 726: 22.47683112680867\n",
      "Train Loss 727: 22.475018292872075\n",
      "Train Loss 728: 22.473211009932243\n",
      "Train Loss 729: 22.471406058233335\n",
      "Train Loss 730: 22.469605818366038\n",
      "Train Loss 731: 22.467810509591764\n",
      "Train Loss 732: 22.466021153344744\n",
      "Train Loss 733: 22.46423838568295\n",
      "Train Loss 734: 22.462459594043427\n",
      "Train Loss 735: 22.46068610017861\n",
      "Train Loss 736: 22.458917697764264\n",
      "Train Loss 737: 22.457156057751515\n",
      "Train Loss 738: 22.455400621332764\n",
      "Train Loss 739: 22.453653164496018\n",
      "Train Loss 740: 22.45191379916399\n",
      "Train Loss 741: 22.45018205963738\n",
      "Train Loss 742: 22.448456662371775\n",
      "Train Loss 743: 22.44673644020932\n",
      "Train Loss 744: 22.445022196942496\n",
      "Train Loss 745: 22.443314564079643\n",
      "Train Loss 746: 22.441612462854202\n",
      "Train Loss 747: 22.43991758963849\n",
      "Train Loss 748: 22.438227271602752\n",
      "Train Loss 749: 22.436542814314166\n",
      "Train Loss 750: 22.434864102965165\n",
      "Train Loss 751: 22.43319128492649\n",
      "Train Loss 752: 22.431523699337298\n",
      "Train Loss 753: 22.429861176521527\n",
      "Train Loss 754: 22.428205229496\n",
      "Train Loss 755: 22.426557368629023\n",
      "Train Loss 756: 22.42491379880772\n",
      "Train Loss 757: 22.423274405344227\n",
      "Train Loss 758: 22.421640751194406\n",
      "Train Loss 759: 22.420014076017246\n",
      "Train Loss 760: 22.418392167771298\n",
      "Train Loss 761: 22.416774124264737\n",
      "Train Loss 762: 22.415160621805157\n",
      "Train Loss 763: 22.413551179632584\n",
      "Train Loss 764: 22.4119466320741\n",
      "Train Loss 765: 22.4103463067687\n",
      "Train Loss 766: 22.408751274847308\n",
      "Train Loss 767: 22.407160114343437\n",
      "Train Loss 768: 22.405573794183987\n",
      "Train Loss 769: 22.40399240911953\n",
      "Train Loss 770: 22.402415215403007\n",
      "Train Loss 771: 22.400841591459425\n",
      "Train Loss 772: 22.39927302250168\n",
      "Train Loss 773: 22.397709210813673\n",
      "Train Loss 774: 22.396150500796644\n",
      "Train Loss 775: 22.394595051009542\n",
      "Train Loss 776: 22.39304364370364\n",
      "Train Loss 777: 22.391495119525057\n",
      "Train Loss 778: 22.389950277822404\n",
      "Train Loss 779: 22.388409716511816\n",
      "Train Loss 780: 22.38687502844694\n",
      "Train Loss 781: 22.385347302813305\n",
      "Train Loss 782: 22.383825377672323\n",
      "Train Loss 783: 22.382307453191352\n",
      "Train Loss 784: 22.38079190475255\n",
      "Train Loss 785: 22.37928104413995\n",
      "Train Loss 786: 22.3777750110408\n",
      "Train Loss 787: 22.376272468423778\n",
      "Train Loss 788: 22.374774802123508\n",
      "Train Loss 789: 22.373280659954066\n",
      "Train Loss 790: 22.371792525372374\n",
      "Train Loss 791: 22.370309236709645\n",
      "Train Loss 792: 22.368830319571412\n",
      "Train Loss 793: 22.367356361464683\n",
      "Train Loss 794: 22.365889001147398\n",
      "Train Loss 795: 22.364427082110172\n",
      "Train Loss 796: 22.36296925247271\n",
      "Train Loss 797: 22.36151535825782\n",
      "Train Loss 798: 22.360065772536117\n",
      "Train Loss 799: 22.35861902842596\n",
      "Train Loss 800: 22.3571759452586\n",
      "Train Loss 801: 22.355738396677687\n",
      "Train Loss 802: 22.354305714646703\n",
      "Train Loss 803: 22.352877040498406\n",
      "Train Loss 804: 22.351453777928924\n",
      "Train Loss 805: 22.350036378201803\n",
      "Train Loss 806: 22.348623059128496\n",
      "Train Loss 807: 22.3472135437744\n",
      "Train Loss 808: 22.345808328468927\n",
      "Train Loss 809: 22.344407041448623\n",
      "Train Loss 810: 22.343008535158614\n",
      "Train Loss 811: 22.341614470359303\n",
      "Train Loss 812: 22.340225035092338\n",
      "Train Loss 813: 22.338840075250747\n",
      "Train Loss 814: 22.337458734032854\n",
      "Train Loss 815: 22.336079617486252\n",
      "Train Loss 816: 22.3347034608348\n",
      "Train Loss 817: 22.333330470269818\n",
      "Train Loss 818: 22.33196183019922\n",
      "Train Loss 819: 22.33059710968453\n",
      "Train Loss 820: 22.329235978363457\n",
      "Train Loss 821: 22.32787883810394\n",
      "Train Loss 822: 22.32652399432175\n",
      "Train Loss 823: 22.325171449678262\n",
      "Train Loss 824: 22.323821655465114\n",
      "Train Loss 825: 22.322476649367097\n",
      "Train Loss 826: 22.321134246342453\n",
      "Train Loss 827: 22.3197956901646\n",
      "Train Loss 828: 22.31845990277154\n",
      "Train Loss 829: 22.317127574302674\n",
      "Train Loss 830: 22.31579887518766\n",
      "Train Loss 831: 22.314473552747792\n",
      "Train Loss 832: 22.313151714045517\n",
      "Train Loss 833: 22.31183485360412\n",
      "Train Loss 834: 22.310521070732225\n",
      "Train Loss 835: 22.309211416158096\n",
      "Train Loss 836: 22.307906213669224\n",
      "Train Loss 837: 22.306603868420467\n",
      "Train Loss 838: 22.30530646667832\n",
      "Train Loss 839: 22.304014378812013\n",
      "Train Loss 840: 22.302725960736296\n",
      "Train Loss 841: 22.301439250351308\n",
      "Train Loss 842: 22.300154714296266\n",
      "Train Loss 843: 22.29887317184538\n",
      "Train Loss 844: 22.297595249527724\n",
      "Train Loss 845: 22.29632081551419\n",
      "Train Loss 846: 22.295049702658677\n",
      "Train Loss 847: 22.293784054954756\n",
      "Train Loss 848: 22.292522806325756\n",
      "Train Loss 849: 22.291264554001362\n",
      "Train Loss 850: 22.290009192255113\n",
      "Train Loss 851: 22.288757565172535\n",
      "Train Loss 852: 22.287508424514037\n",
      "Train Loss 853: 22.28626140238205\n",
      "Train Loss 854: 22.285016256147443\n",
      "Train Loss 855: 22.283773626133495\n",
      "Train Loss 856: 22.282533482172195\n",
      "Train Loss 857: 22.281297946685445\n",
      "Train Loss 858: 22.28006548197283\n",
      "Train Loss 859: 22.278834193066587\n",
      "Train Loss 860: 22.277605359912823\n",
      "Train Loss 861: 22.276379672513567\n",
      "Train Loss 862: 22.27515757629532\n",
      "Train Loss 863: 22.273938192623376\n",
      "Train Loss 864: 22.27272102425982\n",
      "Train Loss 865: 22.271507417606223\n",
      "Train Loss 866: 22.270296005607488\n",
      "Train Loss 867: 22.269086222181905\n",
      "Train Loss 868: 22.26787890943966\n",
      "Train Loss 869: 22.266675960118768\n",
      "Train Loss 870: 22.26547598479887\n",
      "Train Loss 871: 22.264278316826005\n",
      "Train Loss 872: 22.263083243604378\n",
      "Train Loss 873: 22.26189262881705\n",
      "Train Loss 874: 22.260703811985913\n",
      "Train Loss 875: 22.259516828828822\n",
      "Train Loss 876: 22.258331493450967\n",
      "Train Loss 877: 22.257149471017218\n",
      "Train Loss 878: 22.255970102238816\n",
      "Train Loss 879: 22.254792827541934\n",
      "Train Loss 880: 22.25361718353358\n",
      "Train Loss 881: 22.252443585305315\n",
      "Train Loss 882: 22.251272533822267\n",
      "Train Loss 883: 22.250103432466357\n",
      "Train Loss 884: 22.248936631306265\n",
      "Train Loss 885: 22.247772480784562\n",
      "Train Loss 886: 22.2466115865747\n",
      "Train Loss 887: 22.24545237796153\n",
      "Train Loss 888: 22.244294265465545\n",
      "Train Loss 889: 22.243140645308824\n",
      "Train Loss 890: 22.241988759961778\n",
      "Train Loss 891: 22.240838939352376\n",
      "Train Loss 892: 22.239692129228068\n",
      "Train Loss 893: 22.238548129038655\n",
      "Train Loss 894: 22.23740920378148\n",
      "Train Loss 895: 22.236271895571512\n",
      "Train Loss 896: 22.23513605040732\n",
      "Train Loss 897: 22.23400198857998\n",
      "Train Loss 898: 22.23286962388734\n",
      "Train Loss 899: 22.231738918942543\n",
      "Train Loss 900: 22.23060947381701\n",
      "Train Loss 901: 22.229481359756136\n",
      "Train Loss 902: 22.228354888805214\n",
      "Train Loss 903: 22.227230135096647\n",
      "Train Loss 904: 22.226107507535694\n",
      "Train Loss 905: 22.22498764935792\n",
      "Train Loss 906: 22.223869871536053\n",
      "Train Loss 907: 22.22275470946156\n",
      "Train Loss 908: 22.22164205970425\n",
      "Train Loss 909: 22.220531602224852\n",
      "Train Loss 910: 22.219424618751205\n",
      "Train Loss 911: 22.218320802600694\n",
      "Train Loss 912: 22.21721940574212\n",
      "Train Loss 913: 22.216120406114445\n",
      "Train Loss 914: 22.21502233720359\n",
      "Train Loss 915: 22.21392691011386\n",
      "Train Loss 916: 22.21283456045021\n",
      "Train Loss 917: 22.211743204018806\n",
      "Train Loss 918: 22.210653650810304\n",
      "Train Loss 919: 22.2095661526548\n",
      "Train Loss 920: 22.208480233709857\n",
      "Train Loss 921: 22.207397068142093\n",
      "Train Loss 922: 22.206317121539072\n",
      "Train Loss 923: 22.205240059683092\n",
      "Train Loss 924: 22.20416438413738\n",
      "Train Loss 925: 22.203090161677025\n",
      "Train Loss 926: 22.202018514276666\n",
      "Train Loss 927: 22.200949650912186\n",
      "Train Loss 928: 22.199883222326832\n",
      "Train Loss 929: 22.198819368747433\n",
      "Train Loss 930: 22.197757678879846\n",
      "Train Loss 931: 22.19669915939043\n",
      "Train Loss 932: 22.1956431668498\n",
      "Train Loss 933: 22.194590166862056\n",
      "Train Loss 934: 22.193539002854727\n",
      "Train Loss 935: 22.192488587672074\n",
      "Train Loss 936: 22.191440263201176\n",
      "Train Loss 937: 22.190394127514484\n",
      "Train Loss 938: 22.189349423366636\n",
      "Train Loss 939: 22.1883067178987\n",
      "Train Loss 940: 22.18726636657115\n",
      "Train Loss 941: 22.18622845870191\n",
      "Train Loss 942: 22.18519286478259\n",
      "Train Loss 943: 22.1841602121364\n",
      "Train Loss 944: 22.18313001887067\n",
      "Train Loss 945: 22.182101322164097\n",
      "Train Loss 946: 22.181074727956883\n",
      "Train Loss 947: 22.180050239645453\n",
      "Train Loss 948: 22.17902696555496\n",
      "Train Loss 949: 22.178005296196908\n",
      "Train Loss 950: 22.176985108591\n",
      "Train Loss 951: 22.175966770139787\n",
      "Train Loss 952: 22.17494990106244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 953: 22.1739349804442\n",
      "Train Loss 954: 22.172922451277966\n",
      "Train Loss 955: 22.171911643802098\n",
      "Train Loss 956: 22.170901899284875\n",
      "Train Loss 957: 22.169893689828207\n",
      "Train Loss 958: 22.16888937649596\n",
      "Train Loss 959: 22.167887002361915\n",
      "Train Loss 960: 22.16688575584056\n",
      "Train Loss 961: 22.16588528772536\n",
      "Train Loss 962: 22.164886690315925\n",
      "Train Loss 963: 22.1638897403622\n",
      "Train Loss 964: 22.162894673194153\n",
      "Train Loss 965: 22.161902982319845\n",
      "Train Loss 966: 22.160913465745878\n",
      "Train Loss 967: 22.159925978821907\n",
      "Train Loss 968: 22.158940168323085\n",
      "Train Loss 969: 22.1579553703723\n",
      "Train Loss 970: 22.156972353359983\n",
      "Train Loss 971: 22.15599181103322\n",
      "Train Loss 972: 22.15501355082939\n",
      "Train Loss 973: 22.15403749743698\n",
      "Train Loss 974: 22.1530628698938\n",
      "Train Loss 975: 22.15209043821417\n",
      "Train Loss 976: 22.151119465636903\n",
      "Train Loss 977: 22.150151059840603\n",
      "Train Loss 978: 22.14918319092461\n",
      "Train Loss 979: 22.148216265024235\n",
      "Train Loss 980: 22.147249605696658\n",
      "Train Loss 981: 22.14628439086153\n",
      "Train Loss 982: 22.145321532447404\n",
      "Train Loss 983: 22.14436066993801\n",
      "Train Loss 984: 22.143401720825857\n",
      "Train Loss 985: 22.142444434192964\n",
      "Train Loss 986: 22.141488578465726\n",
      "Train Loss 987: 22.14053469633873\n",
      "Train Loss 988: 22.139582910976987\n",
      "Train Loss 989: 22.138632218895683\n",
      "Train Loss 990: 22.13768287657872\n",
      "Train Loss 991: 22.13673439756634\n",
      "Train Loss 992: 22.135786970057058\n",
      "Train Loss 993: 22.134840639402974\n",
      "Train Loss 994: 22.133895504048834\n",
      "Train Loss 995: 22.132951096704346\n",
      "Train Loss 996: 22.13200785354499\n",
      "Train Loss 997: 22.131065343293937\n",
      "Train Loss 998: 22.130124106310316\n",
      "Train Loss 999: 22.129184740220655\n",
      "Train Loss 1000: 22.128249375179923\n",
      "Train Loss 1001: 22.127315684484348\n",
      "Train Loss 1002: 22.12638395062389\n",
      "Train Loss 1003: 22.125453782381122\n",
      "Train Loss 1004: 22.124525157624664\n",
      "Train Loss 1005: 22.123598150028798\n",
      "Train Loss 1006: 22.122672612176366\n",
      "Train Loss 1007: 22.121748048429893\n",
      "Train Loss 1008: 22.12082387355358\n",
      "Train Loss 1009: 22.119900821287114\n",
      "Train Loss 1010: 22.11897865879467\n",
      "Train Loss 1011: 22.118057585654874\n",
      "Train Loss 1012: 22.117138674091567\n",
      "Train Loss 1013: 22.116221799062306\n",
      "Train Loss 1014: 22.115306712039867\n",
      "Train Loss 1015: 22.114393112834602\n",
      "Train Loss 1016: 22.11348064743381\n",
      "Train Loss 1017: 22.112569811484065\n",
      "Train Loss 1018: 22.111660281280045\n",
      "Train Loss 1019: 22.11075137874304\n",
      "Train Loss 1020: 22.109844043227607\n",
      "Train Loss 1021: 22.108938472487615\n",
      "Train Loss 1022: 22.108035186924884\n",
      "Train Loss 1023: 22.107133151530185\n",
      "Train Loss 1024: 22.106231493694775\n",
      "Train Loss 1025: 22.105330814653072\n",
      "Train Loss 1026: 22.104431241106468\n",
      "Train Loss 1027: 22.103531931552013\n",
      "Train Loss 1028: 22.10263440902163\n",
      "Train Loss 1029: 22.10173836493054\n",
      "Train Loss 1030: 22.100844132183827\n",
      "Train Loss 1031: 22.09995128023027\n",
      "Train Loss 1032: 22.09906025500571\n",
      "Train Loss 1033: 22.098170495538007\n",
      "Train Loss 1034: 22.09728228973379\n",
      "Train Loss 1035: 22.096395466039287\n",
      "Train Loss 1036: 22.09550975847044\n",
      "Train Loss 1037: 22.094625039226663\n",
      "Train Loss 1038: 22.093741131972244\n",
      "Train Loss 1039: 22.092857389401455\n",
      "Train Loss 1040: 22.091974299949417\n",
      "Train Loss 1041: 22.091092344163506\n",
      "Train Loss 1042: 22.09021152327245\n",
      "Train Loss 1043: 22.08933205009411\n",
      "Train Loss 1044: 22.08845409574711\n",
      "Train Loss 1045: 22.08757701825217\n",
      "Train Loss 1046: 22.086701999953775\n",
      "Train Loss 1047: 22.085828448769007\n",
      "Train Loss 1048: 22.084955820275564\n",
      "Train Loss 1049: 22.08408447460042\n",
      "Train Loss 1050: 22.083214686714747\n",
      "Train Loss 1051: 22.082346318486437\n",
      "Train Loss 1052: 22.081479815393077\n",
      "Train Loss 1053: 22.080614527787983\n",
      "Train Loss 1054: 22.079750928904353\n",
      "Train Loss 1055: 22.07888841033984\n",
      "Train Loss 1056: 22.078026724234938\n",
      "Train Loss 1057: 22.07716538295541\n",
      "Train Loss 1058: 22.076305068691006\n",
      "Train Loss 1059: 22.075446264815753\n",
      "Train Loss 1060: 22.074588693499663\n",
      "Train Loss 1061: 22.07373264505353\n",
      "Train Loss 1062: 22.072878307597684\n",
      "Train Loss 1063: 22.072025519676664\n",
      "Train Loss 1064: 22.07117378037836\n",
      "Train Loss 1065: 22.07032350034022\n",
      "Train Loss 1066: 22.06947459503657\n",
      "Train Loss 1067: 22.068626412634433\n",
      "Train Loss 1068: 22.06777902992624\n",
      "Train Loss 1069: 22.066933105981942\n",
      "Train Loss 1070: 22.066088737799713\n",
      "Train Loss 1071: 22.065246319095305\n",
      "Train Loss 1072: 22.0644046348115\n",
      "Train Loss 1073: 22.063564872382514\n",
      "Train Loss 1074: 22.06272674261883\n",
      "Train Loss 1075: 22.06189038622766\n",
      "Train Loss 1076: 22.06105516903538\n",
      "Train Loss 1077: 22.060221642674943\n",
      "Train Loss 1078: 22.059389175617063\n",
      "Train Loss 1079: 22.0585583602262\n",
      "Train Loss 1080: 22.05772858425383\n",
      "Train Loss 1081: 22.056900160702792\n",
      "Train Loss 1082: 22.056072544590677\n",
      "Train Loss 1083: 22.055245745681315\n",
      "Train Loss 1084: 22.054419884906356\n",
      "Train Loss 1085: 22.053595385157013\n",
      "Train Loss 1086: 22.052771896703625\n",
      "Train Loss 1087: 22.05194930875819\n",
      "Train Loss 1088: 22.051127738109646\n",
      "Train Loss 1089: 22.05030731184817\n",
      "Train Loss 1090: 22.049488177607568\n",
      "Train Loss 1091: 22.048670375097814\n",
      "Train Loss 1092: 22.047853530310785\n",
      "Train Loss 1093: 22.04703770467411\n",
      "Train Loss 1094: 22.04622313557536\n",
      "Train Loss 1095: 22.04540988307404\n",
      "Train Loss 1096: 22.04459804545005\n",
      "Train Loss 1097: 22.043787122247345\n",
      "Train Loss 1098: 22.042976848513696\n",
      "Train Loss 1099: 22.042166809950157\n",
      "Train Loss 1100: 22.04135739150595\n",
      "Train Loss 1101: 22.040548866868455\n",
      "Train Loss 1102: 22.039741122870286\n",
      "Train Loss 1103: 22.038933998816162\n",
      "Train Loss 1104: 22.0381275885115\n",
      "Train Loss 1105: 22.03732220512761\n",
      "Train Loss 1106: 22.036518061018647\n",
      "Train Loss 1107: 22.03571528488311\n",
      "Train Loss 1108: 22.034913983924504\n",
      "Train Loss 1109: 22.034113633966438\n",
      "Train Loss 1110: 22.033314115269146\n",
      "Train Loss 1111: 22.032515263288786\n",
      "Train Loss 1112: 22.031716535615864\n",
      "Train Loss 1113: 22.03091872803331\n",
      "Train Loss 1114: 22.030121933631428\n",
      "Train Loss 1115: 22.029326114497565\n",
      "Train Loss 1116: 22.028531109791377\n",
      "Train Loss 1117: 22.02773672082082\n",
      "Train Loss 1118: 22.026943696512973\n",
      "Train Loss 1119: 22.026151011050345\n",
      "Train Loss 1120: 22.025359188530494\n",
      "Train Loss 1121: 22.024568406484637\n",
      "Train Loss 1122: 22.023778396055615\n",
      "Train Loss 1123: 22.02298938229556\n",
      "Train Loss 1124: 22.022201515074045\n",
      "Train Loss 1125: 22.02141479181043\n",
      "Train Loss 1126: 22.020628904614963\n",
      "Train Loss 1127: 22.01984407868737\n",
      "Train Loss 1128: 22.019060006080522\n",
      "Train Loss 1129: 22.018276850158287\n",
      "Train Loss 1130: 22.01749447568995\n",
      "Train Loss 1131: 22.016712511334877\n",
      "Train Loss 1132: 22.015931578322775\n",
      "Train Loss 1133: 22.015151598346584\n",
      "Train Loss 1134: 22.014373248417087\n",
      "Train Loss 1135: 22.01359631200796\n",
      "Train Loss 1136: 22.012820893939505\n",
      "Train Loss 1137: 22.01204636307608\n",
      "Train Loss 1138: 22.011272701049375\n",
      "Train Loss 1139: 22.010499551987397\n",
      "Train Loss 1140: 22.00972707817461\n",
      "Train Loss 1141: 22.008955701904775\n",
      "Train Loss 1142: 22.008186515562297\n",
      "Train Loss 1143: 22.00741842516759\n",
      "Train Loss 1144: 22.0066512513651\n",
      "Train Loss 1145: 22.005884738663113\n",
      "Train Loss 1146: 22.005119117866208\n",
      "Train Loss 1147: 22.004354872394572\n",
      "Train Loss 1148: 22.003591445853285\n",
      "Train Loss 1149: 22.002828153056768\n",
      "Train Loss 1150: 22.002065603594517\n",
      "Train Loss 1151: 22.00130398938116\n",
      "Train Loss 1152: 22.000543193913114\n",
      "Train Loss 1153: 21.999783842906616\n",
      "Train Loss 1154: 21.99902488666037\n",
      "Train Loss 1155: 21.998266368341653\n",
      "Train Loss 1156: 21.9975083631462\n",
      "Train Loss 1157: 21.996751214491688\n",
      "Train Loss 1158: 21.995995316437565\n",
      "Train Loss 1159: 21.995240298508563\n",
      "Train Loss 1160: 21.994486056986617\n",
      "Train Loss 1161: 21.993732766099065\n",
      "Train Loss 1162: 21.992980583857964\n",
      "Train Loss 1163: 21.99222901078327\n",
      "Train Loss 1164: 21.991478281956415\n",
      "Train Loss 1165: 21.99072907862099\n",
      "Train Loss 1166: 21.98998113868765\n",
      "Train Loss 1167: 21.98923393021998\n",
      "Train Loss 1168: 21.98848741071428\n",
      "Train Loss 1169: 21.98774220359024\n",
      "Train Loss 1170: 21.986997853304537\n",
      "Train Loss 1171: 21.986254764085388\n",
      "Train Loss 1172: 21.985512459363896\n",
      "Train Loss 1173: 21.984770187858977\n",
      "Train Loss 1174: 21.984028706600192\n",
      "Train Loss 1175: 21.98328852145616\n",
      "Train Loss 1176: 21.98254937938363\n",
      "Train Loss 1177: 21.981811457844866\n",
      "Train Loss 1178: 21.981075097810074\n",
      "Train Loss 1179: 21.980339394570372\n",
      "Train Loss 1180: 21.97960425993442\n",
      "Train Loss 1181: 21.978869649489596\n",
      "Train Loss 1182: 21.97813597726721\n",
      "Train Loss 1183: 21.977402367714674\n",
      "Train Loss 1184: 21.97666935854539\n",
      "Train Loss 1185: 21.975937260985187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 1186: 21.975205689353093\n",
      "Train Loss 1187: 21.974474978841403\n",
      "Train Loss 1188: 21.97374450395941\n",
      "Train Loss 1189: 21.973014364510835\n",
      "Train Loss 1190: 21.97228470190925\n",
      "Train Loss 1191: 21.9715557030784\n",
      "Train Loss 1192: 21.970827380963964\n",
      "Train Loss 1193: 21.970099481888788\n",
      "Train Loss 1194: 21.969372132704137\n",
      "Train Loss 1195: 21.9686455788341\n",
      "Train Loss 1196: 21.967920047317435\n",
      "Train Loss 1197: 21.967195653911546\n",
      "Train Loss 1198: 21.966471713221942\n",
      "Train Loss 1199: 21.965748394422484\n",
      "Train Loss 1200: 21.96502588229835\n",
      "Train Loss 1201: 21.964304177629575\n",
      "Train Loss 1202: 21.963583143404676\n",
      "Train Loss 1203: 21.962862853245298\n",
      "Train Loss 1204: 21.962143364887382\n",
      "Train Loss 1205: 21.961424613632992\n",
      "Train Loss 1206: 21.960706645932362\n",
      "Train Loss 1207: 21.959989408729665\n",
      "Train Loss 1208: 21.959272348171606\n",
      "Train Loss 1209: 21.95855537182467\n",
      "Train Loss 1210: 21.95783872138765\n",
      "Train Loss 1211: 21.957122726325892\n",
      "Train Loss 1212: 21.95640709912457\n",
      "Train Loss 1213: 21.95569211011305\n",
      "Train Loss 1214: 21.954977275476622\n",
      "Train Loss 1215: 21.954262863917943\n",
      "Train Loss 1216: 21.95354902015565\n",
      "Train Loss 1217: 21.95283549975873\n",
      "Train Loss 1218: 21.952122592857005\n",
      "Train Loss 1219: 21.95141027501152\n",
      "Train Loss 1220: 21.950699231988626\n",
      "Train Loss 1221: 21.949988992222252\n",
      "Train Loss 1222: 21.949279479311038\n",
      "Train Loss 1223: 21.948570438056258\n",
      "Train Loss 1224: 21.94786179165183\n",
      "Train Loss 1225: 21.94715430366273\n",
      "Train Loss 1226: 21.94644754588242\n",
      "Train Loss 1227: 21.94574126375135\n",
      "Train Loss 1228: 21.945035418309377\n",
      "Train Loss 1229: 21.944330265500756\n",
      "Train Loss 1230: 21.943625789962642\n",
      "Train Loss 1231: 21.94292192775527\n",
      "Train Loss 1232: 21.942218480751638\n",
      "Train Loss 1233: 21.941515913829768\n",
      "Train Loss 1234: 21.940814397879063\n",
      "Train Loss 1235: 21.940113859633534\n",
      "Train Loss 1236: 21.939414091315477\n",
      "Train Loss 1237: 21.938715128258817\n",
      "Train Loss 1238: 21.93801693276988\n",
      "Train Loss 1239: 21.9373190438928\n",
      "Train Loss 1240: 21.936621611896815\n",
      "Train Loss 1241: 21.935924761645488\n",
      "Train Loss 1242: 21.93522823692087\n",
      "Train Loss 1243: 21.934532161451454\n",
      "Train Loss 1244: 21.933836235679756\n",
      "Train Loss 1245: 21.933140911196567\n",
      "Train Loss 1246: 21.93244634057423\n",
      "Train Loss 1247: 21.931752269138585\n",
      "Train Loss 1248: 21.931058393837187\n",
      "Train Loss 1249: 21.930364873878858\n",
      "Train Loss 1250: 21.929672218493536\n",
      "Train Loss 1251: 21.928980108422135\n",
      "Train Loss 1252: 21.928288655691\n",
      "Train Loss 1253: 21.92759788404482\n",
      "Train Loss 1254: 21.92690799658153\n",
      "Train Loss 1255: 21.926218909589654\n",
      "Train Loss 1256: 21.925530443362575\n",
      "Train Loss 1257: 21.924842431365168\n",
      "Train Loss 1258: 21.924154919076102\n",
      "Train Loss 1259: 21.923467864443644\n",
      "Train Loss 1260: 21.92278150136054\n",
      "Train Loss 1261: 21.92209599049348\n",
      "Train Loss 1262: 21.92141103223814\n",
      "Train Loss 1263: 21.920726696532945\n",
      "Train Loss 1264: 21.920042698985377\n",
      "Train Loss 1265: 21.91935864294959\n",
      "Train Loss 1266: 21.918675103615797\n",
      "Train Loss 1267: 21.917992046312865\n",
      "Train Loss 1268: 21.917309673200435\n",
      "Train Loss 1269: 21.916628107968624\n",
      "Train Loss 1270: 21.915946831360134\n",
      "Train Loss 1271: 21.91526594635522\n",
      "Train Loss 1272: 21.914585718189045\n",
      "Train Loss 1273: 21.913906138782316\n",
      "Train Loss 1274: 21.913227492922168\n",
      "Train Loss 1275: 21.912549178639686\n",
      "Train Loss 1276: 21.911871924537643\n",
      "Train Loss 1277: 21.91119557686754\n",
      "Train Loss 1278: 21.91051985251418\n",
      "Train Loss 1279: 21.909844695813476\n",
      "Train Loss 1280: 21.909169859700135\n",
      "Train Loss 1281: 21.908495545306234\n",
      "Train Loss 1282: 21.907821927970673\n",
      "Train Loss 1283: 21.907148933555945\n",
      "Train Loss 1284: 21.906476536063757\n",
      "Train Loss 1285: 21.905804773031665\n",
      "Train Loss 1286: 21.905133627509176\n",
      "Train Loss 1287: 21.9044630928195\n",
      "Train Loss 1288: 21.903793120460463\n",
      "Train Loss 1289: 21.903123621420278\n",
      "Train Loss 1290: 21.90245462929476\n",
      "Train Loss 1291: 21.901786496525904\n",
      "Train Loss 1292: 21.901119267757167\n",
      "Train Loss 1293: 21.900452621797868\n",
      "Train Loss 1294: 21.89978632105865\n",
      "Train Loss 1295: 21.89912026535515\n",
      "Train Loss 1296: 21.89845459119945\n",
      "Train Loss 1297: 21.89778938537943\n",
      "Train Loss 1298: 21.89712487551643\n",
      "Train Loss 1299: 21.896461092317185\n",
      "Train Loss 1300: 21.895797927189427\n",
      "Train Loss 1301: 21.895135466846764\n",
      "Train Loss 1302: 21.89447319540973\n",
      "Train Loss 1303: 21.893811672842023\n",
      "Train Loss 1304: 21.89315087049747\n",
      "Train Loss 1305: 21.892490629238072\n",
      "Train Loss 1306: 21.891830593130646\n",
      "Train Loss 1307: 21.891170762697865\n",
      "Train Loss 1308: 21.89051152074632\n",
      "Train Loss 1309: 21.88985222176887\n",
      "Train Loss 1310: 21.889193190161127\n",
      "Train Loss 1311: 21.88853510774529\n",
      "Train Loss 1312: 21.887877712976383\n",
      "Train Loss 1313: 21.887220831438785\n",
      "Train Loss 1314: 21.886564508370427\n",
      "Train Loss 1315: 21.885908425201187\n",
      "Train Loss 1316: 21.88525238373365\n",
      "Train Loss 1317: 21.88459677310024\n",
      "Train Loss 1318: 21.88394154361961\n",
      "Train Loss 1319: 21.883287166814476\n",
      "Train Loss 1320: 21.88263316624598\n",
      "Train Loss 1321: 21.881980309743465\n",
      "Train Loss 1322: 21.881328898882167\n",
      "Train Loss 1323: 21.880678411591646\n",
      "Train Loss 1324: 21.880028332308168\n",
      "Train Loss 1325: 21.879378996861384\n",
      "Train Loss 1326: 21.87873072275369\n",
      "Train Loss 1327: 21.87808269451328\n",
      "Train Loss 1328: 21.877435008689506\n",
      "Train Loss 1329: 21.87678791417995\n",
      "Train Loss 1330: 21.87614127364198\n",
      "Train Loss 1331: 21.875495103265333\n",
      "Train Loss 1332: 21.874849343772784\n",
      "Train Loss 1333: 21.874204003529577\n",
      "Train Loss 1334: 21.87355904860947\n",
      "Train Loss 1335: 21.87291459881338\n",
      "Train Loss 1336: 21.87227080728335\n",
      "Train Loss 1337: 21.87162789536034\n",
      "Train Loss 1338: 21.870985484541087\n",
      "Train Loss 1339: 21.87034353014623\n",
      "Train Loss 1340: 21.86970205657441\n",
      "Train Loss 1341: 21.86906112022976\n",
      "Train Loss 1342: 21.86842031253647\n",
      "Train Loss 1343: 21.867780057235947\n",
      "Train Loss 1344: 21.86714133008371\n",
      "Train Loss 1345: 21.86650350929534\n",
      "Train Loss 1346: 21.865866142415836\n",
      "Train Loss 1347: 21.86522883522268\n",
      "Train Loss 1348: 21.864592253718172\n",
      "Train Loss 1349: 21.863956265428957\n",
      "Train Loss 1350: 21.863321232785022\n",
      "Train Loss 1351: 21.862686674891314\n",
      "Train Loss 1352: 21.862052589658088\n",
      "Train Loss 1353: 21.861418904106387\n",
      "Train Loss 1354: 21.86078585463641\n",
      "Train Loss 1355: 21.86015366211332\n",
      "Train Loss 1356: 21.859521916712186\n",
      "Train Loss 1357: 21.858890476398262\n",
      "Train Loss 1358: 21.858259207841435\n",
      "Train Loss 1359: 21.857628239970353\n",
      "Train Loss 1360: 21.856997471059305\n",
      "Train Loss 1361: 21.85636731854644\n",
      "Train Loss 1362: 21.855737577283588\n",
      "Train Loss 1363: 21.85510818399173\n",
      "Train Loss 1364: 21.854479308758673\n",
      "Train Loss 1365: 21.85385090886616\n",
      "Train Loss 1366: 21.853222879794124\n",
      "Train Loss 1367: 21.85259552054373\n",
      "Train Loss 1368: 21.85196863694032\n",
      "Train Loss 1369: 21.85134220975057\n",
      "Train Loss 1370: 21.850716048972192\n",
      "Train Loss 1371: 21.850090106055934\n",
      "Train Loss 1372: 21.84946450187312\n",
      "Train Loss 1373: 21.84883925137106\n",
      "Train Loss 1374: 21.848214474201455\n",
      "Train Loss 1375: 21.847590506052235\n",
      "Train Loss 1376: 21.84696701878556\n",
      "Train Loss 1377: 21.84634428108719\n",
      "Train Loss 1378: 21.845721869601856\n",
      "Train Loss 1379: 21.845099888660698\n",
      "Train Loss 1380: 21.84447857106577\n",
      "Train Loss 1381: 21.84385779000005\n",
      "Train Loss 1382: 21.843237300158613\n",
      "Train Loss 1383: 21.842617234608998\n",
      "Train Loss 1384: 21.841997733451723\n",
      "Train Loss 1385: 21.841378719800375\n",
      "Train Loss 1386: 21.840759992236094\n",
      "Train Loss 1387: 21.840141648633153\n",
      "Train Loss 1388: 21.83952367172062\n",
      "Train Loss 1389: 21.83890618921897\n",
      "Train Loss 1390: 21.838289059691288\n",
      "Train Loss 1391: 21.837672384607643\n",
      "Train Loss 1392: 21.837056171413746\n",
      "Train Loss 1393: 21.83644049677661\n",
      "Train Loss 1394: 21.835825178183548\n",
      "Train Loss 1395: 21.83521060395677\n",
      "Train Loss 1396: 21.83459677086207\n",
      "Train Loss 1397: 21.833983954639358\n",
      "Train Loss 1398: 21.833371495726926\n",
      "Train Loss 1399: 21.832759546751404\n",
      "Train Loss 1400: 21.83214807213767\n",
      "Train Loss 1401: 21.83153708923868\n",
      "Train Loss 1402: 21.830926551212183\n",
      "Train Loss 1403: 21.830316434972303\n",
      "Train Loss 1404: 21.82970664815108\n",
      "Train Loss 1405: 21.82909708645545\n",
      "Train Loss 1406: 21.828487868474564\n",
      "Train Loss 1407: 21.827879395826265\n",
      "Train Loss 1408: 21.827271491513887\n",
      "Train Loss 1409: 21.82666413973971\n",
      "Train Loss 1410: 21.826057336469646\n",
      "Train Loss 1411: 21.825451103589067\n",
      "Train Loss 1412: 21.824845507621532\n",
      "Train Loss 1413: 21.82424061880234\n",
      "Train Loss 1414: 21.823636141380852\n",
      "Train Loss 1415: 21.823032011270275\n",
      "Train Loss 1416: 21.822428286892354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 1417: 21.821825022772796\n",
      "Train Loss 1418: 21.821222256440606\n",
      "Train Loss 1419: 21.820619867356875\n",
      "Train Loss 1420: 21.820017801822146\n",
      "Train Loss 1421: 21.819415394735362\n",
      "Train Loss 1422: 21.818813409377963\n",
      "Train Loss 1423: 21.8182118055783\n",
      "Train Loss 1424: 21.81761053195207\n",
      "Train Loss 1425: 21.81700980243038\n",
      "Train Loss 1426: 21.8164095178974\n",
      "Train Loss 1427: 21.81580963593127\n",
      "Train Loss 1428: 21.815209942880706\n",
      "Train Loss 1429: 21.814610744573983\n",
      "Train Loss 1430: 21.81401165456281\n",
      "Train Loss 1431: 21.813412774257372\n",
      "Train Loss 1432: 21.812814278770364\n",
      "Train Loss 1433: 21.812216244014778\n",
      "Train Loss 1434: 21.811618852435828\n",
      "Train Loss 1435: 21.811021903501825\n",
      "Train Loss 1436: 21.81042544542887\n",
      "Train Loss 1437: 21.80982930310538\n",
      "Train Loss 1438: 21.809233402852847\n",
      "Train Loss 1439: 21.808637758594667\n",
      "Train Loss 1440: 21.80804233627313\n",
      "Train Loss 1441: 21.80744707340116\n",
      "Train Loss 1442: 21.806851901866747\n",
      "Train Loss 1443: 21.806257056094644\n",
      "Train Loss 1444: 21.805662606697965\n",
      "Train Loss 1445: 21.805068364626422\n",
      "Train Loss 1446: 21.804474251056813\n",
      "Train Loss 1447: 21.803880338350993\n",
      "Train Loss 1448: 21.803286696970623\n",
      "Train Loss 1449: 21.80269337946594\n",
      "Train Loss 1450: 21.802100469577248\n",
      "Train Loss 1451: 21.801507962600414\n",
      "Train Loss 1452: 21.800915677275015\n",
      "Train Loss 1453: 21.800323730125115\n",
      "Train Loss 1454: 21.79973217811446\n",
      "Train Loss 1455: 21.799141020903946\n",
      "Train Loss 1456: 21.79855060807271\n",
      "Train Loss 1457: 21.797960625969242\n",
      "Train Loss 1458: 21.79737111959552\n",
      "Train Loss 1459: 21.79678189065084\n",
      "Train Loss 1460: 21.79619314091775\n",
      "Train Loss 1461: 21.795604807917893\n",
      "Train Loss 1462: 21.79501668587839\n",
      "Train Loss 1463: 21.794428640155413\n",
      "Train Loss 1464: 21.79384083703455\n",
      "Train Loss 1465: 21.79325296411424\n",
      "Train Loss 1466: 21.79266522474744\n",
      "Train Loss 1467: 21.79207771990594\n",
      "Train Loss 1468: 21.79149067670918\n",
      "Train Loss 1469: 21.790904185105898\n",
      "Train Loss 1470: 21.79031844960714\n",
      "Train Loss 1471: 21.78973292615308\n",
      "Train Loss 1472: 21.789147457135243\n",
      "Train Loss 1473: 21.788562253380654\n",
      "Train Loss 1474: 21.787977351096828\n",
      "Train Loss 1475: 21.78739283766544\n",
      "Train Loss 1476: 21.7868087648174\n",
      "Train Loss 1477: 21.786225025740734\n",
      "Train Loss 1478: 21.78564151833413\n",
      "Train Loss 1479: 21.78505823378595\n",
      "Train Loss 1480: 21.78447530362424\n",
      "Train Loss 1481: 21.78389264071984\n",
      "Train Loss 1482: 21.783309952250967\n",
      "Train Loss 1483: 21.782727207769515\n",
      "Train Loss 1484: 21.782144629935733\n",
      "Train Loss 1485: 21.781562309217804\n",
      "Train Loss 1486: 21.780980215706094\n",
      "Train Loss 1487: 21.780398593877173\n",
      "Train Loss 1488: 21.779817321976715\n",
      "Train Loss 1489: 21.77923630057266\n",
      "Train Loss 1490: 21.778655505334328\n",
      "Train Loss 1491: 21.778074976943625\n",
      "Train Loss 1492: 21.77749486443796\n",
      "Train Loss 1493: 21.77691560948196\n",
      "Train Loss 1494: 21.776336688643262\n",
      "Train Loss 1495: 21.775758278731928\n",
      "Train Loss 1496: 21.77518058704645\n",
      "Train Loss 1497: 21.774603479527393\n",
      "Train Loss 1498: 21.77402678410251\n",
      "Train Loss 1499: 21.773450518476636\n",
      "Train Loss 1500: 21.77287454927342\n",
      "Train Loss 1501: 21.772298908349217\n",
      "Train Loss 1502: 21.771723623932903\n",
      "Train Loss 1503: 21.771148869463108\n",
      "Train Loss 1504: 21.770574192020536\n",
      "Train Loss 1505: 21.769999758578738\n",
      "Train Loss 1506: 21.76942535780097\n",
      "Train Loss 1507: 21.76885123907051\n",
      "Train Loss 1508: 21.768277348023428\n",
      "Train Loss 1509: 21.767703819555678\n",
      "Train Loss 1510: 21.767130446177667\n",
      "Train Loss 1511: 21.766557380791248\n",
      "Train Loss 1512: 21.765984663646705\n",
      "Train Loss 1513: 21.765412220873262\n",
      "Train Loss 1514: 21.764839967818233\n",
      "Train Loss 1515: 21.764267982889468\n",
      "Train Loss 1516: 21.763696543797614\n",
      "Train Loss 1517: 21.763125522633334\n",
      "Train Loss 1518: 21.762554687338444\n",
      "Train Loss 1519: 21.761984025099384\n",
      "Train Loss 1520: 21.761413689857324\n",
      "Train Loss 1521: 21.7608437905648\n",
      "Train Loss 1522: 21.76027453013994\n",
      "Train Loss 1523: 21.75970537365267\n",
      "Train Loss 1524: 21.75913658815791\n",
      "Train Loss 1525: 21.75856803391949\n",
      "Train Loss 1526: 21.75799971940428\n",
      "Train Loss 1527: 21.757431494528763\n",
      "Train Loss 1528: 21.756863547303244\n",
      "Train Loss 1529: 21.756295752123638\n",
      "Train Loss 1530: 21.75572825066849\n",
      "Train Loss 1531: 21.7551610738266\n",
      "Train Loss 1532: 21.754593974115927\n",
      "Train Loss 1533: 21.75402728513295\n",
      "Train Loss 1534: 21.753461337882726\n",
      "Train Loss 1535: 21.752895839525078\n",
      "Train Loss 1536: 21.752330629221653\n",
      "Train Loss 1537: 21.75176567432494\n",
      "Train Loss 1538: 21.751200948675717\n",
      "Train Loss 1539: 21.75063676028809\n",
      "Train Loss 1540: 21.750072809710986\n",
      "Train Loss 1541: 21.749509243224928\n",
      "Train Loss 1542: 21.74894592945431\n",
      "Train Loss 1543: 21.74838276655442\n",
      "Train Loss 1544: 21.747819819811685\n",
      "Train Loss 1545: 21.74725720116862\n",
      "Train Loss 1546: 21.746694849507684\n",
      "Train Loss 1547: 21.746133046822525\n",
      "Train Loss 1548: 21.745571352272563\n",
      "Train Loss 1549: 21.74500999119112\n",
      "Train Loss 1550: 21.744448947960375\n",
      "Train Loss 1551: 21.74388820001892\n",
      "Train Loss 1552: 21.743327545057547\n",
      "Train Loss 1553: 21.742767251034884\n",
      "Train Loss 1554: 21.742207211577924\n",
      "Train Loss 1555: 21.741647388809685\n",
      "Train Loss 1556: 21.741087658025602\n",
      "Train Loss 1557: 21.740528206139004\n",
      "Train Loss 1558: 21.739969151795098\n",
      "Train Loss 1559: 21.73941038774045\n",
      "Train Loss 1560: 21.738851935723343\n",
      "Train Loss 1561: 21.73829368737102\n",
      "Train Loss 1562: 21.737735675933266\n",
      "Train Loss 1563: 21.73717796814679\n",
      "Train Loss 1564: 21.736620726701812\n",
      "Train Loss 1565: 21.736063771457953\n",
      "Train Loss 1566: 21.735506917241956\n",
      "Train Loss 1567: 21.734950149288625\n",
      "Train Loss 1568: 21.734393555822553\n",
      "Train Loss 1569: 21.73383705195842\n",
      "Train Loss 1570: 21.733280662841103\n",
      "Train Loss 1571: 21.732724488086536\n",
      "Train Loss 1572: 21.732168465494965\n",
      "Train Loss 1573: 21.731612781358187\n",
      "Train Loss 1574: 21.731057255947785\n",
      "Train Loss 1575: 21.73050197533746\n",
      "Train Loss 1576: 21.729946914780314\n",
      "Train Loss 1577: 21.72939208993629\n",
      "Train Loss 1578: 21.728837406085308\n",
      "Train Loss 1579: 21.728282648660187\n",
      "Train Loss 1580: 21.727728324983875\n",
      "Train Loss 1581: 21.72717461660663\n",
      "Train Loss 1582: 21.726621224598272\n",
      "Train Loss 1583: 21.72606796129791\n",
      "Train Loss 1584: 21.72551493265419\n",
      "Train Loss 1585: 21.724962009173694\n",
      "Train Loss 1586: 21.724409554934212\n",
      "Train Loss 1587: 21.723857289853242\n",
      "Train Loss 1588: 21.72330522290497\n",
      "Train Loss 1589: 21.722753436973733\n",
      "Train Loss 1590: 21.722201746465622\n",
      "Train Loss 1591: 21.721650420702105\n",
      "Train Loss 1592: 21.721099760557976\n",
      "Train Loss 1593: 21.720549348768422\n",
      "Train Loss 1594: 21.71999910830933\n",
      "Train Loss 1595: 21.71944912660069\n",
      "Train Loss 1596: 21.71889933730629\n",
      "Train Loss 1597: 21.718349692283276\n",
      "Train Loss 1598: 21.717800272838833\n",
      "Train Loss 1599: 21.717251076152245\n",
      "Train Loss 1600: 21.716702347125533\n",
      "Train Loss 1601: 21.716153795433648\n",
      "Train Loss 1602: 21.71560546500994\n",
      "Train Loss 1603: 21.715057372608243\n",
      "Train Loss 1604: 21.714509359716438\n",
      "Train Loss 1605: 21.71396134490397\n",
      "Train Loss 1606: 21.71341355209828\n",
      "Train Loss 1607: 21.712865672837346\n",
      "Train Loss 1608: 21.712317891835852\n",
      "Train Loss 1609: 21.711770498967542\n",
      "Train Loss 1610: 21.71122331644648\n",
      "Train Loss 1611: 21.71067638498686\n",
      "Train Loss 1612: 21.710129663584315\n",
      "Train Loss 1613: 21.70958321332074\n",
      "Train Loss 1614: 21.709037208386025\n",
      "Train Loss 1615: 21.70849148144934\n",
      "Train Loss 1616: 21.70794595004611\n",
      "Train Loss 1617: 21.707400755692717\n",
      "Train Loss 1618: 21.706856121854155\n",
      "Train Loss 1619: 21.706312009934187\n",
      "Train Loss 1620: 21.70576810535203\n",
      "Train Loss 1621: 21.705224396604734\n",
      "Train Loss 1622: 21.704680938382474\n",
      "Train Loss 1623: 21.704137754692454\n",
      "Train Loss 1624: 21.7035949868037\n",
      "Train Loss 1625: 21.703052460513423\n",
      "Train Loss 1626: 21.702510097190334\n",
      "Train Loss 1627: 21.701967855121755\n",
      "Train Loss 1628: 21.701425732161283\n",
      "Train Loss 1629: 21.70088391646803\n",
      "Train Loss 1630: 21.700342681467596\n",
      "Train Loss 1631: 21.699801753068062\n",
      "Train Loss 1632: 21.699261095220727\n",
      "Train Loss 1633: 21.69872088069844\n",
      "Train Loss 1634: 21.69818084953764\n",
      "Train Loss 1635: 21.69764105841772\n",
      "Train Loss 1636: 21.697101623255293\n",
      "Train Loss 1637: 21.696562525735263\n",
      "Train Loss 1638: 21.69602360089295\n",
      "Train Loss 1639: 21.69548470367997\n",
      "Train Loss 1640: 21.694946165892663\n",
      "Train Loss 1641: 21.694407784046536\n",
      "Train Loss 1642: 21.693869484435616\n",
      "Train Loss 1643: 21.693331131140226\n",
      "Train Loss 1644: 21.69279296301087\n",
      "Train Loss 1645: 21.69225497537898\n",
      "Train Loss 1646: 21.691717068164298\n",
      "Train Loss 1647: 21.69117940603416\n",
      "Train Loss 1648: 21.69064201476374\n",
      "Train Loss 1649: 21.690105162180416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 1650: 21.689568581480717\n",
      "Train Loss 1651: 21.68903237880117\n",
      "Train Loss 1652: 21.68849638852886\n",
      "Train Loss 1653: 21.687960593361048\n",
      "Train Loss 1654: 21.687425044727316\n",
      "Train Loss 1655: 21.68688970947642\n",
      "Train Loss 1656: 21.68635463479947\n",
      "Train Loss 1657: 21.685819925027232\n",
      "Train Loss 1658: 21.685285461016324\n",
      "Train Loss 1659: 21.684751114457285\n",
      "Train Loss 1660: 21.684216734581195\n",
      "Train Loss 1661: 21.683682495938644\n",
      "Train Loss 1662: 21.683148412073837\n",
      "Train Loss 1663: 21.682614253658876\n",
      "Train Loss 1664: 21.682080318975974\n",
      "Train Loss 1665: 21.681546738231493\n",
      "Train Loss 1666: 21.681013469465505\n",
      "Train Loss 1667: 21.680480390888224\n",
      "Train Loss 1668: 21.679947476721214\n",
      "Train Loss 1669: 21.679414708805854\n",
      "Train Loss 1670: 21.678882051858388\n",
      "Train Loss 1671: 21.67834962345161\n",
      "Train Loss 1672: 21.677817356813083\n",
      "Train Loss 1673: 21.677285198929876\n",
      "Train Loss 1674: 21.676753236766675\n",
      "Train Loss 1675: 21.676221562874137\n",
      "Train Loss 1676: 21.675690054519922\n",
      "Train Loss 1677: 21.675158799682485\n",
      "Train Loss 1678: 21.674627998863464\n",
      "Train Loss 1679: 21.67409730649153\n",
      "Train Loss 1680: 21.67356676968893\n",
      "Train Loss 1681: 21.673036274868654\n",
      "Train Loss 1682: 21.672505552685994\n",
      "Train Loss 1683: 21.67197486447295\n",
      "Train Loss 1684: 21.67144460295187\n",
      "Train Loss 1685: 21.670914582354357\n",
      "Train Loss 1686: 21.670384715151886\n",
      "Train Loss 1687: 21.66985500092498\n",
      "Train Loss 1688: 21.66932542750885\n",
      "Train Loss 1689: 21.66879614466165\n",
      "Train Loss 1690: 21.66826718626117\n",
      "Train Loss 1691: 21.6677385990472\n",
      "Train Loss 1692: 21.66721053793692\n",
      "Train Loss 1693: 21.66668300086232\n",
      "Train Loss 1694: 21.66615566409999\n",
      "Train Loss 1695: 21.665628442446668\n",
      "Train Loss 1696: 21.665101405556484\n",
      "Train Loss 1697: 21.66457461835561\n",
      "Train Loss 1698: 21.664048080392163\n",
      "Train Loss 1699: 21.6635217725926\n",
      "Train Loss 1700: 21.662995779557406\n",
      "Train Loss 1701: 21.662469861390836\n",
      "Train Loss 1702: 21.661944126562936\n",
      "Train Loss 1703: 21.661418607490784\n",
      "Train Loss 1704: 21.660893014390453\n",
      "Train Loss 1705: 21.66036764556999\n",
      "Train Loss 1706: 21.65984238205159\n",
      "Train Loss 1707: 21.659317241864976\n",
      "Train Loss 1708: 21.658792540601183\n",
      "Train Loss 1709: 21.65826807284202\n",
      "Train Loss 1710: 21.65774358456633\n",
      "Train Loss 1711: 21.657219097504782\n",
      "Train Loss 1712: 21.656694843890254\n",
      "Train Loss 1713: 21.656170873434107\n",
      "Train Loss 1714: 21.65564784255613\n",
      "Train Loss 1715: 21.655124967033917\n",
      "Train Loss 1716: 21.654602352925288\n",
      "Train Loss 1717: 21.654079829013792\n",
      "Train Loss 1718: 21.653557459726777\n",
      "Train Loss 1719: 21.653035629638747\n",
      "Train Loss 1720: 21.652514401691057\n",
      "Train Loss 1721: 21.651993356300757\n",
      "Train Loss 1722: 21.65147243668783\n",
      "Train Loss 1723: 21.65095164650276\n",
      "Train Loss 1724: 21.650430930064175\n",
      "Train Loss 1725: 21.64991042845204\n",
      "Train Loss 1726: 21.64939008596104\n",
      "Train Loss 1727: 21.648869899190217\n",
      "Train Loss 1728: 21.64835016773916\n",
      "Train Loss 1729: 21.647830585847313\n",
      "Train Loss 1730: 21.647311183408945\n",
      "Train Loss 1731: 21.646792211060916\n",
      "Train Loss 1732: 21.646273773922463\n",
      "Train Loss 1733: 21.645755642219633\n",
      "Train Loss 1734: 21.64523779844577\n",
      "Train Loss 1735: 21.644719951528558\n",
      "Train Loss 1736: 21.64420217044558\n",
      "Train Loss 1737: 21.64368443484303\n",
      "Train Loss 1738: 21.64316685955723\n",
      "Train Loss 1739: 21.642649355233313\n",
      "Train Loss 1740: 21.642131994674113\n",
      "Train Loss 1741: 21.641615057111352\n",
      "Train Loss 1742: 21.641098554979322\n",
      "Train Loss 1743: 21.64058209081661\n",
      "Train Loss 1744: 21.640065759760205\n",
      "Train Loss 1745: 21.63954961083353\n",
      "Train Loss 1746: 21.639033607446372\n",
      "Train Loss 1747: 21.638517692540784\n",
      "Train Loss 1748: 21.6380019674915\n",
      "Train Loss 1749: 21.637486375089953\n",
      "Train Loss 1750: 21.636970780424967\n",
      "Train Loss 1751: 21.63645527259751\n",
      "Train Loss 1752: 21.635939967706083\n",
      "Train Loss 1753: 21.635424849577845\n",
      "Train Loss 1754: 21.634909918324425\n",
      "Train Loss 1755: 21.634395193391878\n",
      "Train Loss 1756: 21.633880665768196\n",
      "Train Loss 1757: 21.633366316626994\n",
      "Train Loss 1758: 21.632852361878587\n",
      "Train Loss 1759: 21.632338760937643\n",
      "Train Loss 1760: 21.63182520881344\n",
      "Train Loss 1761: 21.63131184127275\n",
      "Train Loss 1762: 21.630798723388295\n",
      "Train Loss 1763: 21.63028571509786\n",
      "Train Loss 1764: 21.6297730266056\n",
      "Train Loss 1765: 21.629260635124197\n",
      "Train Loss 1766: 21.62874837815401\n",
      "Train Loss 1767: 21.628236205556238\n",
      "Train Loss 1768: 21.627724059877384\n",
      "Train Loss 1769: 21.62721189039654\n",
      "Train Loss 1770: 21.62669996034927\n",
      "Train Loss 1771: 21.626188154290087\n",
      "Train Loss 1772: 21.625676472469546\n",
      "Train Loss 1773: 21.625164768479067\n",
      "Train Loss 1774: 21.62465326382401\n",
      "Train Loss 1775: 21.624141963145092\n",
      "Train Loss 1776: 21.623631017083575\n",
      "Train Loss 1777: 21.623120294743366\n",
      "Train Loss 1778: 21.622609637892346\n",
      "Train Loss 1779: 21.622099219678418\n",
      "Train Loss 1780: 21.621588931329836\n",
      "Train Loss 1781: 21.621078547655486\n",
      "Train Loss 1782: 21.6205683629988\n",
      "Train Loss 1783: 21.620058407143958\n",
      "Train Loss 1784: 21.61954899082568\n",
      "Train Loss 1785: 21.619039737399117\n",
      "Train Loss 1786: 21.61853101247168\n",
      "Train Loss 1787: 21.6180224928711\n",
      "Train Loss 1788: 21.6175141425095\n",
      "Train Loss 1789: 21.617005816490085\n",
      "Train Loss 1790: 21.616497562597992\n",
      "Train Loss 1791: 21.615989452039855\n",
      "Train Loss 1792: 21.61548155617476\n",
      "Train Loss 1793: 21.61497374413061\n",
      "Train Loss 1794: 21.614466050008954\n",
      "Train Loss 1795: 21.61395846608548\n",
      "Train Loss 1796: 21.61345099358259\n",
      "Train Loss 1797: 21.61294364017575\n",
      "Train Loss 1798: 21.61243644009065\n",
      "Train Loss 1799: 21.611929343312898\n",
      "Train Loss 1800: 21.61142241830959\n",
      "Train Loss 1801: 21.610915635731928\n",
      "Train Loss 1802: 21.610409288836895\n",
      "Train Loss 1803: 21.609903146304244\n",
      "Train Loss 1804: 21.60939719937785\n",
      "Train Loss 1805: 21.608891498523167\n",
      "Train Loss 1806: 21.608386017244374\n",
      "Train Loss 1807: 21.60788071355852\n",
      "Train Loss 1808: 21.60737556397052\n",
      "Train Loss 1809: 21.606870611998392\n",
      "Train Loss 1810: 21.60636581593619\n",
      "Train Loss 1811: 21.605861063049886\n",
      "Train Loss 1812: 21.60535649490208\n",
      "Train Loss 1813: 21.60485214317332\n",
      "Train Loss 1814: 21.60434796164331\n",
      "Train Loss 1815: 21.603844022223697\n",
      "Train Loss 1816: 21.603340321144426\n",
      "Train Loss 1817: 21.602836654746554\n",
      "Train Loss 1818: 21.60233305410535\n",
      "Train Loss 1819: 21.60182958947122\n",
      "Train Loss 1820: 21.60132625372365\n",
      "Train Loss 1821: 21.600823113831463\n",
      "Train Loss 1822: 21.600320189901883\n",
      "Train Loss 1823: 21.599817423432874\n",
      "Train Loss 1824: 21.599314773258186\n",
      "Train Loss 1825: 21.59881229187169\n",
      "Train Loss 1826: 21.598309984145526\n",
      "Train Loss 1827: 21.59780779947106\n",
      "Train Loss 1828: 21.59730575592734\n",
      "Train Loss 1829: 21.59680388412919\n",
      "Train Loss 1830: 21.59630219429454\n",
      "Train Loss 1831: 21.595800737811448\n",
      "Train Loss 1832: 21.5952994686598\n",
      "Train Loss 1833: 21.594798363749867\n",
      "Train Loss 1834: 21.59429742955959\n",
      "Train Loss 1835: 21.593796730465264\n",
      "Train Loss 1836: 21.59329613777986\n",
      "Train Loss 1837: 21.592795677970845\n",
      "Train Loss 1838: 21.592295245629565\n",
      "Train Loss 1839: 21.59179488300999\n",
      "Train Loss 1840: 21.591294665848324\n",
      "Train Loss 1841: 21.590794685897972\n",
      "Train Loss 1842: 21.590294785114914\n",
      "Train Loss 1843: 21.589794942327764\n",
      "Train Loss 1844: 21.58929520432382\n",
      "Train Loss 1845: 21.588795624293383\n",
      "Train Loss 1846: 21.588296436077606\n",
      "Train Loss 1847: 21.587797568722593\n",
      "Train Loss 1848: 21.587298864534503\n",
      "Train Loss 1849: 21.58680015404374\n",
      "Train Loss 1850: 21.586301738515047\n",
      "Train Loss 1851: 21.585803466743528\n",
      "Train Loss 1852: 21.585305334571114\n",
      "Train Loss 1853: 21.584807424591453\n",
      "Train Loss 1854: 21.58430966827623\n",
      "Train Loss 1855: 21.58381201680913\n",
      "Train Loss 1856: 21.58331441385543\n",
      "Train Loss 1857: 21.582816823379098\n",
      "Train Loss 1858: 21.582319288999052\n",
      "Train Loss 1859: 21.581821920804526\n",
      "Train Loss 1860: 21.58132470877248\n",
      "Train Loss 1861: 21.580827615749236\n",
      "Train Loss 1862: 21.5803307288258\n",
      "Train Loss 1863: 21.579833916963864\n",
      "Train Loss 1864: 21.579337332582597\n",
      "Train Loss 1865: 21.57884081078676\n",
      "Train Loss 1866: 21.57834444906389\n",
      "Train Loss 1867: 21.577848369783982\n",
      "Train Loss 1868: 21.577352528093687\n",
      "Train Loss 1869: 21.57685682760261\n",
      "Train Loss 1870: 21.576361261791686\n",
      "Train Loss 1871: 21.575865942380833\n",
      "Train Loss 1872: 21.57537078515774\n",
      "Train Loss 1873: 21.574875820989\n",
      "Train Loss 1874: 21.574381108059164\n",
      "Train Loss 1875: 21.573886540236266\n",
      "Train Loss 1876: 21.573392146344272\n",
      "Train Loss 1877: 21.57289790996285\n",
      "Train Loss 1878: 21.572403734000925\n",
      "Train Loss 1879: 21.57190961870235\n",
      "Train Loss 1880: 21.571415660389718\n",
      "Train Loss 1881: 21.57092181103358\n",
      "Train Loss 1882: 21.570428337148446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 1883: 21.56993504492904\n",
      "Train Loss 1884: 21.569441954706885\n",
      "Train Loss 1885: 21.568949075565065\n",
      "Train Loss 1886: 21.568456481609466\n",
      "Train Loss 1887: 21.567964060785513\n",
      "Train Loss 1888: 21.567471810091057\n",
      "Train Loss 1889: 21.566979707270985\n",
      "Train Loss 1890: 21.56648772578098\n",
      "Train Loss 1891: 21.56599582040019\n",
      "Train Loss 1892: 21.565504059812827\n",
      "Train Loss 1893: 21.5650125402244\n",
      "Train Loss 1894: 21.564521285808702\n",
      "Train Loss 1895: 21.564030152125444\n",
      "Train Loss 1896: 21.563539055234116\n",
      "Train Loss 1897: 21.56304812339146\n",
      "Train Loss 1898: 21.562557418847774\n",
      "Train Loss 1899: 21.562067144732584\n",
      "Train Loss 1900: 21.56157692902925\n",
      "Train Loss 1901: 21.561086820008143\n",
      "Train Loss 1902: 21.560596965436332\n",
      "Train Loss 1903: 21.560107109657377\n",
      "Train Loss 1904: 21.559617165106424\n",
      "Train Loss 1905: 21.559127312209966\n",
      "Train Loss 1906: 21.55863771016583\n",
      "Train Loss 1907: 21.558148258170252\n",
      "Train Loss 1908: 21.557658853263764\n",
      "Train Loss 1909: 21.557169731339425\n",
      "Train Loss 1910: 21.556680592250153\n",
      "Train Loss 1911: 21.55619128579532\n",
      "Train Loss 1912: 21.555702074234695\n",
      "Train Loss 1913: 21.555212857369714\n",
      "Train Loss 1914: 21.554723750129178\n",
      "Train Loss 1915: 21.55423474019199\n",
      "Train Loss 1916: 21.553745890271856\n",
      "Train Loss 1917: 21.55325712098223\n",
      "Train Loss 1918: 21.552768401802165\n",
      "Train Loss 1919: 21.55227987093342\n",
      "Train Loss 1920: 21.55179148975875\n",
      "Train Loss 1921: 21.551303306041014\n",
      "Train Loss 1922: 21.550815224874963\n",
      "Train Loss 1923: 21.550327233506778\n",
      "Train Loss 1924: 21.549839294632047\n",
      "Train Loss 1925: 21.549351493964213\n",
      "Train Loss 1926: 21.548864178635693\n",
      "Train Loss 1927: 21.54837705465261\n",
      "Train Loss 1928: 21.547890014352742\n",
      "Train Loss 1929: 21.54740318005009\n",
      "Train Loss 1930: 21.54691626546126\n",
      "Train Loss 1931: 21.546429388112102\n",
      "Train Loss 1932: 21.545942662876115\n",
      "Train Loss 1933: 21.545456082995706\n",
      "Train Loss 1934: 21.544969620878796\n",
      "Train Loss 1935: 21.54448319972141\n",
      "Train Loss 1936: 21.543996970610124\n",
      "Train Loss 1937: 21.543510896313848\n",
      "Train Loss 1938: 21.543025030369883\n",
      "Train Loss 1939: 21.542539522408763\n",
      "Train Loss 1940: 21.54205473599033\n",
      "Train Loss 1941: 21.54157007248422\n",
      "Train Loss 1942: 21.541085529627665\n",
      "Train Loss 1943: 21.54060103480778\n",
      "Train Loss 1944: 21.540116573041203\n",
      "Train Loss 1945: 21.53963240794816\n",
      "Train Loss 1946: 21.539148381353886\n",
      "Train Loss 1947: 21.538664492578686\n",
      "Train Loss 1948: 21.538180720519154\n",
      "Train Loss 1949: 21.537696957611296\n",
      "Train Loss 1950: 21.5372131932783\n",
      "Train Loss 1951: 21.536729640672124\n",
      "Train Loss 1952: 21.536246252828132\n",
      "Train Loss 1953: 21.535763056055643\n",
      "Train Loss 1954: 21.535280012909027\n",
      "Train Loss 1955: 21.53479712326448\n",
      "Train Loss 1956: 21.534314306238414\n",
      "Train Loss 1957: 21.53383149177893\n",
      "Train Loss 1958: 21.533348748688596\n",
      "Train Loss 1959: 21.532866119123817\n",
      "Train Loss 1960: 21.5323836741126\n",
      "Train Loss 1961: 21.531901463186014\n",
      "Train Loss 1962: 21.531419592657553\n",
      "Train Loss 1963: 21.530937882023036\n",
      "Train Loss 1964: 21.530456271864395\n",
      "Train Loss 1965: 21.529974652953694\n",
      "Train Loss 1966: 21.529493098721787\n",
      "Train Loss 1967: 21.52901181217595\n",
      "Train Loss 1968: 21.528530621396307\n",
      "Train Loss 1969: 21.52804955148577\n",
      "Train Loss 1970: 21.52756862135844\n",
      "Train Loss 1971: 21.527087865192446\n",
      "Train Loss 1972: 21.5266073933014\n",
      "Train Loss 1973: 21.526127257465042\n",
      "Train Loss 1974: 21.52564780140961\n",
      "Train Loss 1975: 21.52516849342922\n",
      "Train Loss 1976: 21.52468939663615\n",
      "Train Loss 1977: 21.52421057904818\n",
      "Train Loss 1978: 21.523732010779828\n",
      "Train Loss 1979: 21.523253688279866\n",
      "Train Loss 1980: 21.522775497711496\n",
      "Train Loss 1981: 21.522297450097163\n",
      "Train Loss 1982: 21.521819626772\n",
      "Train Loss 1983: 21.52134202770541\n",
      "Train Loss 1984: 21.52086458230318\n",
      "Train Loss 1985: 21.520387344035917\n",
      "Train Loss 1986: 21.51991039917745\n",
      "Train Loss 1987: 21.519433533575217\n",
      "Train Loss 1988: 21.518956705481486\n",
      "Train Loss 1989: 21.518480142389173\n",
      "Train Loss 1990: 21.518003761089673\n",
      "Train Loss 1991: 21.51752765922286\n",
      "Train Loss 1992: 21.51705169615997\n",
      "Train Loss 1993: 21.51657584503244\n",
      "Train Loss 1994: 21.516100132771996\n",
      "Train Loss 1995: 21.515624546802737\n",
      "Train Loss 1996: 21.51514904165083\n",
      "Train Loss 1997: 21.514673634322296\n",
      "Train Loss 1998: 21.51419835184943\n",
      "Train Loss 1999: 21.513723130297308\n",
      "Train Loss 2000: 21.513247969142764\n",
      "Train Loss 2001: 21.512772937020138\n",
      "Train Loss 2002: 21.512297981935205\n",
      "Train Loss 2003: 21.511823182878956\n",
      "Train Loss 2004: 21.511348511675692\n",
      "Train Loss 2005: 21.510873978043495\n",
      "Train Loss 2006: 21.51039954630924\n",
      "Train Loss 2007: 21.509925045254867\n",
      "Train Loss 2008: 21.509450630793292\n",
      "Train Loss 2009: 21.50897633165442\n",
      "Train Loss 2010: 21.50850217693318\n",
      "Train Loss 2011: 21.508028264530207\n",
      "Train Loss 2012: 21.50755430059133\n",
      "Train Loss 2013: 21.507080421163003\n",
      "Train Loss 2014: 21.50660686211232\n",
      "Train Loss 2015: 21.50613362915823\n",
      "Train Loss 2016: 21.50566052087571\n",
      "Train Loss 2017: 21.505187477824272\n",
      "Train Loss 2018: 21.504714317574155\n",
      "Train Loss 2019: 21.504241257486406\n",
      "Train Loss 2020: 21.503768373834436\n",
      "Train Loss 2021: 21.5032957809337\n",
      "Train Loss 2022: 21.502823260104066\n",
      "Train Loss 2023: 21.50235074060786\n",
      "Train Loss 2024: 21.50187829356756\n",
      "Train Loss 2025: 21.501406005338357\n",
      "Train Loss 2026: 21.500933840209157\n",
      "Train Loss 2027: 21.50046179616131\n",
      "Train Loss 2028: 21.499989900740214\n",
      "Train Loss 2029: 21.49951809773078\n",
      "Train Loss 2030: 21.499046405119838\n",
      "Train Loss 2031: 21.49857484169774\n",
      "Train Loss 2032: 21.498103382979988\n",
      "Train Loss 2033: 21.49763198147855\n",
      "Train Loss 2034: 21.497160661824996\n",
      "Train Loss 2035: 21.49668939384559\n",
      "Train Loss 2036: 21.49621825674003\n",
      "Train Loss 2037: 21.49574722987502\n",
      "Train Loss 2038: 21.495276418708766\n",
      "Train Loss 2039: 21.494805816907334\n",
      "Train Loss 2040: 21.494335308736837\n",
      "Train Loss 2041: 21.493864924289895\n",
      "Train Loss 2042: 21.4933946419952\n",
      "Train Loss 2043: 21.492924535533245\n",
      "Train Loss 2044: 21.492454519254487\n",
      "Train Loss 2045: 21.49198461062901\n",
      "Train Loss 2046: 21.491514786034568\n",
      "Train Loss 2047: 21.491045129132033\n",
      "Train Loss 2048: 21.49057542485708\n",
      "Train Loss 2049: 21.49010591422173\n",
      "Train Loss 2050: 21.489636491473288\n",
      "Train Loss 2051: 21.489167109125717\n",
      "Train Loss 2052: 21.488697831201\n",
      "Train Loss 2053: 21.48822863369866\n",
      "Train Loss 2054: 21.487759567467613\n",
      "Train Loss 2055: 21.487290648395614\n",
      "Train Loss 2056: 21.486821831510234\n",
      "Train Loss 2057: 21.48635310574117\n",
      "Train Loss 2058: 21.48588439192939\n",
      "Train Loss 2059: 21.485415771586023\n",
      "Train Loss 2060: 21.48494721215089\n",
      "Train Loss 2061: 21.48447876758705\n",
      "Train Loss 2062: 21.484010420413824\n",
      "Train Loss 2063: 21.48354219591943\n",
      "Train Loss 2064: 21.48307410923008\n",
      "Train Loss 2065: 21.48260614626516\n",
      "Train Loss 2066: 21.482138275686125\n",
      "Train Loss 2067: 21.48167040186815\n",
      "Train Loss 2068: 21.481202466671146\n",
      "Train Loss 2069: 21.48073463969958\n",
      "Train Loss 2070: 21.480266910520054\n",
      "Train Loss 2071: 21.479799201996464\n",
      "Train Loss 2072: 21.47933153368922\n",
      "Train Loss 2073: 21.478863846068997\n",
      "Train Loss 2074: 21.47839614715365\n",
      "Train Loss 2075: 21.477928409199393\n",
      "Train Loss 2076: 21.477460760793562\n",
      "Train Loss 2077: 21.476993207532786\n",
      "Train Loss 2078: 21.47652573376136\n",
      "Train Loss 2079: 21.47605848186379\n",
      "Train Loss 2080: 21.47559131333198\n",
      "Train Loss 2081: 21.47512420197086\n",
      "Train Loss 2082: 21.474657235107816\n",
      "Train Loss 2083: 21.47419034304894\n",
      "Train Loss 2084: 21.473723453441494\n",
      "Train Loss 2085: 21.47325648996413\n",
      "Train Loss 2086: 21.472789643632392\n",
      "Train Loss 2087: 21.472322907881544\n",
      "Train Loss 2088: 21.47185634164867\n",
      "Train Loss 2089: 21.471389943378792\n",
      "Train Loss 2090: 21.470923591443206\n",
      "Train Loss 2091: 21.470457524689103\n",
      "Train Loss 2092: 21.469991622385237\n",
      "Train Loss 2093: 21.46952581867704\n",
      "Train Loss 2094: 21.469060072466522\n",
      "Train Loss 2095: 21.468594393724715\n",
      "Train Loss 2096: 21.468128859966946\n",
      "Train Loss 2097: 21.467663559339417\n",
      "Train Loss 2098: 21.467198409161618\n",
      "Train Loss 2099: 21.46673341696667\n",
      "Train Loss 2100: 21.46626854596707\n",
      "Train Loss 2101: 21.46580376792903\n",
      "Train Loss 2102: 21.46533904732291\n",
      "Train Loss 2103: 21.464874417875624\n",
      "Train Loss 2104: 21.46440983128617\n",
      "Train Loss 2105: 21.463945234488424\n",
      "Train Loss 2106: 21.463480747402727\n",
      "Train Loss 2107: 21.46301632749819\n",
      "Train Loss 2108: 21.462551992356527\n",
      "Train Loss 2109: 21.462087758846177\n",
      "Train Loss 2110: 21.46162363255083\n",
      "Train Loss 2111: 21.46115961727139\n",
      "Train Loss 2112: 21.460695824494714\n",
      "Train Loss 2113: 21.460232260653846\n",
      "Train Loss 2114: 21.45976909210867\n",
      "Train Loss 2115: 21.45930608485957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 2116: 21.458843188820655\n",
      "Train Loss 2117: 21.45838039499253\n",
      "Train Loss 2118: 21.457917859616476\n",
      "Train Loss 2119: 21.457455441864983\n",
      "Train Loss 2120: 21.456993121736545\n",
      "Train Loss 2121: 21.45653074135858\n",
      "Train Loss 2122: 21.456068484709416\n",
      "Train Loss 2123: 21.455606334195952\n",
      "Train Loss 2124: 21.45514426632256\n",
      "Train Loss 2125: 21.454682273710105\n",
      "Train Loss 2126: 21.4542204235663\n",
      "Train Loss 2127: 21.453758709561686\n",
      "Train Loss 2128: 21.4532970751173\n",
      "Train Loss 2129: 21.452835541149565\n",
      "Train Loss 2130: 21.452374070333303\n",
      "Train Loss 2131: 21.45191257710802\n",
      "Train Loss 2132: 21.451451053769222\n",
      "Train Loss 2133: 21.45098959965373\n",
      "Train Loss 2134: 21.450528234912326\n",
      "Train Loss 2135: 21.450066926453573\n",
      "Train Loss 2136: 21.449605598275124\n",
      "Train Loss 2137: 21.449144333500364\n",
      "Train Loss 2138: 21.448683100288513\n",
      "Train Loss 2139: 21.448221963994698\n",
      "Train Loss 2140: 21.447760831890278\n",
      "Train Loss 2141: 21.447299725427662\n",
      "Train Loss 2142: 21.446838682721435\n",
      "Train Loss 2143: 21.44637776538381\n",
      "Train Loss 2144: 21.445916953593123\n",
      "Train Loss 2145: 21.445456234322823\n",
      "Train Loss 2146: 21.444995528546315\n",
      "Train Loss 2147: 21.444534904805963\n",
      "Train Loss 2148: 21.444074410336288\n",
      "Train Loss 2149: 21.443614055588732\n",
      "Train Loss 2150: 21.44315369066066\n",
      "Train Loss 2151: 21.442693420751866\n",
      "Train Loss 2152: 21.442233263703827\n",
      "Train Loss 2153: 21.441773373519244\n",
      "Train Loss 2154: 21.441313610787176\n",
      "Train Loss 2155: 21.440853854955634\n",
      "Train Loss 2156: 21.440394185476134\n",
      "Train Loss 2157: 21.439934451822054\n",
      "Train Loss 2158: 21.43947472363987\n",
      "Train Loss 2159: 21.439015078064877\n",
      "Train Loss 2160: 21.438555624620157\n",
      "Train Loss 2161: 21.43809626773048\n",
      "Train Loss 2162: 21.437637034165068\n",
      "Train Loss 2163: 21.437177845537246\n",
      "Train Loss 2164: 21.436718702312472\n",
      "Train Loss 2165: 21.436259647873502\n",
      "Train Loss 2166: 21.435800677756614\n",
      "Train Loss 2167: 21.435341753407915\n",
      "Train Loss 2168: 21.43488283838744\n",
      "Train Loss 2169: 21.43442402656373\n",
      "Train Loss 2170: 21.433965290936364\n",
      "Train Loss 2171: 21.43350662427098\n",
      "Train Loss 2172: 21.433048058196132\n",
      "Train Loss 2173: 21.432589680290423\n",
      "Train Loss 2174: 21.43213147225542\n",
      "Train Loss 2175: 21.431673466039385\n",
      "Train Loss 2176: 21.431215529941344\n",
      "Train Loss 2177: 21.430757698508994\n",
      "Train Loss 2178: 21.430299969665796\n",
      "Train Loss 2179: 21.42984230210634\n",
      "Train Loss 2180: 21.429384650371397\n",
      "Train Loss 2181: 21.428927053279\n",
      "Train Loss 2182: 21.428469518161297\n",
      "Train Loss 2183: 21.42801207698196\n",
      "Train Loss 2184: 21.427554737525448\n",
      "Train Loss 2185: 21.427097480346326\n",
      "Train Loss 2186: 21.426640258358507\n",
      "Train Loss 2187: 21.426183064737607\n",
      "Train Loss 2188: 21.425725939285932\n",
      "Train Loss 2189: 21.425268934196673\n",
      "Train Loss 2190: 21.424812145646857\n",
      "Train Loss 2191: 21.42435545256698\n",
      "Train Loss 2192: 21.423898869555693\n",
      "Train Loss 2193: 21.423442470192548\n",
      "Train Loss 2194: 21.422986168103503\n",
      "Train Loss 2195: 21.422529949896074\n",
      "Train Loss 2196: 21.422073805864848\n",
      "Train Loss 2197: 21.421617759979974\n",
      "Train Loss 2198: 21.42116171691302\n",
      "Train Loss 2199: 21.420705722354562\n",
      "Train Loss 2200: 21.420249731473838\n",
      "Train Loss 2201: 21.41979383881104\n",
      "Train Loss 2202: 21.419338035420598\n",
      "Train Loss 2203: 21.418882321798666\n",
      "Train Loss 2204: 21.418426746588562\n",
      "Train Loss 2205: 21.417971352544686\n",
      "Train Loss 2206: 21.41751605556706\n",
      "Train Loss 2207: 21.417060889331918\n",
      "Train Loss 2208: 21.416605824081465\n",
      "Train Loss 2209: 21.416150859733815\n",
      "Train Loss 2210: 21.41569597445835\n",
      "Train Loss 2211: 21.415241133202553\n",
      "Train Loss 2212: 21.41478639256461\n",
      "Train Loss 2213: 21.414331714163335\n",
      "Train Loss 2214: 21.413877077860587\n",
      "Train Loss 2215: 21.413422526550836\n",
      "Train Loss 2216: 21.412968068016564\n",
      "Train Loss 2217: 21.412513696923654\n",
      "Train Loss 2218: 21.41205947174455\n",
      "Train Loss 2219: 21.411605307096412\n",
      "Train Loss 2220: 21.411151231065475\n",
      "Train Loss 2221: 21.410697242847867\n",
      "Train Loss 2222: 21.410243353883164\n",
      "Train Loss 2223: 21.409789551757875\n",
      "Train Loss 2224: 21.409335762852972\n",
      "Train Loss 2225: 21.408882101480355\n",
      "Train Loss 2226: 21.408428570225954\n",
      "Train Loss 2227: 21.407975072241822\n",
      "Train Loss 2228: 21.40752155635397\n",
      "Train Loss 2229: 21.407068106491284\n",
      "Train Loss 2230: 21.406614660660782\n",
      "Train Loss 2231: 21.40616124056746\n",
      "Train Loss 2232: 21.405707800715376\n",
      "Train Loss 2233: 21.405254431296342\n",
      "Train Loss 2234: 21.404801150827737\n",
      "Train Loss 2235: 21.404347949754204\n",
      "Train Loss 2236: 21.403894796157378\n",
      "Train Loss 2237: 21.403441637287077\n",
      "Train Loss 2238: 21.40298857635201\n",
      "Train Loss 2239: 21.402535604292748\n",
      "Train Loss 2240: 21.402082704586643\n",
      "Train Loss 2241: 21.40162988596463\n",
      "Train Loss 2242: 21.401177152391167\n",
      "Train Loss 2243: 21.400724513353932\n",
      "Train Loss 2244: 21.40027202872198\n",
      "Train Loss 2245: 21.39981966147713\n",
      "Train Loss 2246: 21.39936758135134\n",
      "Train Loss 2247: 21.398915606943987\n",
      "Train Loss 2248: 21.398463831569572\n",
      "Train Loss 2249: 21.398012130820078\n",
      "Train Loss 2250: 21.397560476473025\n",
      "Train Loss 2251: 21.397108859180655\n",
      "Train Loss 2252: 21.396657200773408\n",
      "Train Loss 2253: 21.396205541887312\n",
      "Train Loss 2254: 21.39575397638092\n",
      "Train Loss 2255: 21.39530249936105\n",
      "Train Loss 2256: 21.39485111554507\n",
      "Train Loss 2257: 21.394399837499268\n",
      "Train Loss 2258: 21.393948652744747\n",
      "Train Loss 2259: 21.393497549073327\n",
      "Train Loss 2260: 21.393046509900056\n",
      "Train Loss 2261: 21.39259559554528\n",
      "Train Loss 2262: 21.392144773108303\n",
      "Train Loss 2263: 21.391693990165283\n",
      "Train Loss 2264: 21.391243224382354\n",
      "Train Loss 2265: 21.390792551494677\n",
      "Train Loss 2266: 21.390341969561405\n",
      "Train Loss 2267: 21.38989142840091\n",
      "Train Loss 2268: 21.389440948520317\n",
      "Train Loss 2269: 21.38899052468289\n",
      "Train Loss 2270: 21.388540226872294\n",
      "Train Loss 2271: 21.388089823922556\n",
      "Train Loss 2272: 21.387639482868046\n",
      "Train Loss 2273: 21.38718914906062\n",
      "Train Loss 2274: 21.386738854103935\n",
      "Train Loss 2275: 21.386288421188755\n",
      "Train Loss 2276: 21.385838058244296\n",
      "Train Loss 2277: 21.385387763381534\n",
      "Train Loss 2278: 21.384937495798066\n",
      "Train Loss 2279: 21.384487310718917\n",
      "Train Loss 2280: 21.384037188242548\n",
      "Train Loss 2281: 21.383587153301306\n",
      "Train Loss 2282: 21.38313714679328\n",
      "Train Loss 2283: 21.38268712533381\n",
      "Train Loss 2284: 21.38223719599504\n",
      "Train Loss 2285: 21.381787378607427\n",
      "Train Loss 2286: 21.38133765108627\n",
      "Train Loss 2287: 21.380888003079686\n",
      "Train Loss 2288: 21.38043832576016\n",
      "Train Loss 2289: 21.379988604030704\n",
      "Train Loss 2290: 21.379538974938406\n",
      "Train Loss 2291: 21.379089419760298\n",
      "Train Loss 2292: 21.378639894572878\n",
      "Train Loss 2293: 21.37819044424773\n",
      "Train Loss 2294: 21.377741116126064\n",
      "Train Loss 2295: 21.37729190393266\n",
      "Train Loss 2296: 21.376842739717773\n",
      "Train Loss 2297: 21.3763936647103\n",
      "Train Loss 2298: 21.375944699336276\n",
      "Train Loss 2299: 21.37549585319157\n",
      "Train Loss 2300: 21.375047098293372\n",
      "Train Loss 2301: 21.374598424144498\n",
      "Train Loss 2302: 21.374149764835845\n",
      "Train Loss 2303: 21.37370115940834\n",
      "Train Loss 2304: 21.373252639801027\n",
      "Train Loss 2305: 21.372804186577948\n",
      "Train Loss 2306: 21.372355796599734\n",
      "Train Loss 2307: 21.37190744841812\n",
      "Train Loss 2308: 21.37145919103604\n",
      "Train Loss 2309: 21.37101102438164\n",
      "Train Loss 2310: 21.370562948382926\n",
      "Train Loss 2311: 21.370114943123262\n",
      "Train Loss 2312: 21.36966706245466\n",
      "Train Loss 2313: 21.369219256474295\n",
      "Train Loss 2314: 21.368771507108537\n",
      "Train Loss 2315: 21.36832381759851\n",
      "Train Loss 2316: 21.36787617754122\n",
      "Train Loss 2317: 21.36742859854502\n",
      "Train Loss 2318: 21.366981090654345\n",
      "Train Loss 2319: 21.366533709922315\n",
      "Train Loss 2320: 21.36608650734898\n",
      "Train Loss 2321: 21.3656393389509\n",
      "Train Loss 2322: 21.365192221762875\n",
      "Train Loss 2323: 21.364745222849933\n",
      "Train Loss 2324: 21.364298409436003\n",
      "Train Loss 2325: 21.36385168466514\n",
      "Train Loss 2326: 21.363405043948163\n",
      "Train Loss 2327: 21.362958473867266\n",
      "Train Loss 2328: 21.36251189729968\n",
      "Train Loss 2329: 21.36206529263523\n",
      "Train Loss 2330: 21.36161878026632\n",
      "Train Loss 2331: 21.36117234938266\n",
      "Train Loss 2332: 21.36072602039293\n",
      "Train Loss 2333: 21.36027978929194\n",
      "Train Loss 2334: 21.359833646660643\n",
      "Train Loss 2335: 21.359387631645543\n",
      "Train Loss 2336: 21.35894169887024\n",
      "Train Loss 2337: 21.358495844223278\n",
      "Train Loss 2338: 21.358050052518315\n",
      "Train Loss 2339: 21.35760432804242\n",
      "Train Loss 2340: 21.35715868815492\n",
      "Train Loss 2341: 21.356713119270996\n",
      "Train Loss 2342: 21.356267597865553\n",
      "Train Loss 2343: 21.355822148381314\n",
      "Train Loss 2344: 21.35537677106549\n",
      "Train Loss 2345: 21.35493148076653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 2346: 21.35448627741701\n",
      "Train Loss 2347: 21.354041142850082\n",
      "Train Loss 2348: 21.353595962119893\n",
      "Train Loss 2349: 21.353150844599067\n",
      "Train Loss 2350: 21.3527059384668\n",
      "Train Loss 2351: 21.35226126012676\n",
      "Train Loss 2352: 21.35181660588048\n",
      "Train Loss 2353: 21.351371984109537\n",
      "Train Loss 2354: 21.35092743335715\n",
      "Train Loss 2355: 21.350482993601414\n",
      "Train Loss 2356: 21.35003880207494\n",
      "Train Loss 2357: 21.34959479837471\n",
      "Train Loss 2358: 21.3491508310551\n",
      "Train Loss 2359: 21.34870688568466\n",
      "Train Loss 2360: 21.348262988180245\n",
      "Train Loss 2361: 21.347819167126033\n",
      "Train Loss 2362: 21.347375324372166\n",
      "Train Loss 2363: 21.346931698544115\n",
      "Train Loss 2364: 21.346488324845634\n",
      "Train Loss 2365: 21.346045113497173\n",
      "Train Loss 2366: 21.34560214003319\n",
      "Train Loss 2367: 21.34515930549302\n",
      "Train Loss 2368: 21.344716554534077\n",
      "Train Loss 2369: 21.344273834883353\n",
      "Train Loss 2370: 21.3438311129498\n",
      "Train Loss 2371: 21.343388454000447\n",
      "Train Loss 2372: 21.342945852289567\n",
      "Train Loss 2373: 21.34250328487564\n",
      "Train Loss 2374: 21.342060790182284\n",
      "Train Loss 2375: 21.341618356449764\n",
      "Train Loss 2376: 21.341175974870648\n",
      "Train Loss 2377: 21.340733556313268\n",
      "Train Loss 2378: 21.340291061510968\n",
      "Train Loss 2379: 21.33984861236451\n",
      "Train Loss 2380: 21.339406317400353\n",
      "Train Loss 2381: 21.338964112901692\n",
      "Train Loss 2382: 21.338521932280887\n",
      "Train Loss 2383: 21.33807983380923\n",
      "Train Loss 2384: 21.337637796903515\n",
      "Train Loss 2385: 21.33719581172489\n",
      "Train Loss 2386: 21.336753912233487\n",
      "Train Loss 2387: 21.336312107622753\n",
      "Train Loss 2388: 21.335870404678833\n",
      "Train Loss 2389: 21.335428860680363\n",
      "Train Loss 2390: 21.334987372786777\n",
      "Train Loss 2391: 21.334545946847605\n",
      "Train Loss 2392: 21.334104589032602\n",
      "Train Loss 2393: 21.333663310905415\n",
      "Train Loss 2394: 21.333222093246476\n",
      "Train Loss 2395: 21.332780954941807\n",
      "Train Loss 2396: 21.332340044158062\n",
      "Train Loss 2397: 21.33189919976814\n",
      "Train Loss 2398: 21.331458435616906\n",
      "Train Loss 2399: 21.331017776006227\n",
      "Train Loss 2400: 21.330577176207523\n",
      "Train Loss 2401: 21.33013659545095\n",
      "Train Loss 2402: 21.329696047944104\n",
      "Train Loss 2403: 21.32925558586949\n",
      "Train Loss 2404: 21.32881520957605\n",
      "Train Loss 2405: 21.328374988876156\n",
      "Train Loss 2406: 21.327934952664986\n",
      "Train Loss 2407: 21.327494943955784\n",
      "Train Loss 2408: 21.32705495820884\n",
      "Train Loss 2409: 21.326614974592992\n",
      "Train Loss 2410: 21.326175003451237\n",
      "Train Loss 2411: 21.325735053766124\n",
      "Train Loss 2412: 21.325295167925496\n",
      "Train Loss 2413: 21.324855395791886\n",
      "Train Loss 2414: 21.324415666276945\n",
      "Train Loss 2415: 21.32397593790816\n",
      "Train Loss 2416: 21.323536288122718\n",
      "Train Loss 2417: 21.3230967163813\n",
      "Train Loss 2418: 21.322657195442623\n",
      "Train Loss 2419: 21.32221774693409\n",
      "Train Loss 2420: 21.32177835159655\n",
      "Train Loss 2421: 21.321339011177685\n",
      "Train Loss 2422: 21.320899677962014\n",
      "Train Loss 2423: 21.320460419910308\n",
      "Train Loss 2424: 21.320021322285232\n",
      "Train Loss 2425: 21.31958230240098\n",
      "Train Loss 2426: 21.319143360194367\n",
      "Train Loss 2427: 21.318704493006162\n",
      "Train Loss 2428: 21.318265664949962\n",
      "Train Loss 2429: 21.317826875639852\n",
      "Train Loss 2430: 21.317388093113617\n",
      "Train Loss 2431: 21.31694937980291\n",
      "Train Loss 2432: 21.31651071723143\n",
      "Train Loss 2433: 21.316072127451537\n",
      "Train Loss 2434: 21.315633603344565\n",
      "Train Loss 2435: 21.315195153523337\n",
      "Train Loss 2436: 21.314756757135125\n",
      "Train Loss 2437: 21.314318423693802\n",
      "Train Loss 2438: 21.313880117231985\n",
      "Train Loss 2439: 21.31344184176031\n",
      "Train Loss 2440: 21.313003612730107\n",
      "Train Loss 2441: 21.312565403248914\n",
      "Train Loss 2442: 21.312127244323946\n",
      "Train Loss 2443: 21.31168919604352\n",
      "Train Loss 2444: 21.31125116369748\n",
      "Train Loss 2445: 21.310813164939017\n",
      "Train Loss 2446: 21.31037524348338\n",
      "Train Loss 2447: 21.309937382342934\n",
      "Train Loss 2448: 21.30949959779787\n",
      "Train Loss 2449: 21.30906188046865\n",
      "Train Loss 2450: 21.308624282900574\n",
      "Train Loss 2451: 21.308186761668313\n",
      "Train Loss 2452: 21.3077493102942\n",
      "Train Loss 2453: 21.30731188534976\n",
      "Train Loss 2454: 21.306874497646575\n",
      "Train Loss 2455: 21.306437158116335\n",
      "Train Loss 2456: 21.30599983332672\n",
      "Train Loss 2457: 21.305562597683096\n",
      "Train Loss 2458: 21.305125362746338\n",
      "Train Loss 2459: 21.304688131892892\n",
      "Train Loss 2460: 21.304250988489095\n",
      "Train Loss 2461: 21.303813945049264\n",
      "Train Loss 2462: 21.303376943743668\n",
      "Train Loss 2463: 21.302940017060298\n",
      "Train Loss 2464: 21.302503172469272\n",
      "Train Loss 2465: 21.302066403141737\n",
      "Train Loss 2466: 21.301629697826954\n",
      "Train Loss 2467: 21.30119305350347\n",
      "Train Loss 2468: 21.30075647044711\n",
      "Train Loss 2469: 21.30031996182428\n",
      "Train Loss 2470: 21.299883526043033\n",
      "Train Loss 2471: 21.29944716501792\n",
      "Train Loss 2472: 21.299010866382616\n",
      "Train Loss 2473: 21.298574547597102\n",
      "Train Loss 2474: 21.29813826025146\n",
      "Train Loss 2475: 21.29770203118462\n",
      "Train Loss 2476: 21.297265896359303\n",
      "Train Loss 2477: 21.2968299671911\n",
      "Train Loss 2478: 21.29639413490771\n",
      "Train Loss 2479: 21.29595836569983\n",
      "Train Loss 2480: 21.29552267860396\n",
      "Train Loss 2481: 21.295087065005927\n",
      "Train Loss 2482: 21.29465152024177\n",
      "Train Loss 2483: 21.294216034676786\n",
      "Train Loss 2484: 21.293780613066392\n",
      "Train Loss 2485: 21.293345253716936\n",
      "Train Loss 2486: 21.292910140024954\n",
      "Train Loss 2487: 21.292475056938788\n",
      "Train Loss 2488: 21.292040007240416\n",
      "Train Loss 2489: 21.291605038122636\n",
      "Train Loss 2490: 21.291170176663805\n",
      "Train Loss 2491: 21.29073543184567\n",
      "Train Loss 2492: 21.290300736600752\n",
      "Train Loss 2493: 21.28986605828603\n",
      "Train Loss 2494: 21.28943143248202\n",
      "Train Loss 2495: 21.288996853269555\n",
      "Train Loss 2496: 21.28856236128411\n",
      "Train Loss 2497: 21.288127988702296\n",
      "Train Loss 2498: 21.287693677788837\n",
      "Train Loss 2499: 21.287259673077422\n",
      "Train Loss 2500: 21.286825739590842\n",
      "Train Loss 2501: 21.286391872044398\n",
      "Train Loss 2502: 21.28595806541321\n",
      "Train Loss 2503: 21.28552432984443\n",
      "Train Loss 2504: 21.285090665281047\n",
      "Train Loss 2505: 21.28465707166595\n",
      "Train Loss 2506: 21.284223548941963\n",
      "Train Loss 2507: 21.2837900970518\n",
      "Train Loss 2508: 21.2833567091623\n",
      "Train Loss 2509: 21.28292341610271\n",
      "Train Loss 2510: 21.28249026131807\n",
      "Train Loss 2511: 21.282057139475846\n",
      "Train Loss 2512: 21.28162401199461\n",
      "Train Loss 2513: 21.281190893962375\n",
      "Train Loss 2514: 21.280757843987264\n",
      "Train Loss 2515: 21.280324864458557\n",
      "Train Loss 2516: 21.279891937742846\n",
      "Train Loss 2517: 21.279459033649914\n",
      "Train Loss 2518: 21.279026160765486\n",
      "Train Loss 2519: 21.278593340573632\n",
      "Train Loss 2520: 21.278160587246106\n",
      "Train Loss 2521: 21.277727904633387\n",
      "Train Loss 2522: 21.277295371154167\n",
      "Train Loss 2523: 21.276863065080484\n",
      "Train Loss 2524: 21.276430792965186\n",
      "Train Loss 2525: 21.27599857499201\n",
      "Train Loss 2526: 21.27556642427982\n",
      "Train Loss 2527: 21.275134348192424\n",
      "Train Loss 2528: 21.27470239070356\n",
      "Train Loss 2529: 21.274270451844007\n",
      "Train Loss 2530: 21.273838552514064\n",
      "Train Loss 2531: 21.273406714854108\n",
      "Train Loss 2532: 21.272974945339552\n",
      "Train Loss 2533: 21.272543265814758\n",
      "Train Loss 2534: 21.272111631921344\n",
      "Train Loss 2535: 21.27168004852356\n",
      "Train Loss 2536: 21.271248379365844\n",
      "Train Loss 2537: 21.270816784658113\n",
      "Train Loss 2538: 21.270385316483157\n",
      "Train Loss 2539: 21.26995390510237\n",
      "Train Loss 2540: 21.269522558160602\n",
      "Train Loss 2541: 21.269091271795283\n",
      "Train Loss 2542: 21.268660048932656\n",
      "Train Loss 2543: 21.268228875732582\n",
      "Train Loss 2544: 21.267797751438955\n",
      "Train Loss 2545: 21.267366694918515\n",
      "Train Loss 2546: 21.2669357061172\n",
      "Train Loss 2547: 21.26650477323711\n",
      "Train Loss 2548: 21.266073785302616\n",
      "Train Loss 2549: 21.26564287201567\n",
      "Train Loss 2550: 21.265212085949525\n",
      "Train Loss 2551: 21.264781283899893\n",
      "Train Loss 2552: 21.26435055690982\n",
      "Train Loss 2553: 21.263919956951465\n",
      "Train Loss 2554: 21.26348953383539\n",
      "Train Loss 2555: 21.26305915508594\n",
      "Train Loss 2556: 21.26262880166201\n",
      "Train Loss 2557: 21.26219850337646\n",
      "Train Loss 2558: 21.261768255084476\n",
      "Train Loss 2559: 21.26133808298345\n",
      "Train Loss 2560: 21.26090793236844\n",
      "Train Loss 2561: 21.26047784787777\n",
      "Train Loss 2562: 21.260047829458454\n",
      "Train Loss 2563: 21.259617878736023\n",
      "Train Loss 2564: 21.259188003449598\n",
      "Train Loss 2565: 21.258758188010194\n",
      "Train Loss 2566: 21.25832838922246\n",
      "Train Loss 2567: 21.257898667345177\n",
      "Train Loss 2568: 21.257468986627693\n",
      "Train Loss 2569: 21.257039271278487\n",
      "Train Loss 2570: 21.256609589599737\n",
      "Train Loss 2571: 21.256179973494273\n",
      "Train Loss 2572: 21.255750414453978\n",
      "Train Loss 2573: 21.255320833753807\n",
      "Train Loss 2574: 21.254891317717163\n",
      "Train Loss 2575: 21.25446184676388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 2576: 21.25403243857394\n",
      "Train Loss 2577: 21.253603112876075\n",
      "Train Loss 2578: 21.25317384051129\n",
      "Train Loss 2579: 21.25274463474009\n",
      "Train Loss 2580: 21.25231552429058\n",
      "Train Loss 2581: 21.251886462457126\n",
      "Train Loss 2582: 21.251457465595195\n",
      "Train Loss 2583: 21.25102853800465\n",
      "Train Loss 2584: 21.25059969785429\n",
      "Train Loss 2585: 21.250170895255913\n",
      "Train Loss 2586: 21.24974213168529\n",
      "Train Loss 2587: 21.249313427722385\n",
      "Train Loss 2588: 21.248884801179354\n",
      "Train Loss 2589: 21.248456282103557\n",
      "Train Loss 2590: 21.24802781876054\n",
      "Train Loss 2591: 21.247599396032985\n",
      "Train Loss 2592: 21.247171017142108\n",
      "Train Loss 2593: 21.246742686875763\n",
      "Train Loss 2594: 21.246314356194105\n",
      "Train Loss 2595: 21.24588606660549\n",
      "Train Loss 2596: 21.245457723960094\n",
      "Train Loss 2597: 21.24502944183788\n",
      "Train Loss 2598: 21.244601201797465\n",
      "Train Loss 2599: 21.244172997734797\n",
      "Train Loss 2600: 21.243744769578772\n",
      "Train Loss 2601: 21.243316605562526\n",
      "Train Loss 2602: 21.24288850563453\n",
      "Train Loss 2603: 21.24246046974319\n",
      "Train Loss 2604: 21.242032489044313\n",
      "Train Loss 2605: 21.24160456313505\n",
      "Train Loss 2606: 21.24117666085096\n",
      "Train Loss 2607: 21.240748756106697\n",
      "Train Loss 2608: 21.240320901552664\n",
      "Train Loss 2609: 21.23989310171096\n",
      "Train Loss 2610: 21.23946535354766\n",
      "Train Loss 2611: 21.239037648917474\n",
      "Train Loss 2612: 21.238609888380754\n",
      "Train Loss 2613: 21.23818218588916\n",
      "Train Loss 2614: 21.237754517794084\n",
      "Train Loss 2615: 21.23732694810316\n",
      "Train Loss 2616: 21.236899455433157\n",
      "Train Loss 2617: 21.236471952126855\n",
      "Train Loss 2618: 21.23604447940017\n",
      "Train Loss 2619: 21.235617058092757\n",
      "Train Loss 2620: 21.23518967614896\n",
      "Train Loss 2621: 21.234762310351513\n",
      "Train Loss 2622: 21.23433499858728\n",
      "Train Loss 2623: 21.233907712249543\n",
      "Train Loss 2624: 21.233480469702215\n",
      "Train Loss 2625: 21.233053261302963\n",
      "Train Loss 2626: 21.2326261374743\n",
      "Train Loss 2627: 21.23219907202804\n",
      "Train Loss 2628: 21.231772057032934\n",
      "Train Loss 2629: 21.231345097050358\n",
      "Train Loss 2630: 21.2309182267275\n",
      "Train Loss 2631: 21.230491411228854\n",
      "Train Loss 2632: 21.230064642388783\n",
      "Train Loss 2633: 21.229637911874548\n",
      "Train Loss 2634: 21.229211226817867\n",
      "Train Loss 2635: 21.228784573659592\n",
      "Train Loss 2636: 21.22835796813869\n",
      "Train Loss 2637: 21.227931422681834\n",
      "Train Loss 2638: 21.227504919986597\n",
      "Train Loss 2639: 21.22707847923606\n",
      "Train Loss 2640: 21.226652097346516\n",
      "Train Loss 2641: 21.226225772668787\n",
      "Train Loss 2642: 21.225799504664362\n",
      "Train Loss 2643: 21.225373251161162\n",
      "Train Loss 2644: 21.224947046081553\n",
      "Train Loss 2645: 21.224520980256766\n",
      "Train Loss 2646: 21.22409498350126\n",
      "Train Loss 2647: 21.223669116019018\n",
      "Train Loss 2648: 21.22324330591527\n",
      "Train Loss 2649: 21.222817498893267\n",
      "Train Loss 2650: 21.222391706982357\n",
      "Train Loss 2651: 21.22196589797073\n",
      "Train Loss 2652: 21.221540388357226\n",
      "Train Loss 2653: 21.22111491174285\n",
      "Train Loss 2654: 21.220689516870102\n",
      "Train Loss 2655: 21.220264162437562\n",
      "Train Loss 2656: 21.21983885728645\n",
      "Train Loss 2657: 21.219413551849733\n",
      "Train Loss 2658: 21.21898822915243\n",
      "Train Loss 2659: 21.21856297274111\n",
      "Train Loss 2660: 21.218137728440926\n",
      "Train Loss 2661: 21.21771253941637\n",
      "Train Loss 2662: 21.217287362592845\n",
      "Train Loss 2663: 21.216862156559696\n",
      "Train Loss 2664: 21.21643697721625\n",
      "Train Loss 2665: 21.21601185071033\n",
      "Train Loss 2666: 21.21558678202986\n",
      "Train Loss 2667: 21.215161759263342\n",
      "Train Loss 2668: 21.214736864529797\n",
      "Train Loss 2669: 21.214312081652036\n",
      "Train Loss 2670: 21.213887355303278\n",
      "Train Loss 2671: 21.213462661106306\n",
      "Train Loss 2672: 21.213037997532112\n",
      "Train Loss 2673: 21.212613382690844\n",
      "Train Loss 2674: 21.212188826960357\n",
      "Train Loss 2675: 21.211764351705774\n",
      "Train Loss 2676: 21.21134000877779\n",
      "Train Loss 2677: 21.210915694307005\n",
      "Train Loss 2678: 21.21049136141032\n",
      "Train Loss 2679: 21.21006707807034\n",
      "Train Loss 2680: 21.20964281682564\n",
      "Train Loss 2681: 21.20921859773458\n",
      "Train Loss 2682: 21.208794440680684\n",
      "Train Loss 2683: 21.208370352589263\n",
      "Train Loss 2684: 21.207946313828106\n",
      "Train Loss 2685: 21.20752233326236\n",
      "Train Loss 2686: 21.207098415591595\n",
      "Train Loss 2687: 21.20667455582395\n",
      "Train Loss 2688: 21.20625075391304\n",
      "Train Loss 2689: 21.205827009812445\n",
      "Train Loss 2690: 21.20540332661095\n",
      "Train Loss 2691: 21.204979736814778\n",
      "Train Loss 2692: 21.204556228318165\n",
      "Train Loss 2693: 21.204132786034425\n",
      "Train Loss 2694: 21.203709420454118\n",
      "Train Loss 2695: 21.20328608361469\n",
      "Train Loss 2696: 21.202862810879125\n",
      "Train Loss 2697: 21.20243959527406\n",
      "Train Loss 2698: 21.2020164281359\n",
      "Train Loss 2699: 21.201593300365854\n",
      "Train Loss 2700: 21.201170172894322\n",
      "Train Loss 2701: 21.200747055997077\n",
      "Train Loss 2702: 21.20032393102625\n",
      "Train Loss 2703: 21.19990083346094\n",
      "Train Loss 2704: 21.19947777813122\n",
      "Train Loss 2705: 21.199054782987375\n",
      "Train Loss 2706: 21.19863184455951\n",
      "Train Loss 2707: 21.198208981675805\n",
      "Train Loss 2708: 21.197786246408853\n",
      "Train Loss 2709: 21.197363547284716\n",
      "Train Loss 2710: 21.196940892405692\n",
      "Train Loss 2711: 21.196518293768715\n",
      "Train Loss 2712: 21.196095746134855\n",
      "Train Loss 2713: 21.195673243903734\n",
      "Train Loss 2714: 21.19525078854763\n",
      "Train Loss 2715: 21.194828374024198\n",
      "Train Loss 2716: 21.194405884840045\n",
      "Train Loss 2717: 21.193983451763362\n",
      "Train Loss 2718: 21.193561074749095\n",
      "Train Loss 2719: 21.193138766449092\n",
      "Train Loss 2720: 21.19271653619768\n",
      "Train Loss 2721: 21.192294339866415\n",
      "Train Loss 2722: 21.191872165057113\n",
      "Train Loss 2723: 21.191450046058346\n",
      "Train Loss 2724: 21.191027982825126\n",
      "Train Loss 2725: 21.190605974947367\n",
      "Train Loss 2726: 21.190184020509317\n",
      "Train Loss 2727: 21.18976212168304\n",
      "Train Loss 2728: 21.189340278423405\n",
      "Train Loss 2729: 21.188918483470243\n",
      "Train Loss 2730: 21.18849675554217\n",
      "Train Loss 2731: 21.18807510651113\n",
      "Train Loss 2732: 21.187653473321834\n",
      "Train Loss 2733: 21.187231868488887\n",
      "Train Loss 2734: 21.18681033941726\n",
      "Train Loss 2735: 21.18638884706719\n",
      "Train Loss 2736: 21.18596735099829\n",
      "Train Loss 2737: 21.185545888087805\n",
      "Train Loss 2738: 21.18512443793311\n",
      "Train Loss 2739: 21.184702956090504\n",
      "Train Loss 2740: 21.184281522971755\n",
      "Train Loss 2741: 21.18386012734736\n",
      "Train Loss 2742: 21.18343878643972\n",
      "Train Loss 2743: 21.183017500205125\n",
      "Train Loss 2744: 21.182596268599823\n",
      "Train Loss 2745: 21.18217509158003\n",
      "Train Loss 2746: 21.18175396910193\n",
      "Train Loss 2747: 21.18133289430589\n",
      "Train Loss 2748: 21.18091186729226\n",
      "Train Loss 2749: 21.180490967747154\n",
      "Train Loss 2750: 21.18007010796807\n",
      "Train Loss 2751: 21.179649227473384\n",
      "Train Loss 2752: 21.179228382513543\n",
      "Train Loss 2753: 21.178807580519283\n",
      "Train Loss 2754: 21.17838683269089\n",
      "Train Loss 2755: 21.177966136594527\n",
      "Train Loss 2756: 21.177545477849968\n",
      "Train Loss 2757: 21.177124867664777\n",
      "Train Loss 2758: 21.176704294980667\n",
      "Train Loss 2759: 21.1762837732757\n",
      "Train Loss 2760: 21.175863298726615\n",
      "Train Loss 2761: 21.17544284820105\n",
      "Train Loss 2762: 21.17502243672773\n",
      "Train Loss 2763: 21.174602066031852\n",
      "Train Loss 2764: 21.17418174414145\n",
      "Train Loss 2765: 21.173761469663845\n",
      "Train Loss 2766: 21.17334122711418\n",
      "Train Loss 2767: 21.17292102873073\n",
      "Train Loss 2768: 21.172500880055335\n",
      "Train Loss 2769: 21.172080762146315\n",
      "Train Loss 2770: 21.171660674181542\n",
      "Train Loss 2771: 21.171240615910023\n",
      "Train Loss 2772: 21.17082059406558\n",
      "Train Loss 2773: 21.170400611491925\n",
      "Train Loss 2774: 21.169980673390622\n",
      "Train Loss 2775: 21.16956075912544\n",
      "Train Loss 2776: 21.169140898130436\n",
      "Train Loss 2777: 21.168721099842685\n",
      "Train Loss 2778: 21.168301359543868\n",
      "Train Loss 2779: 21.167881625751257\n",
      "Train Loss 2780: 21.16746189484982\n",
      "Train Loss 2781: 21.167042215976394\n",
      "Train Loss 2782: 21.166622581918578\n",
      "Train Loss 2783: 21.166203000846643\n",
      "Train Loss 2784: 21.16578346298356\n",
      "Train Loss 2785: 21.16536397433276\n",
      "Train Loss 2786: 21.164944538840594\n",
      "Train Loss 2787: 21.164525068792557\n",
      "Train Loss 2788: 21.16410565155182\n",
      "Train Loss 2789: 21.16368628707716\n",
      "Train Loss 2790: 21.163266967465287\n",
      "Train Loss 2791: 21.162847653739824\n",
      "Train Loss 2792: 21.162428416973057\n",
      "Train Loss 2793: 21.162009303225126\n",
      "Train Loss 2794: 21.161590234396627\n",
      "Train Loss 2795: 21.161171197536635\n",
      "Train Loss 2796: 21.16075218259498\n",
      "Train Loss 2797: 21.160333219674328\n",
      "Train Loss 2798: 21.159914308734386\n",
      "Train Loss 2799: 21.15949544973483\n",
      "Train Loss 2800: 21.159076642635306\n",
      "Train Loss 2801: 21.1586578604789\n",
      "Train Loss 2802: 21.1582390902027\n",
      "Train Loss 2803: 21.157820371185238\n",
      "Train Loss 2804: 21.157401689175906\n",
      "Train Loss 2805: 21.156983006030316\n",
      "Train Loss 2806: 21.1565643603804\n",
      "Train Loss 2807: 21.15614575370821\n",
      "Train Loss 2808: 21.155727186776623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 2809: 21.155308665287116\n",
      "Train Loss 2810: 21.154890160851185\n",
      "Train Loss 2811: 21.15447170799819\n",
      "Train Loss 2812: 21.15405330668825\n",
      "Train Loss 2813: 21.153634933177607\n",
      "Train Loss 2814: 21.153216540018562\n",
      "Train Loss 2815: 21.15279819842036\n",
      "Train Loss 2816: 21.15237989099411\n",
      "Train Loss 2817: 21.151961566489774\n",
      "Train Loss 2818: 21.15154328022613\n",
      "Train Loss 2819: 21.15112497966446\n",
      "Train Loss 2820: 21.1507067078966\n",
      "Train Loss 2821: 21.150288572855366\n",
      "Train Loss 2822: 21.14987058426012\n",
      "Train Loss 2823: 21.149452646724082\n",
      "Train Loss 2824: 21.149034755409033\n",
      "Train Loss 2825: 21.148616922756503\n",
      "Train Loss 2826: 21.148199127682354\n",
      "Train Loss 2827: 21.147781378113937\n",
      "Train Loss 2828: 21.14736369989941\n",
      "Train Loss 2829: 21.14694611578596\n",
      "Train Loss 2830: 21.146528582077604\n",
      "Train Loss 2831: 21.1461110820274\n",
      "Train Loss 2832: 21.145693586098176\n",
      "Train Loss 2833: 21.145276139121055\n",
      "Train Loss 2834: 21.144858755705712\n",
      "Train Loss 2835: 21.144441485753823\n",
      "Train Loss 2836: 21.1440242469032\n",
      "Train Loss 2837: 21.143607022034235\n",
      "Train Loss 2838: 21.143189841459773\n",
      "Train Loss 2839: 21.142772710874162\n",
      "Train Loss 2840: 21.142355629834455\n",
      "Train Loss 2841: 21.141938619063495\n",
      "Train Loss 2842: 21.141521661387287\n",
      "Train Loss 2843: 21.141104816330568\n",
      "Train Loss 2844: 21.14068808695457\n",
      "Train Loss 2845: 21.140271406986432\n",
      "Train Loss 2846: 21.139854776388262\n",
      "Train Loss 2847: 21.139438196225427\n",
      "Train Loss 2848: 21.139021619946377\n",
      "Train Loss 2849: 21.138605024037446\n",
      "Train Loss 2850: 21.138188494878506\n",
      "Train Loss 2851: 21.1377719547385\n",
      "Train Loss 2852: 21.137355326184107\n",
      "Train Loss 2853: 21.13693874690136\n",
      "Train Loss 2854: 21.136522188099704\n",
      "Train Loss 2855: 21.136105648001923\n",
      "Train Loss 2856: 21.13568916152747\n",
      "Train Loss 2857: 21.135272763462034\n",
      "Train Loss 2858: 21.134856416889733\n",
      "Train Loss 2859: 21.13444011932766\n",
      "Train Loss 2860: 21.134023842697754\n",
      "Train Loss 2861: 21.13360750870062\n",
      "Train Loss 2862: 21.13319109033693\n",
      "Train Loss 2863: 21.132774762198636\n",
      "Train Loss 2864: 21.132358481446122\n",
      "Train Loss 2865: 21.131942227990603\n",
      "Train Loss 2866: 21.13152597200362\n",
      "Train Loss 2867: 21.13110975127442\n",
      "Train Loss 2868: 21.13069359519185\n",
      "Train Loss 2869: 21.130277499247082\n",
      "Train Loss 2870: 21.129861420953027\n",
      "Train Loss 2871: 21.129445361155206\n",
      "Train Loss 2872: 21.129029346805616\n",
      "Train Loss 2873: 21.128613360923747\n",
      "Train Loss 2874: 21.128197412423063\n",
      "Train Loss 2875: 21.12778151348006\n",
      "Train Loss 2876: 21.127365673471708\n",
      "Train Loss 2877: 21.12694988680952\n",
      "Train Loss 2878: 21.126534134973905\n",
      "Train Loss 2879: 21.126118391653694\n",
      "Train Loss 2880: 21.125702704081135\n",
      "Train Loss 2881: 21.125287076046625\n",
      "Train Loss 2882: 21.124871548426526\n",
      "Train Loss 2883: 21.12445606870417\n",
      "Train Loss 2884: 21.124040630389146\n",
      "Train Loss 2885: 21.123625230749596\n",
      "Train Loss 2886: 21.12320990159945\n",
      "Train Loss 2887: 21.12279468490489\n",
      "Train Loss 2888: 21.12237951571121\n",
      "Train Loss 2889: 21.121964393539507\n",
      "Train Loss 2890: 21.12154930817815\n",
      "Train Loss 2891: 21.121134277699294\n",
      "Train Loss 2892: 21.120719266891854\n",
      "Train Loss 2893: 21.120304288139273\n",
      "Train Loss 2894: 21.119889342316544\n",
      "Train Loss 2895: 21.11947442725954\n",
      "Train Loss 2896: 21.11905953911964\n",
      "Train Loss 2897: 21.11864469816415\n",
      "Train Loss 2898: 21.118229904357744\n",
      "Train Loss 2899: 21.117815122132424\n",
      "Train Loss 2900: 21.117400307232717\n",
      "Train Loss 2901: 21.116985455925306\n",
      "Train Loss 2902: 21.116570641113036\n",
      "Train Loss 2903: 21.116155876341598\n",
      "Train Loss 2904: 21.115741142410446\n",
      "Train Loss 2905: 21.115326456847015\n",
      "Train Loss 2906: 21.11491183233461\n",
      "Train Loss 2907: 21.11449716722509\n",
      "Train Loss 2908: 21.114082548780235\n",
      "Train Loss 2909: 21.113667976964884\n",
      "Train Loss 2910: 21.113253430383303\n",
      "Train Loss 2911: 21.112838865821885\n",
      "Train Loss 2912: 21.11242436657319\n",
      "Train Loss 2913: 21.112009944945285\n",
      "Train Loss 2914: 21.111595566296046\n",
      "Train Loss 2915: 21.111181221769794\n",
      "Train Loss 2916: 21.110766941259275\n",
      "Train Loss 2917: 21.11035273082109\n",
      "Train Loss 2918: 21.10993851964942\n",
      "Train Loss 2919: 21.109524343901434\n",
      "Train Loss 2920: 21.10911015265911\n",
      "Train Loss 2921: 21.108695924599242\n",
      "Train Loss 2922: 21.108281684057154\n",
      "Train Loss 2923: 21.10786746663854\n",
      "Train Loss 2924: 21.10745324547495\n",
      "Train Loss 2925: 21.10703906203073\n",
      "Train Loss 2926: 21.106624986017007\n",
      "Train Loss 2927: 21.10621092339611\n",
      "Train Loss 2928: 21.105796898990494\n",
      "Train Loss 2929: 21.10538292033049\n",
      "Train Loss 2930: 21.10496898221172\n",
      "Train Loss 2931: 21.10455505379419\n",
      "Train Loss 2932: 21.104141139117147\n",
      "Train Loss 2933: 21.103727270079574\n",
      "Train Loss 2934: 21.103313445068615\n",
      "Train Loss 2935: 21.10289964876913\n",
      "Train Loss 2936: 21.102485892502187\n",
      "Train Loss 2937: 21.10207217301269\n",
      "Train Loss 2938: 21.101658489056607\n",
      "Train Loss 2939: 21.101244796263366\n",
      "Train Loss 2940: 21.100831137635893\n",
      "Train Loss 2941: 21.10041748840466\n",
      "Train Loss 2942: 21.100003854516657\n",
      "Train Loss 2943: 21.099590248581574\n",
      "Train Loss 2944: 21.099176679545014\n",
      "Train Loss 2945: 21.098763113881947\n",
      "Train Loss 2946: 21.098349592558755\n",
      "Train Loss 2947: 21.097936056807633\n",
      "Train Loss 2948: 21.097522491379134\n",
      "Train Loss 2949: 21.097108864279836\n",
      "Train Loss 2950: 21.096695280545088\n",
      "Train Loss 2951: 21.096281726328616\n",
      "Train Loss 2952: 21.095868200493566\n",
      "Train Loss 2953: 21.095454670014927\n",
      "Train Loss 2954: 21.095041157134172\n",
      "Train Loss 2955: 21.09462765692616\n",
      "Train Loss 2956: 21.09421417028553\n",
      "Train Loss 2957: 21.09380071441405\n",
      "Train Loss 2958: 21.09338729905675\n",
      "Train Loss 2959: 21.0929739039033\n",
      "Train Loss 2960: 21.092560531500755\n",
      "Train Loss 2961: 21.092147162453536\n",
      "Train Loss 2962: 21.09173383154384\n",
      "Train Loss 2963: 21.09132047476818\n",
      "Train Loss 2964: 21.09090714613715\n",
      "Train Loss 2965: 21.090493826265842\n",
      "Train Loss 2966: 21.090080633671096\n",
      "Train Loss 2967: 21.089667564408362\n",
      "Train Loss 2968: 21.089254591572775\n",
      "Train Loss 2969: 21.088841651221298\n",
      "Train Loss 2970: 21.08842874202129\n",
      "Train Loss 2971: 21.088015831454484\n",
      "Train Loss 2972: 21.087602965193348\n",
      "Train Loss 2973: 21.08719014648751\n",
      "Train Loss 2974: 21.086777373335003\n",
      "Train Loss 2975: 21.086364634180587\n",
      "Train Loss 2976: 21.085951939194956\n",
      "Train Loss 2977: 21.085539285518646\n",
      "Train Loss 2978: 21.08512667509068\n",
      "Train Loss 2979: 21.08471413042662\n",
      "Train Loss 2980: 21.08430169220858\n",
      "Train Loss 2981: 21.083889289961608\n",
      "Train Loss 2982: 21.083476918548186\n",
      "Train Loss 2983: 21.083064575779094\n",
      "Train Loss 2984: 21.08265230850218\n",
      "Train Loss 2985: 21.08224018221402\n",
      "Train Loss 2986: 21.08182807262687\n",
      "Train Loss 2987: 21.08141599267582\n",
      "Train Loss 2988: 21.081003965658027\n",
      "Train Loss 2989: 21.0805919800109\n",
      "Train Loss 2990: 21.080179996135954\n",
      "Train Loss 2991: 21.079768052293115\n",
      "Train Loss 2992: 21.0793561373129\n",
      "Train Loss 2993: 21.07894424584338\n",
      "Train Loss 2994: 21.078532389939042\n",
      "Train Loss 2995: 21.07812057731332\n",
      "Train Loss 2996: 21.077708807935814\n",
      "Train Loss 2997: 21.077297083829286\n",
      "Train Loss 2998: 21.07688540678088\n",
      "Train Loss 2999: 21.076473769925048\n",
      "Train Loss 3000: 21.076062151671486\n",
      "Train Loss 3001: 21.075650576518417\n",
      "Train Loss 3002: 21.075239042518476\n",
      "Train Loss 3003: 21.074827511141642\n",
      "Train Loss 3004: 21.074416022764296\n",
      "Train Loss 3005: 21.074004577356035\n",
      "Train Loss 3006: 21.073593166954545\n",
      "Train Loss 3007: 21.07318176240364\n",
      "Train Loss 3008: 21.07277032773792\n",
      "Train Loss 3009: 21.07235893598079\n",
      "Train Loss 3010: 21.071947583665835\n",
      "Train Loss 3011: 21.071536263118112\n",
      "Train Loss 3012: 21.0711249692095\n",
      "Train Loss 3013: 21.070713718118885\n",
      "Train Loss 3014: 21.070302509816013\n",
      "Train Loss 3015: 21.06989134427063\n",
      "Train Loss 3016: 21.069480219015826\n",
      "Train Loss 3017: 21.06906912706769\n",
      "Train Loss 3018: 21.06865807522032\n",
      "Train Loss 3019: 21.0682470517776\n",
      "Train Loss 3020: 21.067836065566365\n",
      "Train Loss 3021: 21.067425126472468\n",
      "Train Loss 3022: 21.06701424857286\n",
      "Train Loss 3023: 21.066603359448795\n",
      "Train Loss 3024: 21.066192421170385\n",
      "Train Loss 3025: 21.065781498862698\n",
      "Train Loss 3026: 21.065370626963865\n",
      "Train Loss 3027: 21.064959815282865\n",
      "Train Loss 3028: 21.064549031416124\n",
      "Train Loss 3029: 21.064138284880443\n",
      "Train Loss 3030: 21.0637275862017\n",
      "Train Loss 3031: 21.063316934367595\n",
      "Train Loss 3032: 21.06290632463393\n",
      "Train Loss 3033: 21.062495868155988\n",
      "Train Loss 3034: 21.062085610984994\n",
      "Train Loss 3035: 21.061675385892286\n",
      "Train Loss 3036: 21.06126519118903\n",
      "Train Loss 3037: 21.060855038159723\n",
      "Train Loss 3038: 21.06044493959369\n",
      "Train Loss 3039: 21.06003495039596\n",
      "Train Loss 3040: 21.059625088609707\n",
      "Train Loss 3041: 21.059215268113334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 3042: 21.058805486317667\n",
      "Train Loss 3043: 21.058395722265576\n",
      "Train Loss 3044: 21.057985964371483\n",
      "Train Loss 3045: 21.057576241806938\n",
      "Train Loss 3046: 21.057166568964522\n",
      "Train Loss 3047: 21.056756943259142\n",
      "Train Loss 3048: 21.056347390233334\n",
      "Train Loss 3049: 21.055937878154374\n",
      "Train Loss 3050: 21.055528400726352\n",
      "Train Loss 3051: 21.055118964872705\n",
      "Train Loss 3052: 21.05470955287008\n",
      "Train Loss 3053: 21.054300133062156\n",
      "Train Loss 3054: 21.05389074196229\n",
      "Train Loss 3055: 21.053481389576163\n",
      "Train Loss 3056: 21.053072049715123\n",
      "Train Loss 3057: 21.052662775663535\n",
      "Train Loss 3058: 21.05225353566082\n",
      "Train Loss 3059: 21.051844327136212\n",
      "Train Loss 3060: 21.05143515902243\n",
      "Train Loss 3061: 21.051026029286156\n",
      "Train Loss 3062: 21.05061686576199\n",
      "Train Loss 3063: 21.05020773446583\n",
      "Train Loss 3064: 21.04979863185418\n",
      "Train Loss 3065: 21.04938956209157\n",
      "Train Loss 3066: 21.048980533317653\n",
      "Train Loss 3067: 21.048571571722572\n",
      "Train Loss 3068: 21.04816264519249\n",
      "Train Loss 3069: 21.04775373748253\n",
      "Train Loss 3070: 21.04734485851986\n",
      "Train Loss 3071: 21.04693600234114\n",
      "Train Loss 3072: 21.046527161501686\n",
      "Train Loss 3073: 21.04611835307273\n",
      "Train Loss 3074: 21.045709581895878\n",
      "Train Loss 3075: 21.04530078898945\n",
      "Train Loss 3076: 21.044892022593114\n",
      "Train Loss 3077: 21.044483286966027\n",
      "Train Loss 3078: 21.044074578072955\n",
      "Train Loss 3079: 21.043665898317787\n",
      "Train Loss 3080: 21.043257248744126\n",
      "Train Loss 3081: 21.042848590493485\n",
      "Train Loss 3082: 21.042439930365703\n",
      "Train Loss 3083: 21.042031310070236\n",
      "Train Loss 3084: 21.0416227263975\n",
      "Train Loss 3085: 21.041214173032756\n",
      "Train Loss 3086: 21.0408056594372\n",
      "Train Loss 3087: 21.0403971796826\n",
      "Train Loss 3088: 21.039988728499132\n",
      "Train Loss 3089: 21.039580285362334\n",
      "Train Loss 3090: 21.039171796662256\n",
      "Train Loss 3091: 21.03876334520688\n",
      "Train Loss 3092: 21.038354915373212\n",
      "Train Loss 3093: 21.037946518861066\n",
      "Train Loss 3094: 21.037538159742404\n",
      "Train Loss 3095: 21.03712982111524\n",
      "Train Loss 3096: 21.036721507052654\n",
      "Train Loss 3097: 21.03631320657697\n",
      "Train Loss 3098: 21.035904940291097\n",
      "Train Loss 3099: 21.035496714390142\n",
      "Train Loss 3100: 21.035088488425615\n",
      "Train Loss 3101: 21.03468029624214\n",
      "Train Loss 3102: 21.03427214341102\n",
      "Train Loss 3103: 21.033864029905025\n",
      "Train Loss 3104: 21.03345595569692\n",
      "Train Loss 3105: 21.03304792069335\n",
      "Train Loss 3106: 21.032639914471297\n",
      "Train Loss 3107: 21.03223194748457\n",
      "Train Loss 3108: 21.03182401614295\n",
      "Train Loss 3109: 21.0314160934406\n",
      "Train Loss 3110: 21.031008167061643\n",
      "Train Loss 3111: 21.030600248373183\n",
      "Train Loss 3112: 21.030192305865516\n",
      "Train Loss 3113: 21.029784336140576\n",
      "Train Loss 3114: 21.02937638940393\n",
      "Train Loss 3115: 21.02896843518107\n",
      "Train Loss 3116: 21.028560505284048\n",
      "Train Loss 3117: 21.028152658141856\n",
      "Train Loss 3118: 21.027744822117572\n",
      "Train Loss 3119: 21.02733699091513\n",
      "Train Loss 3120: 21.02692918784203\n",
      "Train Loss 3121: 21.02652138113918\n",
      "Train Loss 3122: 21.026113567276795\n",
      "Train Loss 3123: 21.025705811549113\n",
      "Train Loss 3124: 21.025298094330896\n",
      "Train Loss 3125: 21.024890396409816\n",
      "Train Loss 3126: 21.024482615105374\n",
      "Train Loss 3127: 21.024074837968485\n",
      "Train Loss 3128: 21.023667036876024\n",
      "Train Loss 3129: 21.023259224666596\n",
      "Train Loss 3130: 21.02285144208857\n",
      "Train Loss 3131: 21.022443659689444\n",
      "Train Loss 3132: 21.02203590737059\n",
      "Train Loss 3133: 21.021628193751663\n",
      "Train Loss 3134: 21.021220518806647\n",
      "Train Loss 3135: 21.020812875896887\n",
      "Train Loss 3136: 21.020405248461273\n",
      "Train Loss 3137: 21.019997648007607\n",
      "Train Loss 3138: 21.019590057308278\n",
      "Train Loss 3139: 21.019182497642834\n",
      "Train Loss 3140: 21.018774975083325\n",
      "Train Loss 3141: 21.01836747983807\n",
      "Train Loss 3142: 21.01796001847809\n",
      "Train Loss 3143: 21.017552574370345\n",
      "Train Loss 3144: 21.017145177776996\n",
      "Train Loss 3145: 21.016737838172844\n",
      "Train Loss 3146: 21.016330536875664\n",
      "Train Loss 3147: 21.01592327385982\n",
      "Train Loss 3148: 21.015516042178874\n",
      "Train Loss 3149: 21.01510884168847\n",
      "Train Loss 3150: 21.014701681109155\n",
      "Train Loss 3151: 21.014294591162567\n",
      "Train Loss 3152: 21.013887593189622\n",
      "Train Loss 3153: 21.013480624487144\n",
      "Train Loss 3154: 21.013073693625163\n",
      "Train Loss 3155: 21.012666804740864\n",
      "Train Loss 3156: 21.012259987599023\n",
      "Train Loss 3157: 21.011853194771014\n",
      "Train Loss 3158: 21.011446431871942\n",
      "Train Loss 3159: 21.011039710484688\n",
      "Train Loss 3160: 21.010633009939657\n",
      "Train Loss 3161: 21.010226251003676\n",
      "Train Loss 3162: 21.009819503835107\n",
      "Train Loss 3163: 21.00941276272052\n",
      "Train Loss 3164: 21.009006058993396\n",
      "Train Loss 3165: 21.008599392628764\n",
      "Train Loss 3166: 21.008192763601638\n",
      "Train Loss 3167: 21.007786165885555\n",
      "Train Loss 3168: 21.007379583934405\n",
      "Train Loss 3169: 21.006973027628337\n",
      "Train Loss 3170: 21.006566474367904\n",
      "Train Loss 3171: 21.006159940764753\n",
      "Train Loss 3172: 21.00575343910296\n",
      "Train Loss 3173: 21.00534698280068\n",
      "Train Loss 3174: 21.004940645438452\n",
      "Train Loss 3175: 21.004534345098538\n",
      "Train Loss 3176: 21.00412808237444\n",
      "Train Loss 3177: 21.00372185178786\n",
      "Train Loss 3178: 21.00331562684418\n",
      "Train Loss 3179: 21.00290943883278\n",
      "Train Loss 3180: 21.00250331011297\n",
      "Train Loss 3181: 21.00209725391647\n",
      "Train Loss 3182: 21.001691241995566\n",
      "Train Loss 3183: 21.00128533285524\n",
      "Train Loss 3184: 21.00087945979665\n",
      "Train Loss 3185: 21.000473620605884\n",
      "Train Loss 3186: 21.000067803547264\n",
      "Train Loss 3187: 20.999662023082777\n",
      "Train Loss 3188: 20.99925627918816\n",
      "Train Loss 3189: 20.99885058435344\n",
      "Train Loss 3190: 20.99844493885934\n",
      "Train Loss 3191: 20.998039315130146\n",
      "Train Loss 3192: 20.997633720744524\n",
      "Train Loss 3193: 20.997228166180076\n",
      "Train Loss 3194: 20.99682266870724\n",
      "Train Loss 3195: 20.99641719726886\n",
      "Train Loss 3196: 20.996011667067393\n",
      "Train Loss 3197: 20.995606161983265\n",
      "Train Loss 3198: 20.99520069590258\n",
      "Train Loss 3199: 20.99479527877555\n",
      "Train Loss 3200: 20.994389969056787\n",
      "Train Loss 3201: 20.993984725095814\n",
      "Train Loss 3202: 20.99357957360792\n",
      "Train Loss 3203: 20.993174457996414\n",
      "Train Loss 3204: 20.992769350843147\n",
      "Train Loss 3205: 20.99236424045592\n",
      "Train Loss 3206: 20.99195915475058\n",
      "Train Loss 3207: 20.99155410501611\n",
      "Train Loss 3208: 20.9911490488928\n",
      "Train Loss 3209: 20.990743970421054\n",
      "Train Loss 3210: 20.990338927947004\n",
      "Train Loss 3211: 20.98993392144739\n",
      "Train Loss 3212: 20.989528950898904\n",
      "Train Loss 3213: 20.98912401627826\n",
      "Train Loss 3214: 20.98871911756215\n",
      "Train Loss 3215: 20.9883142504608\n",
      "Train Loss 3216: 20.987909415534546\n",
      "Train Loss 3217: 20.987504603400932\n",
      "Train Loss 3218: 20.98709981884897\n",
      "Train Loss 3219: 20.986695087336876\n",
      "Train Loss 3220: 20.986290433556572\n",
      "Train Loss 3221: 20.985885898605552\n",
      "Train Loss 3222: 20.985481399953922\n",
      "Train Loss 3223: 20.985076997351424\n",
      "Train Loss 3224: 20.98467270424532\n",
      "Train Loss 3225: 20.98426848990323\n",
      "Train Loss 3226: 20.983864293834895\n",
      "Train Loss 3227: 20.983460132676164\n",
      "Train Loss 3228: 20.98305598817741\n",
      "Train Loss 3229: 20.982651831053357\n",
      "Train Loss 3230: 20.98224769995563\n",
      "Train Loss 3231: 20.981843589537398\n",
      "Train Loss 3232: 20.981439514009868\n",
      "Train Loss 3233: 20.981035473351202\n",
      "Train Loss 3234: 20.980631461379144\n",
      "Train Loss 3235: 20.980227454121327\n",
      "Train Loss 3236: 20.979823481692545\n",
      "Train Loss 3237: 20.97941954407097\n",
      "Train Loss 3238: 20.97901565883348\n",
      "Train Loss 3239: 20.978611829465958\n",
      "Train Loss 3240: 20.97820807479747\n",
      "Train Loss 3241: 20.977804389799815\n",
      "Train Loss 3242: 20.97740072800973\n",
      "Train Loss 3243: 20.97699709808767\n",
      "Train Loss 3244: 20.976593494750723\n",
      "Train Loss 3245: 20.976189925789484\n",
      "Train Loss 3246: 20.97578637712159\n",
      "Train Loss 3247: 20.97538284297307\n",
      "Train Loss 3248: 20.974979342498035\n",
      "Train Loss 3249: 20.974575873923218\n",
      "Train Loss 3250: 20.974172439598455\n",
      "Train Loss 3251: 20.97376903542153\n",
      "Train Loss 3252: 20.973365657948708\n",
      "Train Loss 3253: 20.972962314617103\n",
      "Train Loss 3254: 20.972559040743125\n",
      "Train Loss 3255: 20.972155861333988\n",
      "Train Loss 3256: 20.971752704484423\n",
      "Train Loss 3257: 20.97134958164737\n",
      "Train Loss 3258: 20.970946492801804\n",
      "Train Loss 3259: 20.970543446104884\n",
      "Train Loss 3260: 20.97014045412968\n",
      "Train Loss 3261: 20.96973748901043\n",
      "Train Loss 3262: 20.969334551341703\n",
      "Train Loss 3263: 20.96893164808743\n",
      "Train Loss 3264: 20.968528756607114\n",
      "Train Loss 3265: 20.968125883899884\n",
      "Train Loss 3266: 20.967723049757588\n",
      "Train Loss 3267: 20.96732024511759\n",
      "Train Loss 3268: 20.966917480439665\n",
      "Train Loss 3269: 20.96651491533288\n",
      "Train Loss 3270: 20.966112405781896\n",
      "Train Loss 3271: 20.965709927383102\n",
      "Train Loss 3272: 20.965307471524383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 3273: 20.964905049685207\n",
      "Train Loss 3274: 20.964502716580903\n",
      "Train Loss 3275: 20.964100413550774\n",
      "Train Loss 3276: 20.963698129923557\n",
      "Train Loss 3277: 20.963295875377476\n",
      "Train Loss 3278: 20.962893642670934\n",
      "Train Loss 3279: 20.962491422525055\n",
      "Train Loss 3280: 20.962089214580686\n",
      "Train Loss 3281: 20.96168703876232\n",
      "Train Loss 3282: 20.96128487515088\n",
      "Train Loss 3283: 20.960882729998136\n",
      "Train Loss 3284: 20.960480579580885\n",
      "Train Loss 3285: 20.960078453723167\n",
      "Train Loss 3286: 20.959676359534118\n",
      "Train Loss 3287: 20.95927428690835\n",
      "Train Loss 3288: 20.958872243789024\n",
      "Train Loss 3289: 20.958470222985177\n",
      "Train Loss 3290: 20.95806828055325\n",
      "Train Loss 3291: 20.957666370791344\n",
      "Train Loss 3292: 20.957264493497735\n",
      "Train Loss 3293: 20.95686263140307\n",
      "Train Loss 3294: 20.956460742119052\n",
      "Train Loss 3295: 20.956058885498127\n",
      "Train Loss 3296: 20.955657058178996\n",
      "Train Loss 3297: 20.95525523426356\n",
      "Train Loss 3298: 20.954853434349822\n",
      "Train Loss 3299: 20.9544516629596\n",
      "Train Loss 3300: 20.95404991714747\n",
      "Train Loss 3301: 20.953648203928385\n",
      "Train Loss 3302: 20.953246523282225\n",
      "Train Loss 3303: 20.952844875188884\n",
      "Train Loss 3304: 20.952443253602752\n",
      "Train Loss 3305: 20.952041696717863\n",
      "Train Loss 3306: 20.951640215893505\n",
      "Train Loss 3307: 20.951238764441225\n",
      "Train Loss 3308: 20.95083732611797\n",
      "Train Loss 3309: 20.950435866106258\n",
      "Train Loss 3310: 20.95003440409382\n",
      "Train Loss 3311: 20.949632968319385\n",
      "Train Loss 3312: 20.94923153467095\n",
      "Train Loss 3313: 20.948830133333498\n",
      "Train Loss 3314: 20.948428764287446\n",
      "Train Loss 3315: 20.948027427513175\n",
      "Train Loss 3316: 20.947626122991103\n",
      "Train Loss 3317: 20.947224857740316\n",
      "Train Loss 3318: 20.946823633865346\n",
      "Train Loss 3319: 20.946422442131\n",
      "Train Loss 3320: 20.94602128469385\n",
      "Train Loss 3321: 20.945620219548296\n",
      "Train Loss 3322: 20.94521914144462\n",
      "Train Loss 3323: 20.944818088404336\n",
      "Train Loss 3324: 20.944417066992635\n",
      "Train Loss 3325: 20.94401606954123\n",
      "Train Loss 3326: 20.943615103939443\n",
      "Train Loss 3327: 20.943214170167963\n",
      "Train Loss 3328: 20.94281325889673\n",
      "Train Loss 3329: 20.94241233552122\n",
      "Train Loss 3330: 20.942011428794704\n",
      "Train Loss 3331: 20.94161059801938\n",
      "Train Loss 3332: 20.941209798912247\n",
      "Train Loss 3333: 20.940809032373856\n",
      "Train Loss 3334: 20.940408300208833\n",
      "Train Loss 3335: 20.94000759963614\n",
      "Train Loss 3336: 20.93960692728419\n",
      "Train Loss 3337: 20.939206276469292\n",
      "Train Loss 3338: 20.93880565720798\n",
      "Train Loss 3339: 20.938405061046897\n",
      "Train Loss 3340: 20.93800443874191\n",
      "Train Loss 3341: 20.93760385025135\n",
      "Train Loss 3342: 20.93720330283227\n",
      "Train Loss 3343: 20.936802793556453\n",
      "Train Loss 3344: 20.936402315686998\n",
      "Train Loss 3345: 20.936001866235088\n",
      "Train Loss 3346: 20.935601442515406\n",
      "Train Loss 3347: 20.93520105016075\n",
      "Train Loss 3348: 20.934800685914077\n",
      "Train Loss 3349: 20.934400346481407\n",
      "Train Loss 3350: 20.934000038373682\n",
      "Train Loss 3351: 20.93359975738855\n",
      "Train Loss 3352: 20.933199499770275\n",
      "Train Loss 3353: 20.932799273439542\n",
      "Train Loss 3354: 20.93239907837767\n",
      "Train Loss 3355: 20.93199891456598\n",
      "Train Loss 3356: 20.93159877058028\n",
      "Train Loss 3357: 20.93119863723531\n",
      "Train Loss 3358: 20.930798524649955\n",
      "Train Loss 3359: 20.93039844325107\n",
      "Train Loss 3360: 20.92999839302013\n",
      "Train Loss 3361: 20.929598374770386\n",
      "Train Loss 3362: 20.929198459032875\n",
      "Train Loss 3363: 20.928798574225652\n",
      "Train Loss 3364: 20.92839872033043\n",
      "Train Loss 3365: 20.92799889719912\n",
      "Train Loss 3366: 20.92759909114519\n",
      "Train Loss 3367: 20.927199309509184\n",
      "Train Loss 3368: 20.926799578935245\n",
      "Train Loss 3369: 20.92639992295162\n",
      "Train Loss 3370: 20.92600029775422\n",
      "Train Loss 3371: 20.92560070332478\n",
      "Train Loss 3372: 20.925201139645004\n",
      "Train Loss 3373: 20.924801606696626\n",
      "Train Loss 3374: 20.92440209228644\n",
      "Train Loss 3375: 20.9240025701373\n",
      "Train Loss 3376: 20.923603078206472\n",
      "Train Loss 3377: 20.92320359902011\n",
      "Train Loss 3378: 20.922804068381662\n",
      "Train Loss 3379: 20.922404579776508\n",
      "Train Loss 3380: 20.92200511636446\n",
      "Train Loss 3381: 20.921605673503198\n",
      "Train Loss 3382: 20.921206256364997\n",
      "Train Loss 3383: 20.920806863717758\n",
      "Train Loss 3384: 20.920407478170873\n",
      "Train Loss 3385: 20.92000812782877\n",
      "Train Loss 3386: 20.919608827034523\n",
      "Train Loss 3387: 20.919209549203224\n",
      "Train Loss 3388: 20.918810300680008\n",
      "Train Loss 3389: 20.918411069514924\n",
      "Train Loss 3390: 20.918011862773806\n",
      "Train Loss 3391: 20.917612686568408\n",
      "Train Loss 3392: 20.91721354088093\n",
      "Train Loss 3393: 20.91681442569356\n",
      "Train Loss 3394: 20.91641534098849\n",
      "Train Loss 3395: 20.916016281663826\n",
      "Train Loss 3396: 20.915617246778908\n",
      "Train Loss 3397: 20.91521824233398\n",
      "Train Loss 3398: 20.914819266111756\n",
      "Train Loss 3399: 20.914420290301543\n",
      "Train Loss 3400: 20.914021297526254\n",
      "Train Loss 3401: 20.913622331922998\n",
      "Train Loss 3402: 20.913223378276726\n",
      "Train Loss 3403: 20.912824415029164\n",
      "Train Loss 3404: 20.912425524201446\n",
      "Train Loss 3405: 20.91202664858747\n",
      "Train Loss 3406: 20.911627792390696\n",
      "Train Loss 3407: 20.911228947538635\n",
      "Train Loss 3408: 20.91083016457743\n",
      "Train Loss 3409: 20.910431402542137\n",
      "Train Loss 3410: 20.91003261997119\n",
      "Train Loss 3411: 20.90963386399252\n",
      "Train Loss 3412: 20.90923512949295\n",
      "Train Loss 3413: 20.90883641036185\n",
      "Train Loss 3414: 20.908437675169356\n",
      "Train Loss 3415: 20.90803896504817\n",
      "Train Loss 3416: 20.907640278773037\n",
      "Train Loss 3417: 20.907241628296752\n",
      "Train Loss 3418: 20.906842995403196\n",
      "Train Loss 3419: 20.906444376762515\n",
      "Train Loss 3420: 20.906045772496842\n",
      "Train Loss 3421: 20.905647197987975\n",
      "Train Loss 3422: 20.905248640753744\n",
      "Train Loss 3423: 20.904850106438868\n",
      "Train Loss 3424: 20.904451583304827\n",
      "Train Loss 3425: 20.904053077993602\n",
      "Train Loss 3426: 20.903654583093907\n",
      "Train Loss 3427: 20.903256105369195\n",
      "Train Loss 3428: 20.902857760592987\n",
      "Train Loss 3429: 20.90245953735986\n",
      "Train Loss 3430: 20.902061343825288\n",
      "Train Loss 3431: 20.901663179345597\n",
      "Train Loss 3432: 20.901265013084704\n",
      "Train Loss 3433: 20.90086681794518\n",
      "Train Loss 3434: 20.900468652425737\n",
      "Train Loss 3435: 20.900070516509032\n",
      "Train Loss 3436: 20.899672407827993\n",
      "Train Loss 3437: 20.899274312314464\n",
      "Train Loss 3438: 20.898876232076777\n",
      "Train Loss 3439: 20.898478153681143\n",
      "Train Loss 3440: 20.89808010323086\n",
      "Train Loss 3441: 20.89768207543615\n",
      "Train Loss 3442: 20.897284058615483\n",
      "Train Loss 3443: 20.8968860731949\n",
      "Train Loss 3444: 20.89648818945904\n",
      "Train Loss 3445: 20.896090335139657\n",
      "Train Loss 3446: 20.89569250806763\n",
      "Train Loss 3447: 20.89529469822652\n",
      "Train Loss 3448: 20.894896909096644\n",
      "Train Loss 3449: 20.894499149342614\n",
      "Train Loss 3450: 20.894101408647856\n",
      "Train Loss 3451: 20.893703679576383\n",
      "Train Loss 3452: 20.893305982348952\n",
      "Train Loss 3453: 20.892908336507166\n",
      "Train Loss 3454: 20.89251071976565\n",
      "Train Loss 3455: 20.892113133975894\n",
      "Train Loss 3456: 20.891715603482318\n",
      "Train Loss 3457: 20.891318091033966\n",
      "Train Loss 3458: 20.89092060661763\n",
      "Train Loss 3459: 20.890523128845775\n",
      "Train Loss 3460: 20.890125637597272\n",
      "Train Loss 3461: 20.88972816191383\n",
      "Train Loss 3462: 20.889330685063534\n",
      "Train Loss 3463: 20.88893323601168\n",
      "Train Loss 3464: 20.888535808711723\n",
      "Train Loss 3465: 20.888138408822197\n",
      "Train Loss 3466: 20.887741029206133\n",
      "Train Loss 3467: 20.887343678433318\n",
      "Train Loss 3468: 20.886946355398607\n",
      "Train Loss 3469: 20.886549050424424\n",
      "Train Loss 3470: 20.886151774255232\n",
      "Train Loss 3471: 20.88575452687409\n",
      "Train Loss 3472: 20.885357320851167\n",
      "Train Loss 3473: 20.88496014339335\n",
      "Train Loss 3474: 20.88456297296017\n",
      "Train Loss 3475: 20.884165828921954\n",
      "Train Loss 3476: 20.883768687312543\n",
      "Train Loss 3477: 20.883371554103455\n",
      "Train Loss 3478: 20.882974449512826\n",
      "Train Loss 3479: 20.88257737352382\n",
      "Train Loss 3480: 20.88218032611961\n",
      "Train Loss 3481: 20.881783304636922\n",
      "Train Loss 3482: 20.88138629703312\n",
      "Train Loss 3483: 20.88098929632148\n",
      "Train Loss 3484: 20.880592299556927\n",
      "Train Loss 3485: 20.880195331354873\n",
      "Train Loss 3486: 20.879798391698543\n",
      "Train Loss 3487: 20.879401480571183\n",
      "Train Loss 3488: 20.879004597956023\n",
      "Train Loss 3489: 20.878607742843943\n",
      "Train Loss 3490: 20.878210911120348\n",
      "Train Loss 3491: 20.87781409215171\n",
      "Train Loss 3492: 20.877417272972355\n",
      "Train Loss 3493: 20.877020465325373\n",
      "Train Loss 3494: 20.87662367661656\n",
      "Train Loss 3495: 20.876226916288037\n",
      "Train Loss 3496: 20.875830178370773\n",
      "Train Loss 3497: 20.875433451932032\n",
      "Train Loss 3498: 20.875036753852466\n",
      "Train Loss 3499: 20.874640080236357\n",
      "Train Loss 3500: 20.874243426379255\n",
      "Train Loss 3501: 20.87384680084448\n",
      "Train Loss 3502: 20.873450203615306\n",
      "Train Loss 3503: 20.873053634674996\n",
      "Train Loss 3504: 20.872657094006836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 3505: 20.872260585182342\n",
      "Train Loss 3506: 20.871864117780174\n",
      "Train Loss 3507: 20.87146767099685\n",
      "Train Loss 3508: 20.871071250791964\n",
      "Train Loss 3509: 20.870674858742785\n",
      "Train Loss 3510: 20.87027849483269\n",
      "Train Loss 3511: 20.86988215904506\n",
      "Train Loss 3512: 20.869485851363255\n",
      "Train Loss 3513: 20.869089566025888\n",
      "Train Loss 3514: 20.86869330245594\n",
      "Train Loss 3515: 20.868297066955968\n",
      "Train Loss 3516: 20.867900856251342\n",
      "Train Loss 3517: 20.867504667117153\n",
      "Train Loss 3518: 20.867108514514563\n",
      "Train Loss 3519: 20.866712342417937\n",
      "Train Loss 3520: 20.866316188784957\n",
      "Train Loss 3521: 20.865920067179516\n",
      "Train Loss 3522: 20.86552399020067\n",
      "Train Loss 3523: 20.86512792779966\n",
      "Train Loss 3524: 20.86473188739007\n",
      "Train Loss 3525: 20.86433589791068\n",
      "Train Loss 3526: 20.86393986682224\n",
      "Train Loss 3527: 20.863543868341022\n",
      "Train Loss 3528: 20.863147896915738\n",
      "Train Loss 3529: 20.86275192831892\n",
      "Train Loss 3530: 20.86235594231379\n",
      "Train Loss 3531: 20.861959984038513\n",
      "Train Loss 3532: 20.861564017841594\n",
      "Train Loss 3533: 20.861168040280145\n",
      "Train Loss 3534: 20.860772130374766\n",
      "Train Loss 3535: 20.860376237228074\n",
      "Train Loss 3536: 20.85998039106248\n",
      "Train Loss 3537: 20.85958461731288\n",
      "Train Loss 3538: 20.859188870943022\n",
      "Train Loss 3539: 20.858793151184166\n",
      "Train Loss 3540: 20.858397447699506\n",
      "Train Loss 3541: 20.85800177153345\n",
      "Train Loss 3542: 20.857606122670838\n",
      "Train Loss 3543: 20.857210501096517\n",
      "Train Loss 3544: 20.85681490679533\n",
      "Train Loss 3545: 20.856419339752104\n",
      "Train Loss 3546: 20.856023797603022\n",
      "Train Loss 3547: 20.855628276377114\n",
      "Train Loss 3548: 20.855232788032897\n",
      "Train Loss 3549: 20.854837326877576\n",
      "Train Loss 3550: 20.854441892896006\n",
      "Train Loss 3551: 20.854046483120676\n",
      "Train Loss 3552: 20.853651088876553\n",
      "Train Loss 3553: 20.853255715634972\n",
      "Train Loss 3554: 20.852860428926565\n",
      "Train Loss 3555: 20.85246529843348\n",
      "Train Loss 3556: 20.852070194821476\n",
      "Train Loss 3557: 20.851675103228377\n",
      "Train Loss 3558: 20.851280012477602\n",
      "Train Loss 3559: 20.850884943555045\n",
      "Train Loss 3560: 20.850489893087254\n",
      "Train Loss 3561: 20.85009486173899\n",
      "Train Loss 3562: 20.849699842086512\n",
      "Train Loss 3563: 20.849304858495938\n",
      "Train Loss 3564: 20.848909932803878\n",
      "Train Loss 3565: 20.848515033831923\n",
      "Train Loss 3566: 20.848120161565017\n",
      "Train Loss 3567: 20.847725315988075\n",
      "Train Loss 3568: 20.84733049699305\n",
      "Train Loss 3569: 20.846935701881\n",
      "Train Loss 3570: 20.846540923634052\n",
      "Train Loss 3571: 20.84614616780505\n",
      "Train Loss 3572: 20.845751417286323\n",
      "Train Loss 3573: 20.84535668125637\n",
      "Train Loss 3574: 20.844961964250857\n",
      "Train Loss 3575: 20.844567269820672\n",
      "Train Loss 3576: 20.844172573925796\n",
      "Train Loss 3577: 20.84377790453205\n",
      "Train Loss 3578: 20.84338326338756\n",
      "Train Loss 3579: 20.84298865203096\n",
      "Train Loss 3580: 20.84259402701975\n",
      "Train Loss 3581: 20.842199368471213\n",
      "Train Loss 3582: 20.841804725181653\n",
      "Train Loss 3583: 20.84141009488407\n",
      "Train Loss 3584: 20.841015493353503\n",
      "Train Loss 3585: 20.840620918255578\n",
      "Train Loss 3586: 20.84022636957564\n",
      "Train Loss 3587: 20.839831847299028\n",
      "Train Loss 3588: 20.839437351411092\n",
      "Train Loss 3589: 20.839042881870117\n",
      "Train Loss 3590: 20.838648423640336\n",
      "Train Loss 3591: 20.838253983675415\n",
      "Train Loss 3592: 20.837859550500013\n",
      "Train Loss 3593: 20.837465135637455\n",
      "Train Loss 3594: 20.837070746736504\n",
      "Train Loss 3595: 20.836676375339188\n",
      "Train Loss 3596: 20.836282042029726\n",
      "Train Loss 3597: 20.835887785658592\n",
      "Train Loss 3598: 20.83549355548694\n",
      "Train Loss 3599: 20.83509935150043\n",
      "Train Loss 3600: 20.834705152355603\n",
      "Train Loss 3601: 20.834310918761197\n",
      "Train Loss 3602: 20.833916699877143\n",
      "Train Loss 3603: 20.833522507186608\n",
      "Train Loss 3604: 20.833128303320237\n",
      "Train Loss 3605: 20.832734061871435\n",
      "Train Loss 3606: 20.832339838273676\n",
      "Train Loss 3607: 20.831945634155193\n",
      "Train Loss 3608: 20.83155145149609\n",
      "Train Loss 3609: 20.831157283209414\n",
      "Train Loss 3610: 20.830763127014716\n",
      "Train Loss 3611: 20.83036899001258\n",
      "Train Loss 3612: 20.82997487444125\n",
      "Train Loss 3613: 20.829580779326918\n",
      "Train Loss 3614: 20.829186705326833\n",
      "Train Loss 3615: 20.828792650034885\n",
      "Train Loss 3616: 20.828398619963956\n",
      "Train Loss 3617: 20.82800459417347\n",
      "Train Loss 3618: 20.827610678739866\n",
      "Train Loss 3619: 20.827216772403865\n",
      "Train Loss 3620: 20.82682288589822\n",
      "Train Loss 3621: 20.826429019593807\n",
      "Train Loss 3622: 20.826035164898634\n",
      "Train Loss 3623: 20.825641330088622\n",
      "Train Loss 3624: 20.82524752123646\n",
      "Train Loss 3625: 20.824853730873425\n",
      "Train Loss 3626: 20.82445995921068\n",
      "Train Loss 3627: 20.82406620384998\n",
      "Train Loss 3628: 20.823672425926965\n",
      "Train Loss 3629: 20.823278673930982\n",
      "Train Loss 3630: 20.82288494784828\n",
      "Train Loss 3631: 20.82249124766508\n",
      "Train Loss 3632: 20.822097560750333\n",
      "Train Loss 3633: 20.82170387581361\n",
      "Train Loss 3634: 20.821310216770424\n",
      "Train Loss 3635: 20.82091658360703\n",
      "Train Loss 3636: 20.820522976309686\n",
      "Train Loss 3637: 20.820129390102636\n",
      "Train Loss 3638: 20.819735823819936\n",
      "Train Loss 3639: 20.819342216338864\n",
      "Train Loss 3640: 20.818948590439142\n",
      "Train Loss 3641: 20.818554957870035\n",
      "Train Loss 3642: 20.818161260269378\n",
      "Train Loss 3643: 20.81776758214293\n",
      "Train Loss 3644: 20.817373916717013\n",
      "Train Loss 3645: 20.816980277107945\n",
      "Train Loss 3646: 20.816586666630318\n",
      "Train Loss 3647: 20.816193081067077\n",
      "Train Loss 3648: 20.815799520574934\n",
      "Train Loss 3649: 20.81540603744291\n",
      "Train Loss 3650: 20.815012703081653\n",
      "Train Loss 3651: 20.81461938775363\n",
      "Train Loss 3652: 20.814226097978406\n",
      "Train Loss 3653: 20.813832833742328\n",
      "Train Loss 3654: 20.81343959503172\n",
      "Train Loss 3655: 20.813046381640802\n",
      "Train Loss 3656: 20.812653182546605\n",
      "Train Loss 3657: 20.81226003922017\n",
      "Train Loss 3658: 20.811866960878092\n",
      "Train Loss 3659: 20.811473954479595\n",
      "Train Loss 3660: 20.81108096005518\n",
      "Train Loss 3661: 20.810688045009023\n",
      "Train Loss 3662: 20.810295155116574\n",
      "Train Loss 3663: 20.809902290364523\n",
      "Train Loss 3664: 20.809509450739547\n",
      "Train Loss 3665: 20.809116636228335\n",
      "Train Loss 3666: 20.808723846817582\n",
      "Train Loss 3667: 20.80833108249395\n",
      "Train Loss 3668: 20.80793834324414\n",
      "Train Loss 3669: 20.80754562905482\n",
      "Train Loss 3670: 20.807152936498298\n",
      "Train Loss 3671: 20.806760264561063\n",
      "Train Loss 3672: 20.806367617655376\n",
      "Train Loss 3673: 20.80597501256346\n",
      "Train Loss 3674: 20.805582454077875\n",
      "Train Loss 3675: 20.80518990222861\n",
      "Train Loss 3676: 20.80479732680277\n",
      "Train Loss 3677: 20.80440477168855\n",
      "Train Loss 3678: 20.80401224146912\n",
      "Train Loss 3679: 20.80361973613134\n",
      "Train Loss 3680: 20.80322725566203\n",
      "Train Loss 3681: 20.80283479685949\n",
      "Train Loss 3682: 20.802442339808692\n",
      "Train Loss 3683: 20.80204990088795\n",
      "Train Loss 3684: 20.801657486826\n",
      "Train Loss 3685: 20.801265097609715\n",
      "Train Loss 3686: 20.80087272923288\n",
      "Train Loss 3687: 20.800480383422578\n",
      "Train Loss 3688: 20.800088062414375\n",
      "Train Loss 3689: 20.799695765585295\n",
      "Train Loss 3690: 20.799303489108045\n",
      "Train Loss 3691: 20.79891126026968\n",
      "Train Loss 3692: 20.79851904468936\n",
      "Train Loss 3693: 20.798126844623958\n",
      "Train Loss 3694: 20.7977346692226\n",
      "Train Loss 3695: 20.797342518472345\n",
      "Train Loss 3696: 20.79695039236026\n",
      "Train Loss 3697: 20.79655829211355\n",
      "Train Loss 3698: 20.79616621974705\n",
      "Train Loss 3699: 20.795774168304142\n",
      "Train Loss 3700: 20.79538212100465\n",
      "Train Loss 3701: 20.794990090002088\n",
      "Train Loss 3702: 20.794598081420844\n",
      "Train Loss 3703: 20.79420608781205\n",
      "Train Loss 3704: 20.793814116062006\n",
      "Train Loss 3705: 20.793422159993\n",
      "Train Loss 3706: 20.793030257595543\n",
      "Train Loss 3707: 20.792638420682273\n",
      "Train Loss 3708: 20.792246615225345\n",
      "Train Loss 3709: 20.791854834041594\n",
      "Train Loss 3710: 20.791463077118326\n",
      "Train Loss 3711: 20.79107134444284\n",
      "Train Loss 3712: 20.790679636002444\n",
      "Train Loss 3713: 20.790287952357023\n",
      "Train Loss 3714: 20.789896294667045\n",
      "Train Loss 3715: 20.789504664389572\n",
      "Train Loss 3716: 20.78911307118088\n",
      "Train Loss 3717: 20.788721493142553\n",
      "Train Loss 3718: 20.78832993016534\n",
      "Train Loss 3719: 20.787938392019274\n",
      "Train Loss 3720: 20.787546908133905\n",
      "Train Loss 3721: 20.78715545130193\n",
      "Train Loss 3722: 20.786764032009188\n",
      "Train Loss 3723: 20.786372663316584\n",
      "Train Loss 3724: 20.7859813153602\n",
      "Train Loss 3725: 20.78558998411091\n",
      "Train Loss 3726: 20.78519867666654\n",
      "Train Loss 3727: 20.784807393014766\n",
      "Train Loss 3728: 20.784416132225733\n",
      "Train Loss 3729: 20.784024891380074\n",
      "Train Loss 3730: 20.783633674150323\n",
      "Train Loss 3731: 20.783242468999724\n",
      "Train Loss 3732: 20.78285128519671\n",
      "Train Loss 3733: 20.78246011670529\n",
      "Train Loss 3734: 20.78206897191204\n",
      "Train Loss 3735: 20.781677845371647\n",
      "Train Loss 3736: 20.78128673650503\n",
      "Train Loss 3737: 20.78089565131568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 3738: 20.780504587012487\n",
      "Train Loss 3739: 20.780113538670054\n",
      "Train Loss 3740: 20.779722525635577\n",
      "Train Loss 3741: 20.779331556588698\n",
      "Train Loss 3742: 20.778940605888987\n",
      "Train Loss 3743: 20.778549678760825\n",
      "Train Loss 3744: 20.778158775192068\n",
      "Train Loss 3745: 20.777767895170577\n",
      "Train Loss 3746: 20.77737703868421\n",
      "Train Loss 3747: 20.776986205720835\n",
      "Train Loss 3748: 20.776595434691487\n",
      "Train Loss 3749: 20.776204820005287\n",
      "Train Loss 3750: 20.775814228199955\n",
      "Train Loss 3751: 20.77542363327172\n",
      "Train Loss 3752: 20.77503303207506\n",
      "Train Loss 3753: 20.774642453562127\n",
      "Train Loss 3754: 20.774251887661023\n",
      "Train Loss 3755: 20.773861345060034\n",
      "Train Loss 3756: 20.773470825746976\n",
      "Train Loss 3757: 20.773080329709657\n",
      "Train Loss 3758: 20.77268985693591\n",
      "Train Loss 3759: 20.772299407282112\n",
      "Train Loss 3760: 20.77190898230927\n",
      "Train Loss 3761: 20.77151858786891\n",
      "Train Loss 3762: 20.771128208296638\n",
      "Train Loss 3763: 20.770737843688384\n",
      "Train Loss 3764: 20.770347502686604\n",
      "Train Loss 3765: 20.76995718724886\n",
      "Train Loss 3766: 20.76956689490869\n",
      "Train Loss 3767: 20.769176625654126\n",
      "Train Loss 3768: 20.768786364834057\n",
      "Train Loss 3769: 20.768396088197257\n",
      "Train Loss 3770: 20.768005787023775\n",
      "Train Loss 3771: 20.76761550841196\n",
      "Train Loss 3772: 20.76722522902636\n",
      "Train Loss 3773: 20.76683490655367\n",
      "Train Loss 3774: 20.766444586623845\n",
      "Train Loss 3775: 20.76605426530216\n",
      "Train Loss 3776: 20.765663972297308\n",
      "Train Loss 3777: 20.765273702298014\n",
      "Train Loss 3778: 20.76488345529269\n",
      "Train Loss 3779: 20.76449322638206\n",
      "Train Loss 3780: 20.76410300564334\n",
      "Train Loss 3781: 20.76371280789255\n",
      "Train Loss 3782: 20.76332263115016\n",
      "Train Loss 3783: 20.76293249077957\n",
      "Train Loss 3784: 20.76254237088852\n",
      "Train Loss 3785: 20.76215223996189\n",
      "Train Loss 3786: 20.761762131941143\n",
      "Train Loss 3787: 20.76137204681488\n",
      "Train Loss 3788: 20.76098198457167\n",
      "Train Loss 3789: 20.76059196792747\n",
      "Train Loss 3790: 20.76020201160708\n",
      "Train Loss 3791: 20.75981207800162\n",
      "Train Loss 3792: 20.759422167099828\n",
      "Train Loss 3793: 20.759032278890437\n",
      "Train Loss 3794: 20.758642410911378\n",
      "Train Loss 3795: 20.758252558225948\n",
      "Train Loss 3796: 20.757862728212856\n",
      "Train Loss 3797: 20.75747292392414\n",
      "Train Loss 3798: 20.757083152916003\n",
      "Train Loss 3799: 20.7566934039279\n",
      "Train Loss 3800: 20.756303669823872\n",
      "Train Loss 3801: 20.755913926680677\n",
      "Train Loss 3802: 20.755524204595602\n",
      "Train Loss 3803: 20.755134502917056\n",
      "Train Loss 3804: 20.75474481076685\n",
      "Train Loss 3805: 20.75435514778688\n",
      "Train Loss 3806: 20.753965529673994\n",
      "Train Loss 3807: 20.753575928717265\n",
      "Train Loss 3808: 20.753186341086067\n",
      "Train Loss 3809: 20.752796775816883\n",
      "Train Loss 3810: 20.752407232898715\n",
      "Train Loss 3811: 20.752017712320544\n",
      "Train Loss 3812: 20.751628211473715\n",
      "Train Loss 3813: 20.75123872702127\n",
      "Train Loss 3814: 20.750849260579\n",
      "Train Loss 3815: 20.750459810104566\n",
      "Train Loss 3816: 20.750070381946326\n",
      "Train Loss 3817: 20.749680972872124\n",
      "Train Loss 3818: 20.749291579197486\n",
      "Train Loss 3819: 20.748902207819274\n",
      "Train Loss 3820: 20.7485128587265\n",
      "Train Loss 3821: 20.748123524452108\n",
      "Train Loss 3822: 20.747734200563748\n",
      "Train Loss 3823: 20.747344898954623\n",
      "Train Loss 3824: 20.746955620616845\n",
      "Train Loss 3825: 20.746566365955864\n",
      "Train Loss 3826: 20.746177133528256\n",
      "Train Loss 3827: 20.745787923323064\n",
      "Train Loss 3828: 20.74539873532933\n",
      "Train Loss 3829: 20.745009567135202\n",
      "Train Loss 3830: 20.744620416315385\n",
      "Train Loss 3831: 20.744231308554554\n",
      "Train Loss 3832: 20.743842222939897\n",
      "Train Loss 3833: 20.743453138816946\n",
      "Train Loss 3834: 20.74306404674637\n",
      "Train Loss 3835: 20.74267497414521\n",
      "Train Loss 3836: 20.74228592360937\n",
      "Train Loss 3837: 20.741896895127933\n",
      "Train Loss 3838: 20.74150788868997\n",
      "Train Loss 3839: 20.741118904284573\n",
      "Train Loss 3840: 20.740729941012685\n",
      "Train Loss 3841: 20.740340990617085\n",
      "Train Loss 3842: 20.739952053482767\n",
      "Train Loss 3843: 20.739563138364804\n",
      "Train Loss 3844: 20.739174256961963\n",
      "Train Loss 3845: 20.73878541267031\n",
      "Train Loss 3846: 20.738396589535462\n",
      "Train Loss 3847: 20.738007787903122\n",
      "Train Loss 3848: 20.737618997782967\n",
      "Train Loss 3849: 20.73723020103979\n",
      "Train Loss 3850: 20.736841357639044\n",
      "Train Loss 3851: 20.73645253617436\n",
      "Train Loss 3852: 20.736063725245522\n",
      "Train Loss 3853: 20.735674886087107\n",
      "Train Loss 3854: 20.735286043440606\n",
      "Train Loss 3855: 20.734897224656077\n",
      "Train Loss 3856: 20.73450844844436\n",
      "Train Loss 3857: 20.734119691572552\n",
      "Train Loss 3858: 20.733730951898345\n",
      "Train Loss 3859: 20.733342234171626\n",
      "Train Loss 3860: 20.732953540839723\n",
      "Train Loss 3861: 20.7325648842082\n",
      "Train Loss 3862: 20.73217624945378\n",
      "Train Loss 3863: 20.731787632953754\n",
      "Train Loss 3864: 20.731399022406578\n",
      "Train Loss 3865: 20.731010433705308\n",
      "Train Loss 3866: 20.730621866839357\n",
      "Train Loss 3867: 20.73023332179815\n",
      "Train Loss 3868: 20.729844797730106\n",
      "Train Loss 3869: 20.72945628694647\n",
      "Train Loss 3870: 20.72906779355687\n",
      "Train Loss 3871: 20.728679306865263\n",
      "Train Loss 3872: 20.72829084198538\n",
      "Train Loss 3873: 20.72790238511171\n",
      "Train Loss 3874: 20.72751393443156\n",
      "Train Loss 3875: 20.727125505563215\n",
      "Train Loss 3876: 20.72673709849612\n",
      "Train Loss 3877: 20.72634870910494\n",
      "Train Loss 3878: 20.72596032890194\n",
      "Train Loss 3879: 20.72557197046448\n",
      "Train Loss 3880: 20.725183633782063\n",
      "Train Loss 3881: 20.72479531684153\n",
      "Train Loss 3882: 20.724406997366074\n",
      "Train Loss 3883: 20.724018668287787\n",
      "Train Loss 3884: 20.72363036098433\n",
      "Train Loss 3885: 20.723242075445253\n",
      "Train Loss 3886: 20.722853810466212\n",
      "Train Loss 3887: 20.722465560291436\n",
      "Train Loss 3888: 20.722077311038063\n",
      "Train Loss 3889: 20.721689039780195\n",
      "Train Loss 3890: 20.72130078576788\n",
      "Train Loss 3891: 20.720912547461293\n",
      "Train Loss 3892: 20.720524330842522\n",
      "Train Loss 3893: 20.720136135901186\n",
      "Train Loss 3894: 20.719747966337497\n",
      "Train Loss 3895: 20.71935983992301\n",
      "Train Loss 3896: 20.71897172313415\n",
      "Train Loss 3897: 20.71858362563299\n",
      "Train Loss 3898: 20.718195557545812\n",
      "Train Loss 3899: 20.71780750376069\n",
      "Train Loss 3900: 20.717419471541895\n",
      "Train Loss 3901: 20.717031458659335\n",
      "Train Loss 3902: 20.71664343585502\n",
      "Train Loss 3903: 20.716255430382752\n",
      "Train Loss 3904: 20.715867425199594\n",
      "Train Loss 3905: 20.715479423751216\n",
      "Train Loss 3906: 20.71509144384512\n",
      "Train Loss 3907: 20.714703485471176\n",
      "Train Loss 3908: 20.714315572840267\n",
      "Train Loss 3909: 20.713927711431722\n",
      "Train Loss 3910: 20.713539871404894\n",
      "Train Loss 3911: 20.713152048701357\n",
      "Train Loss 3912: 20.712764243237658\n",
      "Train Loss 3913: 20.712376459137296\n",
      "Train Loss 3914: 20.7119886949929\n",
      "Train Loss 3915: 20.711600942904195\n",
      "Train Loss 3916: 20.711213208319588\n",
      "Train Loss 3917: 20.710825490195557\n",
      "Train Loss 3918: 20.710437791784873\n",
      "Train Loss 3919: 20.710050111829226\n",
      "Train Loss 3920: 20.709662471476044\n",
      "Train Loss 3921: 20.709274857260063\n",
      "Train Loss 3922: 20.708887270669155\n",
      "Train Loss 3923: 20.7084997041707\n",
      "Train Loss 3924: 20.7081121503844\n",
      "Train Loss 3925: 20.707724617821626\n",
      "Train Loss 3926: 20.70733709971752\n",
      "Train Loss 3927: 20.70694961173181\n",
      "Train Loss 3928: 20.706562164365028\n",
      "Train Loss 3929: 20.706174738108132\n",
      "Train Loss 3930: 20.70578733295137\n",
      "Train Loss 3931: 20.705399948885013\n",
      "Train Loss 3932: 20.7050125743804\n",
      "Train Loss 3933: 20.70462520639223\n",
      "Train Loss 3934: 20.70423785948055\n",
      "Train Loss 3935: 20.703850521626517\n",
      "Train Loss 3936: 20.703463169198358\n",
      "Train Loss 3937: 20.703075837866535\n",
      "Train Loss 3938: 20.70268852762138\n",
      "Train Loss 3939: 20.702301238453202\n",
      "Train Loss 3940: 20.701913970352333\n",
      "Train Loss 3941: 20.701526741272776\n",
      "Train Loss 3942: 20.70113954401682\n",
      "Train Loss 3943: 20.700752367741472\n",
      "Train Loss 3944: 20.700365212437156\n",
      "Train Loss 3945: 20.699978078094283\n",
      "Train Loss 3946: 20.69959096470328\n",
      "Train Loss 3947: 20.699203872254564\n",
      "Train Loss 3948: 20.698816800738555\n",
      "Train Loss 3949: 20.698429748354275\n",
      "Train Loss 3950: 20.69804270857616\n",
      "Train Loss 3951: 20.69765568971604\n",
      "Train Loss 3952: 20.69726869176434\n",
      "Train Loss 3953: 20.6968817147115\n",
      "Train Loss 3954: 20.69649475854793\n",
      "Train Loss 3955: 20.696107819767416\n",
      "Train Loss 3956: 20.695720893081468\n",
      "Train Loss 3957: 20.695333943096962\n",
      "Train Loss 3958: 20.694947009282174\n",
      "Train Loss 3959: 20.6945600737375\n",
      "Train Loss 3960: 20.694173123003793\n",
      "Train Loss 3961: 20.693786193170013\n",
      "Train Loss 3962: 20.693399283933168\n",
      "Train Loss 3963: 20.69301240805064\n",
      "Train Loss 3964: 20.692625577640825\n",
      "Train Loss 3965: 20.69223876803801\n",
      "Train Loss 3966: 20.69185197933231\n",
      "Train Loss 3967: 20.69146521385432\n",
      "Train Loss 3968: 20.691078469145985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 3969: 20.69069174700568\n",
      "Train Loss 3970: 20.69030506970494\n",
      "Train Loss 3971: 20.689918413091778\n",
      "Train Loss 3972: 20.689531778970654\n",
      "Train Loss 3973: 20.68914521160803\n",
      "Train Loss 3974: 20.68875866480334\n",
      "Train Loss 3975: 20.688372138547372\n",
      "Train Loss 3976: 20.687985631027978\n",
      "Train Loss 3977: 20.687599131049698\n",
      "Train Loss 3978: 20.68721261431508\n",
      "Train Loss 3979: 20.68682611244436\n",
      "Train Loss 3980: 20.68643959437022\n",
      "Train Loss 3981: 20.686053079162104\n",
      "Train Loss 3982: 20.685666584517133\n",
      "Train Loss 3983: 20.6852801104262\n",
      "Train Loss 3984: 20.68489365688019\n",
      "Train Loss 3985: 20.684507223556373\n",
      "Train Loss 3986: 20.684120805978612\n",
      "Train Loss 3987: 20.683734408205677\n",
      "Train Loss 3988: 20.68334802474758\n",
      "Train Loss 3989: 20.68296166361595\n",
      "Train Loss 3990: 20.682575325557718\n",
      "Train Loss 3991: 20.682189007988605\n",
      "Train Loss 3992: 20.68180270335142\n",
      "Train Loss 3993: 20.681416400799662\n",
      "Train Loss 3994: 20.68103010525779\n",
      "Train Loss 3995: 20.680643809648167\n",
      "Train Loss 3996: 20.680257534495745\n",
      "Train Loss 3997: 20.679871290547645\n",
      "Train Loss 3998: 20.679485085403627\n",
      "Train Loss 3999: 20.679098897821856\n",
      "Train Loss 4000: 20.67871272413187\n",
      "Train Loss 4001: 20.678326552085316\n",
      "Train Loss 4002: 20.67794040575947\n",
      "Train Loss 4003: 20.677554355966354\n",
      "Train Loss 4004: 20.677168326384813\n",
      "Train Loss 4005: 20.676782317005873\n",
      "Train Loss 4006: 20.676396326159313\n",
      "Train Loss 4007: 20.6760103433851\n",
      "Train Loss 4008: 20.675624337160865\n",
      "Train Loss 4009: 20.675238344016062\n",
      "Train Loss 4010: 20.674852369482622\n",
      "Train Loss 4011: 20.674466401918547\n",
      "Train Loss 4012: 20.674080446445323\n",
      "Train Loss 4013: 20.67369446101089\n",
      "Train Loss 4014: 20.673308475484443\n",
      "Train Loss 4015: 20.672922486973302\n",
      "Train Loss 4016: 20.67253651864669\n",
      "Train Loss 4017: 20.672150570495678\n",
      "Train Loss 4018: 20.671764641765687\n",
      "Train Loss 4019: 20.671378725780396\n",
      "Train Loss 4020: 20.670992829954532\n",
      "Train Loss 4021: 20.670606954279183\n",
      "Train Loss 4022: 20.67022108074237\n",
      "Train Loss 4023: 20.66983519331044\n",
      "Train Loss 4024: 20.66944932606443\n",
      "Train Loss 4025: 20.669063478995486\n",
      "Train Loss 4026: 20.668677652065238\n",
      "Train Loss 4027: 20.66829184526485\n",
      "Train Loss 4028: 20.667906058585473\n",
      "Train Loss 4029: 20.66752030586546\n",
      "Train Loss 4030: 20.667134593080725\n",
      "Train Loss 4031: 20.666748900318098\n",
      "Train Loss 4032: 20.666363233346278\n",
      "Train Loss 4033: 20.66597759355119\n",
      "Train Loss 4034: 20.665591971500174\n",
      "Train Loss 4035: 20.66520637161837\n",
      "Train Loss 4036: 20.66482079164858\n",
      "Train Loss 4037: 20.66443522917965\n",
      "Train Loss 4038: 20.664049680756463\n",
      "Train Loss 4039: 20.66366415122456\n",
      "Train Loss 4040: 20.663278655918628\n",
      "Train Loss 4041: 20.66289320142991\n",
      "Train Loss 4042: 20.66250776679133\n",
      "Train Loss 4043: 20.66212235199424\n",
      "Train Loss 4044: 20.661736953875593\n",
      "Train Loss 4045: 20.661351570730858\n",
      "Train Loss 4046: 20.660966199810225\n",
      "Train Loss 4047: 20.660580848717462\n",
      "Train Loss 4048: 20.660195517443917\n",
      "Train Loss 4049: 20.65981020435643\n",
      "Train Loss 4050: 20.659424905908185\n",
      "Train Loss 4051: 20.659039649713442\n",
      "Train Loss 4052: 20.658654449597204\n",
      "Train Loss 4053: 20.658269272041515\n",
      "Train Loss 4054: 20.657884118921277\n",
      "Train Loss 4055: 20.6574989854596\n",
      "Train Loss 4056: 20.65711387164783\n",
      "Train Loss 4057: 20.656728777477312\n",
      "Train Loss 4058: 20.656343696309804\n",
      "Train Loss 4059: 20.655958605373247\n",
      "Train Loss 4060: 20.655573534008756\n",
      "Train Loss 4061: 20.65518850612921\n",
      "Train Loss 4062: 20.654803522273046\n",
      "Train Loss 4063: 20.65441855789116\n",
      "Train Loss 4064: 20.654033612974974\n",
      "Train Loss 4065: 20.65364868751592\n",
      "Train Loss 4066: 20.653263781505423\n",
      "Train Loss 4067: 20.652878894934922\n",
      "Train Loss 4068: 20.65249402779585\n",
      "Train Loss 4069: 20.652109180079638\n",
      "Train Loss 4070: 20.651724351777723\n",
      "Train Loss 4071: 20.651339542881544\n",
      "Train Loss 4072: 20.650954753382536\n",
      "Train Loss 4073: 20.650569978753783\n",
      "Train Loss 4074: 20.650185218180763\n",
      "Train Loss 4075: 20.64980047585849\n",
      "Train Loss 4076: 20.649415746485257\n",
      "Train Loss 4077: 20.64903103556163\n",
      "Train Loss 4078: 20.648646346981206\n",
      "Train Loss 4079: 20.648261680896468\n",
      "Train Loss 4080: 20.647877034132215\n",
      "Train Loss 4081: 20.64749240667993\n",
      "Train Loss 4082: 20.647107798531117\n",
      "Train Loss 4083: 20.646723209677262\n",
      "Train Loss 4084: 20.646338640360312\n",
      "Train Loss 4085: 20.645954113671774\n",
      "Train Loss 4086: 20.645569606226395\n",
      "Train Loss 4087: 20.64518511646913\n",
      "Train Loss 4088: 20.64480062536267\n",
      "Train Loss 4089: 20.64441615349933\n",
      "Train Loss 4090: 20.644031700870656\n",
      "Train Loss 4091: 20.64364726394749\n",
      "Train Loss 4092: 20.643262853827775\n",
      "Train Loss 4093: 20.64287847301401\n",
      "Train Loss 4094: 20.64249410643375\n",
      "Train Loss 4095: 20.64210975901876\n",
      "Train Loss 4096: 20.641725432309556\n",
      "Train Loss 4097: 20.641341151104978\n",
      "Train Loss 4098: 20.640956856091083\n",
      "Train Loss 4099: 20.640572580202633\n",
      "Train Loss 4100: 20.64018832276016\n",
      "Train Loss 4101: 20.639804076263918\n",
      "Train Loss 4102: 20.639419848878905\n",
      "Train Loss 4103: 20.639035640596845\n",
      "Train Loss 4104: 20.638651451409448\n",
      "Train Loss 4105: 20.638267263179348\n",
      "Train Loss 4106: 20.63788306973174\n",
      "Train Loss 4107: 20.637498894431403\n",
      "Train Loss 4108: 20.637114728509044\n",
      "Train Loss 4109: 20.636730576268096\n",
      "Train Loss 4110: 20.636346443145854\n",
      "Train Loss 4111: 20.635962329134053\n",
      "Train Loss 4112: 20.635578234224436\n",
      "Train Loss 4113: 20.635194158408744\n",
      "Train Loss 4114: 20.634810101547295\n",
      "Train Loss 4115: 20.6344260569254\n",
      "Train Loss 4116: 20.63404203150811\n",
      "Train Loss 4117: 20.63365802515618\n",
      "Train Loss 4118: 20.633274037861373\n",
      "Train Loss 4119: 20.63289008203319\n",
      "Train Loss 4120: 20.632506159889317\n",
      "Train Loss 4121: 20.63212225674445\n",
      "Train Loss 4122: 20.631738372590377\n",
      "Train Loss 4123: 20.63135450741892\n",
      "Train Loss 4124: 20.630970661221877\n",
      "Train Loss 4125: 20.63058683399106\n",
      "Train Loss 4126: 20.63020302571828\n",
      "Train Loss 4127: 20.629819236395345\n",
      "Train Loss 4128: 20.629435466014076\n",
      "Train Loss 4129: 20.629051714318432\n",
      "Train Loss 4130: 20.628667971297862\n",
      "Train Loss 4131: 20.628284262493274\n",
      "Train Loss 4132: 20.627900701920794\n",
      "Train Loss 4133: 20.627517160135795\n",
      "Train Loss 4134: 20.627133637129994\n",
      "Train Loss 4135: 20.626750132895122\n",
      "Train Loss 4136: 20.626366647422913\n",
      "Train Loss 4137: 20.625983180705088\n",
      "Train Loss 4138: 20.625599732733374\n",
      "Train Loss 4139: 20.625216302110772\n",
      "Train Loss 4140: 20.624832862701943\n",
      "Train Loss 4141: 20.624449451537192\n",
      "Train Loss 4142: 20.624066084704197\n",
      "Train Loss 4143: 20.623682736554727\n",
      "Train Loss 4144: 20.623299406786803\n",
      "Train Loss 4145: 20.622916091137707\n",
      "Train Loss 4146: 20.622532794133733\n",
      "Train Loss 4147: 20.62214951576673\n",
      "Train Loss 4148: 20.62176625602854\n",
      "Train Loss 4149: 20.621383010922575\n",
      "Train Loss 4150: 20.620999779026754\n",
      "Train Loss 4151: 20.62061656574942\n",
      "Train Loss 4152: 20.62023337108242\n",
      "Train Loss 4153: 20.619850195017612\n",
      "Train Loss 4154: 20.619467037546844\n",
      "Train Loss 4155: 20.619083898661962\n",
      "Train Loss 4156: 20.618700778354825\n",
      "Train Loss 4157: 20.61831767661729\n",
      "Train Loss 4158: 20.617934593441213\n",
      "Train Loss 4159: 20.61755152881846\n",
      "Train Loss 4160: 20.617168481787214\n",
      "Train Loss 4161: 20.61678544664692\n",
      "Train Loss 4162: 20.616402430047746\n",
      "Train Loss 4163: 20.616019431965583\n",
      "Train Loss 4164: 20.615636451638657\n",
      "Train Loss 4165: 20.615253489818805\n",
      "Train Loss 4166: 20.614870543715092\n",
      "Train Loss 4167: 20.614487610400914\n",
      "Train Loss 4168: 20.614104689800133\n",
      "Train Loss 4169: 20.61372178769795\n",
      "Train Loss 4170: 20.61333889576928\n",
      "Train Loss 4171: 20.61295598081601\n",
      "Train Loss 4172: 20.612573088933804\n",
      "Train Loss 4173: 20.612190229925268\n",
      "Train Loss 4174: 20.611807385537002\n",
      "Train Loss 4175: 20.611424548430946\n",
      "Train Loss 4176: 20.61104171929009\n",
      "Train Loss 4177: 20.610658908574933\n",
      "Train Loss 4178: 20.61027611627749\n",
      "Train Loss 4179: 20.609893342389753\n",
      "Train Loss 4180: 20.609510586903728\n",
      "Train Loss 4181: 20.609127849811422\n",
      "Train Loss 4182: 20.608745131104843\n",
      "Train Loss 4183: 20.608362430775994\n",
      "Train Loss 4184: 20.607979743836232\n",
      "Train Loss 4185: 20.60759706821789\n",
      "Train Loss 4186: 20.607214410966474\n",
      "Train Loss 4187: 20.60683177207402\n",
      "Train Loss 4188: 20.606449151532555\n",
      "Train Loss 4189: 20.60606656659404\n",
      "Train Loss 4190: 20.60568403103676\n",
      "Train Loss 4191: 20.605301513299136\n",
      "Train Loss 4192: 20.604919005798624\n",
      "Train Loss 4193: 20.604536516515072\n",
      "Train Loss 4194: 20.604154045440673\n",
      "Train Loss 4195: 20.603771590919585\n",
      "Train Loss 4196: 20.603389146407384\n",
      "Train Loss 4197: 20.603006714003477\n",
      "Train Loss 4198: 20.60262429682328\n",
      "Train Loss 4199: 20.602241891605637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 4200: 20.60185949696498\n",
      "Train Loss 4201: 20.601477109046616\n",
      "Train Loss 4202: 20.60109473523579\n",
      "Train Loss 4203: 20.60071237963517\n",
      "Train Loss 4204: 20.600330042236983\n",
      "Train Loss 4205: 20.599947722940186\n",
      "Train Loss 4206: 20.599565411034224\n",
      "Train Loss 4207: 20.599183109024843\n",
      "Train Loss 4208: 20.598800808812673\n",
      "Train Loss 4209: 20.598418526841165\n",
      "Train Loss 4210: 20.598036263102454\n",
      "Train Loss 4211: 20.59765401758872\n",
      "Train Loss 4212: 20.59727178829144\n",
      "Train Loss 4213: 20.59688956885801\n",
      "Train Loss 4214: 20.59650736762876\n",
      "Train Loss 4215: 20.59612518459587\n",
      "Train Loss 4216: 20.59574301975153\n",
      "Train Loss 4217: 20.595360867444104\n",
      "Train Loss 4218: 20.594978727490755\n",
      "Train Loss 4219: 20.594596605695163\n",
      "Train Loss 4220: 20.594214496513615\n",
      "Train Loss 4221: 20.59383239942127\n",
      "Train Loss 4222: 20.59345032047582\n",
      "Train Loss 4223: 20.593068259669522\n",
      "Train Loss 4224: 20.59268620852845\n",
      "Train Loss 4225: 20.592304158282644\n",
      "Train Loss 4226: 20.591922104024484\n",
      "Train Loss 4227: 20.59154005990488\n",
      "Train Loss 4228: 20.591158035887617\n",
      "Train Loss 4229: 20.590776040819733\n",
      "Train Loss 4230: 20.59039406338916\n",
      "Train Loss 4231: 20.59001210230286\n",
      "Train Loss 4232: 20.58963015926074\n",
      "Train Loss 4233: 20.58924823425516\n",
      "Train Loss 4234: 20.588866327278502\n",
      "Train Loss 4235: 20.588484438323142\n",
      "Train Loss 4236: 20.588102567381462\n",
      "Train Loss 4237: 20.587720711553956\n",
      "Train Loss 4238: 20.587338864533525\n",
      "Train Loss 4239: 20.586957036229286\n",
      "Train Loss 4240: 20.586575227174336\n",
      "Train Loss 4241: 20.586193436074318\n",
      "Train Loss 4242: 20.585811662921696\n",
      "Train Loss 4243: 20.585429902256454\n",
      "Train Loss 4244: 20.58504815375216\n",
      "Train Loss 4245: 20.58466642318726\n",
      "Train Loss 4246: 20.584284708343898\n",
      "Train Loss 4247: 20.58390300560293\n",
      "Train Loss 4248: 20.58352132078964\n",
      "Train Loss 4249: 20.58313965389646\n",
      "Train Loss 4250: 20.58275800491587\n",
      "Train Loss 4251: 20.58237637361586\n",
      "Train Loss 4252: 20.581994756053582\n",
      "Train Loss 4253: 20.581613156369023\n",
      "Train Loss 4254: 20.58123159365818\n",
      "Train Loss 4255: 20.580850116634547\n",
      "Train Loss 4256: 20.580468734439695\n",
      "Train Loss 4257: 20.580087364747087\n",
      "Train Loss 4258: 20.579706012735905\n",
      "Train Loss 4259: 20.579324677855602\n",
      "Train Loss 4260: 20.578943350854676\n",
      "Train Loss 4261: 20.57856203843703\n",
      "Train Loss 4262: 20.57818076373547\n",
      "Train Loss 4263: 20.577799614742773\n",
      "Train Loss 4264: 20.577418481943898\n",
      "Train Loss 4265: 20.577037359415247\n",
      "Train Loss 4266: 20.57665625508939\n",
      "Train Loss 4267: 20.576275206252493\n",
      "Train Loss 4268: 20.575894174852262\n",
      "Train Loss 4269: 20.575513158163083\n",
      "Train Loss 4270: 20.5751321530152\n",
      "Train Loss 4271: 20.574751165294547\n",
      "Train Loss 4272: 20.57437019499368\n",
      "Train Loss 4273: 20.573989234788627\n",
      "Train Loss 4274: 20.57360826731112\n",
      "Train Loss 4275: 20.573227318848666\n",
      "Train Loss 4276: 20.572846382104284\n",
      "Train Loss 4277: 20.57246547162072\n",
      "Train Loss 4278: 20.572084601599972\n",
      "Train Loss 4279: 20.571703742803503\n",
      "Train Loss 4280: 20.571322901273444\n",
      "Train Loss 4281: 20.57094207700252\n",
      "Train Loss 4282: 20.57056126998347\n",
      "Train Loss 4283: 20.570180462453386\n",
      "Train Loss 4284: 20.569799651781057\n",
      "Train Loss 4285: 20.56941886205279\n",
      "Train Loss 4286: 20.569038105837745\n",
      "Train Loss 4287: 20.56865736685052\n",
      "Train Loss 4288: 20.568276645083905\n",
      "Train Loss 4289: 20.567895940530708\n",
      "Train Loss 4290: 20.567515253183714\n",
      "Train Loss 4291: 20.567134583201216\n",
      "Train Loss 4292: 20.566753952938328\n",
      "Train Loss 4293: 20.56637336631703\n",
      "Train Loss 4294: 20.565992788265532\n",
      "Train Loss 4295: 20.565612217797387\n",
      "Train Loss 4296: 20.56523164824641\n",
      "Train Loss 4297: 20.564851095733445\n",
      "Train Loss 4298: 20.56447056025151\n",
      "Train Loss 4299: 20.56409003971188\n",
      "Train Loss 4300: 20.563709533042594\n",
      "Train Loss 4301: 20.563329037067465\n",
      "Train Loss 4302: 20.562948531137643\n",
      "Train Loss 4303: 20.562568042177414\n",
      "Train Loss 4304: 20.56218757017977\n",
      "Train Loss 4305: 20.56180711513772\n",
      "Train Loss 4306: 20.561426677044263\n",
      "Train Loss 4307: 20.561046255892414\n",
      "Train Loss 4308: 20.56066585167518\n",
      "Train Loss 4309: 20.560285461980847\n",
      "Train Loss 4310: 20.55990508361321\n",
      "Train Loss 4311: 20.55952471644364\n",
      "Train Loss 4312: 20.559144328006546\n",
      "Train Loss 4313: 20.55876395264421\n",
      "Train Loss 4314: 20.558383587276968\n",
      "Train Loss 4315: 20.558003231599795\n",
      "Train Loss 4316: 20.55762289286063\n",
      "Train Loss 4317: 20.55724257105255\n",
      "Train Loss 4318: 20.55686226616865\n",
      "Train Loss 4319: 20.556481978202026\n",
      "Train Loss 4320: 20.55610170714577\n",
      "Train Loss 4321: 20.55572145299297\n",
      "Train Loss 4322: 20.555341215736725\n",
      "Train Loss 4323: 20.5549609872954\n",
      "Train Loss 4324: 20.554580764796857\n",
      "Train Loss 4325: 20.554200559174863\n",
      "Train Loss 4326: 20.55382037042252\n",
      "Train Loss 4327: 20.553440198532968\n",
      "Train Loss 4328: 20.55306003972981\n",
      "Train Loss 4329: 20.552679892764786\n",
      "Train Loss 4330: 20.552299758641233\n",
      "Train Loss 4331: 20.55191963138155\n",
      "Train Loss 4332: 20.551539514052592\n",
      "Train Loss 4333: 20.55115940707849\n",
      "Train Loss 4334: 20.55077930810848\n",
      "Train Loss 4335: 20.550399208374223\n",
      "Train Loss 4336: 20.55001909812781\n",
      "Train Loss 4337: 20.549639007212846\n",
      "Train Loss 4338: 20.549258936033805\n",
      "Train Loss 4339: 20.548878876085425\n",
      "Train Loss 4340: 20.548498832993737\n",
      "Train Loss 4341: 20.548118803524037\n",
      "Train Loss 4342: 20.547738787604562\n",
      "Train Loss 4343: 20.547358788532453\n",
      "Train Loss 4344: 20.54697880630085\n",
      "Train Loss 4345: 20.546598840902888\n",
      "Train Loss 4346: 20.5462188923317\n",
      "Train Loss 4347: 20.545838960580433\n",
      "Train Loss 4348: 20.545459031734655\n",
      "Train Loss 4349: 20.545079096863176\n",
      "Train Loss 4350: 20.5446991751236\n",
      "Train Loss 4351: 20.544319266528287\n",
      "Train Loss 4352: 20.54393937630401\n",
      "Train Loss 4353: 20.543559502897303\n",
      "Train Loss 4354: 20.543179646301336\n",
      "Train Loss 4355: 20.54279980650928\n",
      "Train Loss 4356: 20.542419983514314\n",
      "Train Loss 4357: 20.542040177309616\n",
      "Train Loss 4358: 20.54166038788835\n",
      "Train Loss 4359: 20.541280615243714\n",
      "Train Loss 4360: 20.540900859368882\n",
      "Train Loss 4361: 20.540521118498948\n",
      "Train Loss 4362: 20.540141391628115\n",
      "Train Loss 4363: 20.539761681408837\n",
      "Train Loss 4364: 20.53938198071023\n",
      "Train Loss 4365: 20.539002296748414\n",
      "Train Loss 4366: 20.538622626935496\n",
      "Train Loss 4367: 20.53824296744395\n",
      "Train Loss 4368: 20.53786332468957\n",
      "Train Loss 4369: 20.53748369866558\n",
      "Train Loss 4370: 20.537104089365208\n",
      "Train Loss 4371: 20.536724496781662\n",
      "Train Loss 4372: 20.536344920908185\n",
      "Train Loss 4373: 20.53596535249423\n",
      "Train Loss 4374: 20.535585778263727\n",
      "Train Loss 4375: 20.535206218227135\n",
      "Train Loss 4376: 20.534826670071244\n",
      "Train Loss 4377: 20.534447129725006\n",
      "Train Loss 4378: 20.53406759724188\n",
      "Train Loss 4379: 20.533688086161124\n",
      "Train Loss 4380: 20.53330859175807\n",
      "Train Loss 4381: 20.532929110730105\n",
      "Train Loss 4382: 20.53254961586318\n",
      "Train Loss 4383: 20.532170137680804\n",
      "Train Loss 4384: 20.53179068547577\n",
      "Train Loss 4385: 20.53141126198072\n",
      "Train Loss 4386: 20.53103185512006\n",
      "Train Loss 4387: 20.530652464887122\n",
      "Train Loss 4388: 20.530273091275212\n",
      "Train Loss 4389: 20.529893732407697\n",
      "Train Loss 4390: 20.52951438488051\n",
      "Train Loss 4391: 20.529135043181448\n",
      "Train Loss 4392: 20.528755713465777\n",
      "Train Loss 4393: 20.528376382303666\n",
      "Train Loss 4394: 20.52799704191499\n",
      "Train Loss 4395: 20.52761770764728\n",
      "Train Loss 4396: 20.527238390020486\n",
      "Train Loss 4397: 20.52685908904158\n",
      "Train Loss 4398: 20.5264798326045\n",
      "Train Loss 4399: 20.526100584477447\n",
      "Train Loss 4400: 20.525721321213748\n",
      "Train Loss 4401: 20.52534206621722\n",
      "Train Loss 4402: 20.52496282531998\n",
      "Train Loss 4403: 20.524583596671906\n",
      "Train Loss 4404: 20.524204384630814\n",
      "Train Loss 4405: 20.523825189190116\n",
      "Train Loss 4406: 20.52344601034322\n",
      "Train Loss 4407: 20.523066846518116\n",
      "Train Loss 4408: 20.52268769290063\n",
      "Train Loss 4409: 20.522308555867216\n",
      "Train Loss 4410: 20.521929432213955\n",
      "Train Loss 4411: 20.521550319500022\n",
      "Train Loss 4412: 20.521171223361453\n",
      "Train Loss 4413: 20.520792143791667\n",
      "Train Loss 4414: 20.520413080784078\n",
      "Train Loss 4415: 20.520034054309136\n",
      "Train Loss 4416: 20.519655139597347\n",
      "Train Loss 4417: 20.519276237043403\n",
      "Train Loss 4418: 20.51889734343387\n",
      "Train Loss 4419: 20.518518458317782\n",
      "Train Loss 4420: 20.518139581161293\n",
      "Train Loss 4421: 20.517760715849175\n",
      "Train Loss 4422: 20.51738186676938\n",
      "Train Loss 4423: 20.51700298871094\n",
      "Train Loss 4424: 20.516624087118913\n",
      "Train Loss 4425: 20.516245202029438\n",
      "Train Loss 4426: 20.51586633343589\n",
      "Train Loss 4427: 20.515487481331654\n",
      "Train Loss 4428: 20.51510864571012\n",
      "Train Loss 4429: 20.51472982656467\n",
      "Train Loss 4430: 20.51435102136879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 4431: 20.513972227246228\n",
      "Train Loss 4432: 20.51359345151332\n",
      "Train Loss 4433: 20.51321468932862\n",
      "Train Loss 4434: 20.51283593807013\n",
      "Train Loss 4435: 20.51245722105479\n",
      "Train Loss 4436: 20.512078544732187\n",
      "Train Loss 4437: 20.511699882094533\n",
      "Train Loss 4438: 20.51132122933687\n",
      "Train Loss 4439: 20.5109425929434\n",
      "Train Loss 4440: 20.510563961960415\n",
      "Train Loss 4441: 20.510185333898402\n",
      "Train Loss 4442: 20.509806722210918\n",
      "Train Loss 4443: 20.50942812689146\n",
      "Train Loss 4444: 20.50904954793354\n",
      "Train Loss 4445: 20.50867098533066\n",
      "Train Loss 4446: 20.508292439076335\n",
      "Train Loss 4447: 20.507913910695418\n",
      "Train Loss 4448: 20.507535408108552\n",
      "Train Loss 4449: 20.507156921833698\n",
      "Train Loss 4450: 20.50677845186438\n",
      "Train Loss 4451: 20.506399998194155\n",
      "Train Loss 4452: 20.506021560816556\n",
      "Train Loss 4453: 20.505643135189963\n",
      "Train Loss 4454: 20.505264713369723\n",
      "Train Loss 4455: 20.504886307825622\n",
      "Train Loss 4456: 20.504507918551248\n",
      "Train Loss 4457: 20.50412954554019\n",
      "Train Loss 4458: 20.50375118830402\n",
      "Train Loss 4459: 20.503372850049274\n",
      "Train Loss 4460: 20.502994528008426\n",
      "Train Loss 4461: 20.50261622217511\n",
      "Train Loss 4462: 20.502237930688835\n",
      "Train Loss 4463: 20.501859652389562\n",
      "Train Loss 4464: 20.50148139026485\n",
      "Train Loss 4465: 20.50110314430838\n",
      "Train Loss 4466: 20.500724914513846\n",
      "Train Loss 4467: 20.500346700874935\n",
      "Train Loss 4468: 20.499968503385336\n",
      "Train Loss 4469: 20.499590322038742\n",
      "Train Loss 4470: 20.499212156828843\n",
      "Train Loss 4471: 20.49883400774935\n",
      "Train Loss 4472: 20.498455873674388\n",
      "Train Loss 4473: 20.49807774836187\n",
      "Train Loss 4474: 20.497699639170122\n",
      "Train Loss 4475: 20.497321546092856\n",
      "Train Loss 4476: 20.496943460172425\n",
      "Train Loss 4477: 20.496565382930758\n",
      "Train Loss 4478: 20.49618733589988\n",
      "Train Loss 4479: 20.495809307469262\n",
      "Train Loss 4480: 20.495431295076255\n",
      "Train Loss 4481: 20.495053298714662\n",
      "Train Loss 4482: 20.494675318378295\n",
      "Train Loss 4483: 20.494297354060965\n",
      "Train Loss 4484: 20.493919399943223\n",
      "Train Loss 4485: 20.493541441101208\n",
      "Train Loss 4486: 20.493163498281266\n",
      "Train Loss 4487: 20.492785561119206\n",
      "Train Loss 4488: 20.492407627834215\n",
      "Train Loss 4489: 20.492029706399762\n",
      "Train Loss 4490: 20.491651790089477\n",
      "Train Loss 4491: 20.49127392976751\n",
      "Train Loss 4492: 20.4908960854449\n",
      "Train Loss 4493: 20.49051825711552\n",
      "Train Loss 4494: 20.490140444773232\n",
      "Train Loss 4495: 20.48976264841191\n",
      "Train Loss 4496: 20.48938486802543\n",
      "Train Loss 4497: 20.489007103607655\n",
      "Train Loss 4498: 20.48862938001577\n",
      "Train Loss 4499: 20.48825170409185\n",
      "Train Loss 4500: 20.487874043952786\n",
      "Train Loss 4501: 20.487496391391222\n",
      "Train Loss 4502: 20.487118754695693\n",
      "Train Loss 4503: 20.48674112661745\n",
      "Train Loss 4504: 20.486363532102214\n",
      "Train Loss 4505: 20.48598595330537\n",
      "Train Loss 4506: 20.485608390220985\n",
      "Train Loss 4507: 20.485230842843112\n",
      "Train Loss 4508: 20.484853311165814\n",
      "Train Loss 4509: 20.48447579518315\n",
      "Train Loss 4510: 20.48409829454193\n",
      "Train Loss 4511: 20.48372077946651\n",
      "Train Loss 4512: 20.48334328009515\n",
      "Train Loss 4513: 20.482965784289522\n",
      "Train Loss 4514: 20.48258828457425\n",
      "Train Loss 4515: 20.482210795388315\n",
      "Train Loss 4516: 20.481833321918565\n",
      "Train Loss 4517: 20.481455864159102\n",
      "Train Loss 4518: 20.481078410339652\n",
      "Train Loss 4519: 20.480700929074104\n",
      "Train Loss 4520: 20.48032346324787\n",
      "Train Loss 4521: 20.479946011980967\n",
      "Train Loss 4522: 20.479568576414103\n",
      "Train Loss 4523: 20.47919114716343\n",
      "Train Loss 4524: 20.47881370740642\n",
      "Train Loss 4525: 20.478436283366285\n",
      "Train Loss 4526: 20.4780589234958\n",
      "Train Loss 4527: 20.477681641274607\n",
      "Train Loss 4528: 20.477304374670428\n",
      "Train Loss 4529: 20.47692712367734\n",
      "Train Loss 4530: 20.476549888289437\n",
      "Train Loss 4531: 20.47617266850079\n",
      "Train Loss 4532: 20.475795463778613\n",
      "Train Loss 4533: 20.475418269090035\n",
      "Train Loss 4534: 20.47504108999266\n",
      "Train Loss 4535: 20.474663926480588\n",
      "Train Loss 4536: 20.47428677224479\n",
      "Train Loss 4537: 20.473909620930918\n",
      "Train Loss 4538: 20.473532485196706\n",
      "Train Loss 4539: 20.473155365036256\n",
      "Train Loss 4540: 20.472778260443697\n",
      "Train Loss 4541: 20.47240117228305\n",
      "Train Loss 4542: 20.472024111213283\n",
      "Train Loss 4543: 20.47164706567326\n",
      "Train Loss 4544: 20.471270033744457\n",
      "Train Loss 4545: 20.47089301887888\n",
      "Train Loss 4546: 20.470516035548748\n",
      "Train Loss 4547: 20.47013906981288\n",
      "Train Loss 4548: 20.469762153029187\n",
      "Train Loss 4549: 20.469385243962858\n",
      "Train Loss 4550: 20.469008350307817\n",
      "Train Loss 4551: 20.468631468080243\n",
      "Train Loss 4552: 20.468254584576332\n",
      "Train Loss 4553: 20.467877716480242\n",
      "Train Loss 4554: 20.467500881741003\n",
      "Train Loss 4555: 20.467124089477696\n",
      "Train Loss 4556: 20.466747337717003\n",
      "Train Loss 4557: 20.466370601229837\n",
      "Train Loss 4558: 20.46599388001062\n",
      "Train Loss 4559: 20.46561717405379\n",
      "Train Loss 4560: 20.465240483353778\n",
      "Train Loss 4561: 20.46486380790502\n",
      "Train Loss 4562: 20.46448714770195\n",
      "Train Loss 4563: 20.464110502738997\n",
      "Train Loss 4564: 20.463733873010618\n",
      "Train Loss 4565: 20.463357256772873\n",
      "Train Loss 4566: 20.462980653088785\n",
      "Train Loss 4567: 20.462604064611277\n",
      "Train Loss 4568: 20.46222749133482\n",
      "Train Loss 4569: 20.461850933253892\n",
      "Train Loss 4570: 20.461474390362977\n",
      "Train Loss 4571: 20.461097862656555\n",
      "Train Loss 4572: 20.46072135012911\n",
      "Train Loss 4573: 20.460344852775126\n",
      "Train Loss 4574: 20.45996838525355\n",
      "Train Loss 4575: 20.459591951053163\n",
      "Train Loss 4576: 20.45921553193617\n",
      "Train Loss 4577: 20.45883912458938\n",
      "Train Loss 4578: 20.458462731108217\n",
      "Train Loss 4579: 20.458086371357712\n",
      "Train Loss 4580: 20.457710026658386\n",
      "Train Loss 4581: 20.45733369700487\n",
      "Train Loss 4582: 20.456957382391778\n",
      "Train Loss 4583: 20.456581086555758\n",
      "Train Loss 4584: 20.456204818954372\n",
      "Train Loss 4585: 20.455828572522556\n",
      "Train Loss 4586: 20.455452378638086\n",
      "Train Loss 4587: 20.455076191065544\n",
      "Train Loss 4588: 20.454700000319264\n",
      "Train Loss 4589: 20.454323823882735\n",
      "Train Loss 4590: 20.45394765471353\n",
      "Train Loss 4591: 20.453571499892774\n",
      "Train Loss 4592: 20.453195354218362\n",
      "Train Loss 4593: 20.452819223451225\n",
      "Train Loss 4594: 20.452443107586202\n",
      "Train Loss 4595: 20.45206700504121\n",
      "Train Loss 4596: 20.451690915502805\n",
      "Train Loss 4597: 20.451314845333933\n",
      "Train Loss 4598: 20.450938802013535\n",
      "Train Loss 4599: 20.450562773542426\n",
      "Train Loss 4600: 20.4501867599155\n",
      "Train Loss 4601: 20.449810761127615\n",
      "Train Loss 4602: 20.449434777173675\n",
      "Train Loss 4603: 20.449058808048555\n",
      "Train Loss 4604: 20.44868285374714\n",
      "Train Loss 4605: 20.44830691426433\n",
      "Train Loss 4606: 20.447930989594997\n",
      "Train Loss 4607: 20.44755507973405\n",
      "Train Loss 4608: 20.447179184676376\n",
      "Train Loss 4609: 20.44680330441687\n",
      "Train Loss 4610: 20.446427438731586\n",
      "Train Loss 4611: 20.446051581141376\n",
      "Train Loss 4612: 20.445675716460904\n",
      "Train Loss 4613: 20.445299844400598\n",
      "Train Loss 4614: 20.44492398714344\n",
      "Train Loss 4615: 20.44454814468436\n",
      "Train Loss 4616: 20.4441723170183\n",
      "Train Loss 4617: 20.443796504140202\n",
      "Train Loss 4618: 20.443420706045003\n",
      "Train Loss 4619: 20.44304491690175\n",
      "Train Loss 4620: 20.44266912392981\n",
      "Train Loss 4621: 20.44229334487052\n",
      "Train Loss 4622: 20.44191757543661\n",
      "Train Loss 4623: 20.44154182079375\n",
      "Train Loss 4624: 20.4411660809369\n",
      "Train Loss 4625: 20.44079035586099\n",
      "Train Loss 4626: 20.440414645561006\n",
      "Train Loss 4627: 20.44003895003188\n",
      "Train Loss 4628: 20.43966326926859\n",
      "Train Loss 4629: 20.439287603266088\n",
      "Train Loss 4630: 20.438911952019332\n",
      "Train Loss 4631: 20.43853631552329\n",
      "Train Loss 4632: 20.438160693772936\n",
      "Train Loss 4633: 20.437785086763224\n",
      "Train Loss 4634: 20.43740949448914\n",
      "Train Loss 4635: 20.437033916915812\n",
      "Train Loss 4636: 20.43665832495316\n",
      "Train Loss 4637: 20.436282747743633\n",
      "Train Loss 4638: 20.435907184098756\n",
      "Train Loss 4639: 20.435531630776794\n",
      "Train Loss 4640: 20.435156087387977\n",
      "Train Loss 4641: 20.434780558748216\n",
      "Train Loss 4642: 20.434405046015552\n",
      "Train Loss 4643: 20.434029550529363\n",
      "Train Loss 4644: 20.4336540740157\n",
      "Train Loss 4645: 20.43327860710832\n",
      "Train Loss 4646: 20.432903146944028\n",
      "Train Loss 4647: 20.432527696096226\n",
      "Train Loss 4648: 20.432152250367526\n",
      "Train Loss 4649: 20.431776819307565\n",
      "Train Loss 4650: 20.431401401617755\n",
      "Train Loss 4651: 20.431025989483715\n",
      "Train Loss 4652: 20.430650582967516\n",
      "Train Loss 4653: 20.43027519112894\n",
      "Train Loss 4654: 20.429899805734287\n",
      "Train Loss 4655: 20.429524421049727\n",
      "Train Loss 4656: 20.429149046739\n",
      "Train Loss 4657: 20.428773688279193\n",
      "Train Loss 4658: 20.428398367077882\n",
      "Train Loss 4659: 20.428023060507567\n",
      "Train Loss 4660: 20.42764782806944\n",
      "Train Loss 4661: 20.427272668272135\n",
      "Train Loss 4662: 20.426897522981267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 4663: 20.42652239219189\n",
      "Train Loss 4664: 20.426147275899062\n",
      "Train Loss 4665: 20.425772174097848\n",
      "Train Loss 4666: 20.4253970867833\n",
      "Train Loss 4667: 20.425022013950482\n",
      "Train Loss 4668: 20.42464695039082\n",
      "Train Loss 4669: 20.424271868511557\n",
      "Train Loss 4670: 20.42389680109181\n",
      "Train Loss 4671: 20.42352175474954\n",
      "Train Loss 4672: 20.423146730392638\n",
      "Train Loss 4673: 20.42277172950302\n",
      "Train Loss 4674: 20.422396759886922\n",
      "Train Loss 4675: 20.422021801529358\n",
      "Train Loss 4676: 20.421646853835604\n",
      "Train Loss 4677: 20.421271920525022\n",
      "Train Loss 4678: 20.42089700159274\n",
      "Train Loss 4679: 20.420522097033892\n",
      "Train Loss 4680: 20.420147206843623\n",
      "Train Loss 4681: 20.41977233027156\n",
      "Train Loss 4682: 20.419397463126497\n",
      "Train Loss 4683: 20.41902261034316\n",
      "Train Loss 4684: 20.41864778816587\n",
      "Train Loss 4685: 20.41827299999023\n",
      "Train Loss 4686: 20.417898219166652\n",
      "Train Loss 4687: 20.417523429597257\n",
      "Train Loss 4688: 20.417148654285473\n",
      "Train Loss 4689: 20.41677389081149\n",
      "Train Loss 4690: 20.416399137207062\n",
      "Train Loss 4691: 20.4160243945733\n",
      "Train Loss 4692: 20.415649662490736\n",
      "Train Loss 4693: 20.415274942266507\n",
      "Train Loss 4694: 20.414900230192455\n",
      "Train Loss 4695: 20.414525532358066\n",
      "Train Loss 4696: 20.414150848758617\n",
      "Train Loss 4697: 20.413776180934423\n",
      "Train Loss 4698: 20.41340154419552\n",
      "Train Loss 4699: 20.41302691492154\n",
      "Train Loss 4700: 20.41265228625606\n",
      "Train Loss 4701: 20.412277671790143\n",
      "Train Loss 4702: 20.411903071519102\n",
      "Train Loss 4703: 20.411528485438268\n",
      "Train Loss 4704: 20.411153913542943\n",
      "Train Loss 4705: 20.410779355828467\n",
      "Train Loss 4706: 20.41040481173325\n",
      "Train Loss 4707: 20.41003027649873\n",
      "Train Loss 4708: 20.409655755438806\n",
      "Train Loss 4709: 20.409281248548794\n",
      "Train Loss 4710: 20.40890675582405\n",
      "Train Loss 4711: 20.408532277259877\n",
      "Train Loss 4712: 20.408157812851627\n",
      "Train Loss 4713: 20.407783362093245\n",
      "Train Loss 4714: 20.40740892160331\n",
      "Train Loss 4715: 20.407034495264178\n",
      "Train Loss 4716: 20.40666008307118\n",
      "Train Loss 4717: 20.40628568501966\n",
      "Train Loss 4718: 20.4059112986917\n",
      "Train Loss 4719: 20.405536921149313\n",
      "Train Loss 4720: 20.405162557742308\n",
      "Train Loss 4721: 20.404788208466012\n",
      "Train Loss 4722: 20.404413870417123\n",
      "Train Loss 4723: 20.404039524188427\n",
      "Train Loss 4724: 20.40366519209659\n",
      "Train Loss 4725: 20.403290874136967\n",
      "Train Loss 4726: 20.402916570304917\n",
      "Train Loss 4727: 20.402542280595796\n",
      "Train Loss 4728: 20.40216800500496\n",
      "Train Loss 4729: 20.401793743297006\n",
      "Train Loss 4730: 20.401419489216632\n",
      "Train Loss 4731: 20.401045249249364\n",
      "Train Loss 4732: 20.400671022759084\n",
      "Train Loss 4733: 20.40029680908527\n",
      "Train Loss 4734: 20.39992260160841\n",
      "Train Loss 4735: 20.399548364348476\n",
      "Train Loss 4736: 20.399174118277276\n",
      "Train Loss 4737: 20.398799886347952\n",
      "Train Loss 4738: 20.398425668555916\n",
      "Train Loss 4739: 20.398051466588132\n",
      "Train Loss 4740: 20.397677280662133\n",
      "Train Loss 4741: 20.397303101334305\n",
      "Train Loss 4742: 20.39692892374236\n",
      "Train Loss 4743: 20.396554758730367\n",
      "Train Loss 4744: 20.39618060434818\n",
      "Train Loss 4745: 20.395806461274915\n",
      "Train Loss 4746: 20.39543233619978\n",
      "Train Loss 4747: 20.395058232499867\n",
      "Train Loss 4748: 20.394684138718283\n",
      "Train Loss 4749: 20.394310059022907\n",
      "Train Loss 4750: 20.39393599340919\n",
      "Train Loss 4751: 20.3935619418726\n",
      "Train Loss 4752: 20.39318790440861\n",
      "Train Loss 4753: 20.392813881012678\n",
      "Train Loss 4754: 20.392439871680278\n",
      "Train Loss 4755: 20.392065876406882\n",
      "Train Loss 4756: 20.39169189518796\n",
      "Train Loss 4757: 20.39131792801899\n",
      "Train Loss 4758: 20.390943974895453\n",
      "Train Loss 4759: 20.39057003512531\n",
      "Train Loss 4760: 20.390196105854653\n",
      "Train Loss 4761: 20.389822190621942\n",
      "Train Loss 4762: 20.389448286319038\n",
      "Train Loss 4763: 20.38907439124389\n",
      "Train Loss 4764: 20.38870052096472\n",
      "Train Loss 4765: 20.388326678335787\n",
      "Train Loss 4766: 20.387952844631517\n",
      "Train Loss 4767: 20.38757908437996\n",
      "Train Loss 4768: 20.38720532813918\n",
      "Train Loss 4769: 20.386831590070628\n",
      "Train Loss 4770: 20.3864578702586\n",
      "Train Loss 4771: 20.38608416290992\n",
      "Train Loss 4772: 20.385710465593085\n",
      "Train Loss 4773: 20.385336780301706\n",
      "Train Loss 4774: 20.384963108843525\n",
      "Train Loss 4775: 20.384589447846025\n",
      "Train Loss 4776: 20.38421579500044\n",
      "Train Loss 4777: 20.38384215597593\n",
      "Train Loss 4778: 20.383468530768237\n",
      "Train Loss 4779: 20.38309491937312\n",
      "Train Loss 4780: 20.382721321786335\n",
      "Train Loss 4781: 20.38234773800363\n",
      "Train Loss 4782: 20.381974168020776\n",
      "Train Loss 4783: 20.381600611833523\n",
      "Train Loss 4784: 20.381227069437628\n",
      "Train Loss 4785: 20.380853540828866\n",
      "Train Loss 4786: 20.380480026003003\n",
      "Train Loss 4787: 20.380106524955796\n",
      "Train Loss 4788: 20.37973303853713\n",
      "Train Loss 4789: 20.37935958726706\n",
      "Train Loss 4790: 20.378986149746915\n",
      "Train Loss 4791: 20.37861272597245\n",
      "Train Loss 4792: 20.378239315939446\n",
      "Train Loss 4793: 20.377865919094297\n",
      "Train Loss 4794: 20.377492530718538\n",
      "Train Loss 4795: 20.377119156081932\n",
      "Train Loss 4796: 20.37674578303698\n",
      "Train Loss 4797: 20.37637240685041\n",
      "Train Loss 4798: 20.375999044421732\n",
      "Train Loss 4799: 20.375625695521826\n",
      "Train Loss 4800: 20.375252351691373\n",
      "Train Loss 4801: 20.374879014497907\n",
      "Train Loss 4802: 20.374505691045343\n",
      "Train Loss 4803: 20.374132381329495\n",
      "Train Loss 4804: 20.3737590853462\n",
      "Train Loss 4805: 20.373385803091274\n",
      "Train Loss 4806: 20.373012532038373\n",
      "Train Loss 4807: 20.37263927127272\n",
      "Train Loss 4808: 20.372266024231674\n",
      "Train Loss 4809: 20.37189279091107\n",
      "Train Loss 4810: 20.371519571306727\n",
      "Train Loss 4811: 20.37114636541447\n",
      "Train Loss 4812: 20.37077317323015\n",
      "Train Loss 4813: 20.370399994749587\n",
      "Train Loss 4814: 20.370026829968623\n",
      "Train Loss 4815: 20.36965367750221\n",
      "Train Loss 4816: 20.36928053494737\n",
      "Train Loss 4817: 20.368907404254895\n",
      "Train Loss 4818: 20.368534285826208\n",
      "Train Loss 4819: 20.368161182549873\n",
      "Train Loss 4820: 20.36778808846778\n",
      "Train Loss 4821: 20.367415010625354\n",
      "Train Loss 4822: 20.367041943263974\n",
      "Train Loss 4823: 20.366668889565904\n",
      "Train Loss 4824: 20.366295849526978\n",
      "Train Loss 4825: 20.365922823143034\n",
      "Train Loss 4826: 20.36554981040991\n",
      "Train Loss 4827: 20.365176812083423\n",
      "Train Loss 4828: 20.36480382835703\n",
      "Train Loss 4829: 20.364430858261827\n",
      "Train Loss 4830: 20.364057902160933\n",
      "Train Loss 4831: 20.363684956699586\n",
      "Train Loss 4832: 20.363312009930386\n",
      "Train Loss 4833: 20.36293907676338\n",
      "Train Loss 4834: 20.362566163873055\n",
      "Train Loss 4835: 20.36219329291283\n",
      "Train Loss 4836: 20.361820457734236\n",
      "Train Loss 4837: 20.361447638477962\n",
      "Train Loss 4838: 20.361074834583828\n",
      "Train Loss 4839: 20.360702044200465\n",
      "Train Loss 4840: 20.360329267323813\n",
      "Train Loss 4841: 20.359956503949828\n",
      "Train Loss 4842: 20.35958375407447\n",
      "Train Loss 4843: 20.35921101769367\n",
      "Train Loss 4844: 20.358838294803412\n",
      "Train Loss 4845: 20.358465585399628\n",
      "Train Loss 4846: 20.358092889478286\n",
      "Train Loss 4847: 20.357720206600806\n",
      "Train Loss 4848: 20.35734752594943\n",
      "Train Loss 4849: 20.356974842301668\n",
      "Train Loss 4850: 20.356602172134362\n",
      "Train Loss 4851: 20.356229513286202\n",
      "Train Loss 4852: 20.35585686457521\n",
      "Train Loss 4853: 20.355484229343865\n",
      "Train Loss 4854: 20.355111607588157\n",
      "Train Loss 4855: 20.35473899930409\n",
      "Train Loss 4856: 20.35436640448765\n",
      "Train Loss 4857: 20.35399382388539\n",
      "Train Loss 4858: 20.35362125832043\n",
      "Train Loss 4859: 20.35324870571958\n",
      "Train Loss 4860: 20.352876159925984\n",
      "Train Loss 4861: 20.352503627578116\n",
      "Train Loss 4862: 20.352131107578753\n",
      "Train Loss 4863: 20.351758597788322\n",
      "Train Loss 4864: 20.351386101439157\n",
      "Train Loss 4865: 20.35101361689344\n",
      "Train Loss 4866: 20.350641141288133\n",
      "Train Loss 4867: 20.350268679120212\n",
      "Train Loss 4868: 20.349896230385674\n",
      "Train Loss 4869: 20.349523795080543\n",
      "Train Loss 4870: 20.34915137320081\n",
      "Train Loss 4871: 20.348778964715912\n",
      "Train Loss 4872: 20.34840656499316\n",
      "Train Loss 4873: 20.348034178692178\n",
      "Train Loss 4874: 20.34766180580899\n",
      "Train Loss 4875: 20.34728944633959\n",
      "Train Loss 4876: 20.346917100280006\n",
      "Train Loss 4877: 20.34654476409674\n",
      "Train Loss 4878: 20.34617242648146\n",
      "Train Loss 4879: 20.34580010227458\n",
      "Train Loss 4880: 20.345427791472122\n",
      "Train Loss 4881: 20.345055494070124\n",
      "Train Loss 4882: 20.34468321006463\n",
      "Train Loss 4883: 20.34431094712239\n",
      "Train Loss 4884: 20.343938705971482\n",
      "Train Loss 4885: 20.34356647819363\n",
      "Train Loss 4886: 20.343194263784895\n",
      "Train Loss 4887: 20.342822062741334\n",
      "Train Loss 4888: 20.34244987505899\n",
      "Train Loss 4889: 20.34207769914555\n",
      "Train Loss 4890: 20.341705526482727\n",
      "Train Loss 4891: 20.34133337357964\n",
      "Train Loss 4892: 20.340961249017084\n",
      "Train Loss 4893: 20.34058911207557\n",
      "Train Loss 4894: 20.340216988444833\n",
      "Train Loss 4895: 20.33984487812101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 4896: 20.339472781100245\n",
      "Train Loss 4897: 20.33910069737868\n",
      "Train Loss 4898: 20.338728626397714\n",
      "Train Loss 4899: 20.33835656274822\n",
      "Train Loss 4900: 20.337984512396837\n",
      "Train Loss 4901: 20.337612475339704\n",
      "Train Loss 4902: 20.337240451572967\n",
      "Train Loss 4903: 20.33686844109277\n",
      "Train Loss 4904: 20.336496443895253\n",
      "Train Loss 4905: 20.336124459976567\n",
      "Train Loss 4906: 20.335752488930392\n",
      "Train Loss 4907: 20.335380521317784\n",
      "Train Loss 4908: 20.33500856638178\n",
      "Train Loss 4909: 20.334636618695956\n",
      "Train Loss 4910: 20.3342646789596\n",
      "Train Loss 4911: 20.333892752043575\n",
      "Train Loss 4912: 20.333520831140028\n",
      "Train Loss 4913: 20.33314892228524\n",
      "Train Loss 4914: 20.332777023478535\n",
      "Train Loss 4915: 20.332405137927676\n",
      "Train Loss 4916: 20.332033265628848\n",
      "Train Loss 4917: 20.33166140547111\n",
      "Train Loss 4918: 20.331289554862067\n",
      "Train Loss 4919: 20.330917763141755\n",
      "Train Loss 4920: 20.330545984572495\n",
      "Train Loss 4921: 20.33017422184438\n",
      "Train Loss 4922: 20.329802478418785\n",
      "Train Loss 4923: 20.329430748866372\n",
      "Train Loss 4924: 20.32905903925922\n",
      "Train Loss 4925: 20.32868734276143\n",
      "Train Loss 4926: 20.328315659369363\n",
      "Train Loss 4927: 20.327943989079397\n",
      "Train Loss 4928: 20.32757232652353\n",
      "Train Loss 4929: 20.327200655011822\n",
      "Train Loss 4930: 20.326829013918207\n",
      "Train Loss 4931: 20.326457389485647\n",
      "Train Loss 4932: 20.32608577812591\n",
      "Train Loss 4933: 20.325714179835423\n",
      "Train Loss 4934: 20.325342599731414\n",
      "Train Loss 4935: 20.32497104194054\n",
      "Train Loss 4936: 20.324599497184288\n",
      "Train Loss 4937: 20.32422796457374\n",
      "Train Loss 4938: 20.32385644119762\n",
      "Train Loss 4939: 20.32348493085173\n",
      "Train Loss 4940: 20.323113433532537\n",
      "Train Loss 4941: 20.32274194923652\n",
      "Train Loss 4942: 20.32237047796013\n",
      "Train Loss 4943: 20.321999019699845\n",
      "Train Loss 4944: 20.321627574452137\n",
      "Train Loss 4945: 20.321256142213482\n",
      "Train Loss 4946: 20.32088472194589\n",
      "Train Loss 4947: 20.320513310748474\n",
      "Train Loss 4948: 20.320141909339256\n",
      "Train Loss 4949: 20.319770514015794\n",
      "Train Loss 4950: 20.31939913170823\n",
      "Train Loss 4951: 20.31902776083653\n",
      "Train Loss 4952: 20.31865639946176\n",
      "Train Loss 4953: 20.318285051100993\n",
      "Train Loss 4954: 20.317913716251418\n",
      "Train Loss 4955: 20.317542394577988\n",
      "Train Loss 4956: 20.317171085909823\n",
      "Train Loss 4957: 20.316799790243394\n",
      "Train Loss 4958: 20.31642852163575\n",
      "Train Loss 4959: 20.316057310958485\n",
      "Train Loss 4960: 20.31568611323582\n",
      "Train Loss 4961: 20.31531492846424\n",
      "Train Loss 4962: 20.31494375664023\n",
      "Train Loss 4963: 20.314572597760268\n",
      "Train Loss 4964: 20.314201451820846\n",
      "Train Loss 4965: 20.313830318818447\n",
      "Train Loss 4966: 20.313459198749563\n",
      "Train Loss 4967: 20.31308809161068\n",
      "Train Loss 4968: 20.312716997398297\n",
      "Train Loss 4969: 20.312345916108903\n",
      "Train Loss 4970: 20.311974847738995\n",
      "Train Loss 4971: 20.311603796244754\n",
      "Train Loss 4972: 20.311232766755918\n",
      "Train Loss 4973: 20.310861750150284\n",
      "Train Loss 4974: 20.31049074638809\n",
      "Train Loss 4975: 20.310119751873653\n",
      "Train Loss 4976: 20.309748770239352\n",
      "Train Loss 4977: 20.309377801481716\n",
      "Train Loss 4978: 20.30900684559729\n",
      "Train Loss 4979: 20.30863590258259\n",
      "Train Loss 4980: 20.308264969809713\n",
      "Train Loss 4981: 20.307894046826483\n",
      "Train Loss 4982: 20.307523136712245\n",
      "Train Loss 4983: 20.307152239137725\n",
      "Train Loss 4984: 20.30678134976113\n",
      "Train Loss 4985: 20.3064104740232\n",
      "Train Loss 4986: 20.306039618090562\n",
      "Train Loss 4987: 20.305668767219373\n",
      "Train Loss 4988: 20.305297913430657\n",
      "Train Loss 4989: 20.30492707244814\n",
      "Train Loss 4990: 20.304556250399415\n",
      "Train Loss 4991: 20.30418546085997\n",
      "Train Loss 4992: 20.30381468406806\n",
      "Train Loss 4993: 20.30344392002029\n",
      "Train Loss 4994: 20.303073168713226\n",
      "Train Loss 4995: 20.302702430143476\n",
      "Train Loss 4996: 20.30233170430763\n",
      "Train Loss 4997: 20.30196099120228\n",
      "Train Loss 4998: 20.301590290824016\n",
      "Train Loss 4999: 20.301219603169447\n",
      "Train Loss 5000: 20.30084892818686\n",
      "Train Loss 5001: 20.30047826281752\n",
      "Train Loss 5002: 20.300107610168812\n",
      "Train Loss 5003: 20.29973697023733\n",
      "Train Loss 5004: 20.299366343019667\n",
      "Train Loss 5005: 20.298995728512427\n",
      "Train Loss 5006: 20.298625126712214\n",
      "Train Loss 5007: 20.29825453761563\n",
      "Train Loss 5008: 20.297883961219277\n",
      "Train Loss 5009: 20.297513397519772\n",
      "Train Loss 5010: 20.29714284651371\n",
      "Train Loss 5011: 20.296772308000165\n",
      "Train Loss 5012: 20.29640177268391\n",
      "Train Loss 5013: 20.29603123277303\n",
      "Train Loss 5014: 20.295660705557875\n",
      "Train Loss 5015: 20.295290191035075\n",
      "Train Loss 5016: 20.294919689201247\n",
      "Train Loss 5017: 20.294549200053005\n",
      "Train Loss 5018: 20.29417872358697\n",
      "Train Loss 5019: 20.293808259799768\n",
      "Train Loss 5020: 20.293437808688022\n",
      "Train Loss 5021: 20.29306737024836\n",
      "Train Loss 5022: 20.2926969362684\n",
      "Train Loss 5023: 20.292326493059576\n",
      "Train Loss 5024: 20.291956040143383\n",
      "Train Loss 5025: 20.291585607909102\n",
      "Train Loss 5026: 20.29121520459662\n",
      "Train Loss 5027: 20.290844787113627\n",
      "Train Loss 5028: 20.29047438226913\n",
      "Train Loss 5029: 20.290103987724894\n",
      "Train Loss 5030: 20.28973360164871\n",
      "Train Loss 5031: 20.289363264881906\n",
      "Train Loss 5032: 20.28899300631148\n",
      "Train Loss 5033: 20.288622760278756\n",
      "Train Loss 5034: 20.288252526780433\n",
      "Train Loss 5035: 20.287882305813216\n",
      "Train Loss 5036: 20.287512097373824\n",
      "Train Loss 5037: 20.287141901458966\n",
      "Train Loss 5038: 20.286771718065342\n",
      "Train Loss 5039: 20.286401547189676\n",
      "Train Loss 5040: 20.286031388828686\n",
      "Train Loss 5041: 20.28566124297907\n",
      "Train Loss 5042: 20.28529110963757\n",
      "Train Loss 5043: 20.284920988800884\n",
      "Train Loss 5044: 20.28455088046575\n",
      "Train Loss 5045: 20.28418078462888\n",
      "Train Loss 5046: 20.283810701287006\n",
      "Train Loss 5047: 20.28344063043685\n",
      "Train Loss 5048: 20.283070572075133\n",
      "Train Loss 5049: 20.282700524765925\n",
      "Train Loss 5050: 20.282330485526835\n",
      "Train Loss 5051: 20.281960458773174\n",
      "Train Loss 5052: 20.281590442932245\n",
      "Train Loss 5053: 20.281220436190207\n",
      "Train Loss 5054: 20.280850441930983\n",
      "Train Loss 5055: 20.28048046015129\n",
      "Train Loss 5056: 20.28011049084786\n",
      "Train Loss 5057: 20.279740534017428\n",
      "Train Loss 5058: 20.279370589656725\n",
      "Train Loss 5059: 20.27900065776248\n",
      "Train Loss 5060: 20.278630738331437\n",
      "Train Loss 5061: 20.278260826374396\n",
      "Train Loss 5062: 20.27789091678244\n",
      "Train Loss 5063: 20.277521019664974\n",
      "Train Loss 5064: 20.277151135018734\n",
      "Train Loss 5065: 20.276781262840437\n",
      "Train Loss 5066: 20.276411403126815\n",
      "Train Loss 5067: 20.276041553964966\n",
      "Train Loss 5068: 20.275671714163437\n",
      "Train Loss 5069: 20.27530188457882\n",
      "Train Loss 5070: 20.27493206500011\n",
      "Train Loss 5071: 20.274562257886316\n",
      "Train Loss 5072: 20.274192463234147\n",
      "Train Loss 5073: 20.273822681040336\n",
      "Train Loss 5074: 20.273452904383092\n",
      "Train Loss 5075: 20.273083113122993\n",
      "Train Loss 5076: 20.27271333430054\n",
      "Train Loss 5077: 20.272343567912472\n",
      "Train Loss 5078: 20.27197381395553\n",
      "Train Loss 5079: 20.271604072426452\n",
      "Train Loss 5080: 20.271234343297035\n",
      "Train Loss 5081: 20.27086461897009\n",
      "Train Loss 5082: 20.270494914190696\n",
      "Train Loss 5083: 20.27012522181229\n",
      "Train Loss 5084: 20.269755541831632\n",
      "Train Loss 5085: 20.269385874245486\n",
      "Train Loss 5086: 20.26901621905062\n",
      "Train Loss 5087: 20.268646576243793\n",
      "Train Loss 5088: 20.268276939316756\n",
      "Train Loss 5089: 20.267907305294838\n",
      "Train Loss 5090: 20.26753768478273\n",
      "Train Loss 5091: 20.26716807891889\n",
      "Train Loss 5092: 20.266798480807484\n",
      "Train Loss 5093: 20.26642889506311\n",
      "Train Loss 5094: 20.266059316455202\n",
      "Train Loss 5095: 20.265689723041763\n",
      "Train Loss 5096: 20.265320142010165\n",
      "Train Loss 5097: 20.264950573357225\n",
      "Train Loss 5098: 20.26458101707974\n",
      "Train Loss 5099: 20.264211475850136\n",
      "Train Loss 5100: 20.26384195792053\n",
      "Train Loss 5101: 20.263472452343148\n",
      "Train Loss 5102: 20.263102959114807\n",
      "Train Loss 5103: 20.26273347823232\n",
      "Train Loss 5104: 20.262364011515526\n",
      "Train Loss 5105: 20.261994559554196\n",
      "Train Loss 5106: 20.26162511990562\n",
      "Train Loss 5107: 20.26125569256664\n",
      "Train Loss 5108: 20.260886277534066\n",
      "Train Loss 5109: 20.260516880575796\n",
      "Train Loss 5110: 20.260147521252364\n",
      "Train Loss 5111: 20.25977817417708\n",
      "Train Loss 5112: 20.259408839346822\n",
      "Train Loss 5113: 20.259039516758513\n",
      "Train Loss 5114: 20.258670206409047\n",
      "Train Loss 5115: 20.258300908295332\n",
      "Train Loss 5116: 20.257931629458447\n",
      "Train Loss 5117: 20.257562381239392\n",
      "Train Loss 5118: 20.257193145198073\n",
      "Train Loss 5119: 20.256823921331478\n",
      "Train Loss 5120: 20.256454709636593\n",
      "Train Loss 5121: 20.256085510110406\n",
      "Train Loss 5122: 20.25571632274991\n",
      "Train Loss 5123: 20.2553471475521\n",
      "Train Loss 5124: 20.25497798450687\n",
      "Train Loss 5125: 20.254608830405637\n",
      "Train Loss 5126: 20.25423968846451\n",
      "Train Loss 5127: 20.253870558680465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 5128: 20.253501441050506\n",
      "Train Loss 5129: 20.25313233557163\n",
      "Train Loss 5130: 20.252763242240842\n",
      "Train Loss 5131: 20.252394161055136\n",
      "Train Loss 5132: 20.25202509186209\n",
      "Train Loss 5133: 20.2516560310688\n",
      "Train Loss 5134: 20.251286988417803\n",
      "Train Loss 5135: 20.250917967676116\n",
      "Train Loss 5136: 20.250548958086775\n",
      "Train Loss 5137: 20.25017995862481\n",
      "Train Loss 5138: 20.249810969805207\n",
      "Train Loss 5139: 20.249441991032114\n",
      "Train Loss 5140: 20.249073024372226\n",
      "Train Loss 5141: 20.24870405166648\n",
      "Train Loss 5142: 20.248335051537698\n",
      "Train Loss 5143: 20.247966063534847\n",
      "Train Loss 5144: 20.247597087654945\n",
      "Train Loss 5145: 20.247228123895024\n",
      "Train Loss 5146: 20.2468591722521\n",
      "Train Loss 5147: 20.24649023250271\n",
      "Train Loss 5148: 20.24612129872577\n",
      "Train Loss 5149: 20.245752364739843\n",
      "Train Loss 5150: 20.245383442852287\n",
      "Train Loss 5151: 20.245014533060136\n",
      "Train Loss 5152: 20.24464563401525\n",
      "Train Loss 5153: 20.24427674294177\n",
      "Train Loss 5154: 20.243907859970985\n",
      "Train Loss 5155: 20.243538989097306\n",
      "Train Loss 5156: 20.243170130317747\n",
      "Train Loss 5157: 20.242801283321818\n",
      "Train Loss 5158: 20.24243242319985\n",
      "Train Loss 5159: 20.242063575144144\n",
      "Train Loss 5160: 20.24169473915173\n",
      "Train Loss 5161: 20.241325915219655\n",
      "Train Loss 5162: 20.240957103344957\n",
      "Train Loss 5163: 20.24058830352468\n",
      "Train Loss 5164: 20.240219515847556\n",
      "Train Loss 5165: 20.23985070552463\n",
      "Train Loss 5166: 20.239481891310806\n",
      "Train Loss 5167: 20.239113080637654\n",
      "Train Loss 5168: 20.238744266186618\n",
      "Train Loss 5169: 20.238375463805397\n",
      "Train Loss 5170: 20.238006673491093\n",
      "Train Loss 5171: 20.23763789343859\n",
      "Train Loss 5172: 20.237269122276352\n",
      "Train Loss 5173: 20.236900363181427\n",
      "Train Loss 5174: 20.236531616150934\n",
      "Train Loss 5175: 20.236162881181954\n",
      "Train Loss 5176: 20.23579414726314\n",
      "Train Loss 5177: 20.23542541352001\n",
      "Train Loss 5178: 20.235056691833964\n",
      "Train Loss 5179: 20.234687982202136\n",
      "Train Loss 5180: 20.234319284621648\n",
      "Train Loss 5181: 20.23395059908963\n",
      "Train Loss 5182: 20.233581927257337\n",
      "Train Loss 5183: 20.23321328067836\n",
      "Train Loss 5184: 20.232844645739455\n",
      "Train Loss 5185: 20.232476028043756\n",
      "Train Loss 5186: 20.232107420213797\n",
      "Train Loss 5187: 20.231738805942875\n",
      "Train Loss 5188: 20.23137020366823\n",
      "Train Loss 5189: 20.231001613387065\n",
      "Train Loss 5190: 20.23063304424941\n",
      "Train Loss 5191: 20.230264498369955\n",
      "Train Loss 5192: 20.229895959997783\n",
      "Train Loss 5193: 20.22952743359614\n",
      "Train Loss 5194: 20.229158919162234\n",
      "Train Loss 5195: 20.228790416693293\n",
      "Train Loss 5196: 20.22842192603295\n",
      "Train Loss 5197: 20.22805344278725\n",
      "Train Loss 5198: 20.22768497150692\n",
      "Train Loss 5199: 20.22731651145442\n",
      "Train Loss 5200: 20.226948059188906\n",
      "Train Loss 5201: 20.22657961888873\n",
      "Train Loss 5202: 20.22621119055112\n",
      "Train Loss 5203: 20.22584277329614\n",
      "Train Loss 5204: 20.225474365673627\n",
      "Train Loss 5205: 20.22510597921703\n",
      "Train Loss 5206: 20.22473760469967\n",
      "Train Loss 5207: 20.22436924211879\n",
      "Train Loss 5208: 20.22400089147163\n",
      "Train Loss 5209: 20.223632552755447\n",
      "Train Loss 5210: 20.223264225967473\n",
      "Train Loss 5211: 20.222895911104967\n",
      "Train Loss 5212: 20.222527608165166\n",
      "Train Loss 5213: 20.22215931714533\n",
      "Train Loss 5214: 20.221791038042713\n",
      "Train Loss 5215: 20.22142277085456\n",
      "Train Loss 5216: 20.22105451557813\n",
      "Train Loss 5217: 20.220686272210678\n",
      "Train Loss 5218: 20.22031803885111\n",
      "Train Loss 5219: 20.219949797661595\n",
      "Train Loss 5220: 20.219581580313257\n",
      "Train Loss 5221: 20.219213371580324\n",
      "Train Loss 5222: 20.218845174718194\n",
      "Train Loss 5223: 20.21847698972413\n",
      "Train Loss 5224: 20.218108816595407\n",
      "Train Loss 5225: 20.21774065532931\n",
      "Train Loss 5226: 20.217372497185888\n",
      "Train Loss 5227: 20.21700431163104\n",
      "Train Loss 5228: 20.216636137936263\n",
      "Train Loss 5229: 20.216267976098845\n",
      "Train Loss 5230: 20.21589982611606\n",
      "Train Loss 5231: 20.215531687985205\n",
      "Train Loss 5232: 20.215163561703566\n",
      "Train Loss 5233: 20.214795447268422\n",
      "Train Loss 5234: 20.21442734467708\n",
      "Train Loss 5235: 20.21405925346339\n",
      "Train Loss 5236: 20.213691170125525\n",
      "Train Loss 5237: 20.213323098628283\n",
      "Train Loss 5238: 20.21295503896895\n",
      "Train Loss 5239: 20.212586991144832\n",
      "Train Loss 5240: 20.21221895515321\n",
      "Train Loss 5241: 20.211850930991385\n",
      "Train Loss 5242: 20.211482918656653\n",
      "Train Loss 5243: 20.21111491814632\n",
      "Train Loss 5244: 20.210746928685705\n",
      "Train Loss 5245: 20.21037894515215\n",
      "Train Loss 5246: 20.210010967516393\n",
      "Train Loss 5247: 20.20964300168109\n",
      "Train Loss 5248: 20.209275043565743\n",
      "Train Loss 5249: 20.208907097263136\n",
      "Train Loss 5250: 20.208539177989632\n",
      "Train Loss 5251: 20.208171291583604\n",
      "Train Loss 5252: 20.207803416945268\n",
      "Train Loss 5253: 20.20743555390675\n",
      "Train Loss 5254: 20.207067699603964\n",
      "Train Loss 5255: 20.20669985706581\n",
      "Train Loss 5256: 20.206332033866264\n",
      "Train Loss 5257: 20.205964232651816\n",
      "Train Loss 5258: 20.205596443154796\n",
      "Train Loss 5259: 20.20522866537263\n",
      "Train Loss 5260: 20.204860899302737\n",
      "Train Loss 5261: 20.204493143011526\n",
      "Train Loss 5262: 20.204125401473505\n",
      "Train Loss 5263: 20.20375765518969\n",
      "Train Loss 5264: 20.20338991020606\n",
      "Train Loss 5265: 20.20302217690322\n",
      "Train Loss 5266: 20.20265445525959\n",
      "Train Loss 5267: 20.20228674133853\n",
      "Train Loss 5268: 20.20191903909754\n",
      "Train Loss 5269: 20.201551348534082\n",
      "Train Loss 5270: 20.20118366964563\n",
      "Train Loss 5271: 20.20081600242965\n",
      "Train Loss 5272: 20.200448346883615\n",
      "Train Loss 5273: 20.200080703004996\n",
      "Train Loss 5274: 20.199713070791272\n",
      "Train Loss 5275: 20.19934545023991\n",
      "Train Loss 5276: 20.198977841348388\n",
      "Train Loss 5277: 20.19861024397936\n",
      "Train Loss 5278: 20.198242654472303\n",
      "Train Loss 5279: 20.197875076623166\n",
      "Train Loss 5280: 20.19750750958763\n",
      "Train Loss 5281: 20.197139950364363\n",
      "Train Loss 5282: 20.196772402796867\n",
      "Train Loss 5283: 20.196404866882617\n",
      "Train Loss 5284: 20.1960373426191\n",
      "Train Loss 5285: 20.19566983000378\n",
      "Train Loss 5286: 20.195302327721937\n",
      "Train Loss 5287: 20.194934833494884\n",
      "Train Loss 5288: 20.19456735037292\n",
      "Train Loss 5289: 20.194199873807257\n",
      "Train Loss 5290: 20.193832408408973\n",
      "Train Loss 5291: 20.193464951628386\n",
      "Train Loss 5292: 20.193097506499072\n",
      "Train Loss 5293: 20.192730073018495\n",
      "Train Loss 5294: 20.192362624336837\n",
      "Train Loss 5295: 20.191995156088105\n",
      "Train Loss 5296: 20.191627699504405\n",
      "Train Loss 5297: 20.191260244957313\n",
      "Train Loss 5298: 20.190892789555257\n",
      "Train Loss 5299: 20.190525345605877\n",
      "Train Loss 5300: 20.190157906599175\n",
      "Train Loss 5301: 20.18979047081993\n",
      "Train Loss 5302: 20.189423046732813\n",
      "Train Loss 5303: 20.18905563433529\n",
      "Train Loss 5304: 20.18868823362483\n",
      "Train Loss 5305: 20.18832084459889\n",
      "Train Loss 5306: 20.187953467254953\n",
      "Train Loss 5307: 20.187586101590465\n",
      "Train Loss 5308: 20.187218750634777\n",
      "Train Loss 5309: 20.186851425907843\n",
      "Train Loss 5310: 20.186484112838233\n",
      "Train Loss 5311: 20.18611681142345\n",
      "Train Loss 5312: 20.18574952166097\n",
      "Train Loss 5313: 20.185382243548283\n",
      "Train Loss 5314: 20.18501497708289\n",
      "Train Loss 5315: 20.18464772226227\n",
      "Train Loss 5316: 20.184280477505126\n",
      "Train Loss 5317: 20.18391324193064\n",
      "Train Loss 5318: 20.18354601799854\n",
      "Train Loss 5319: 20.183178805601308\n",
      "Train Loss 5320: 20.182811602082968\n",
      "Train Loss 5321: 20.18244441020598\n",
      "Train Loss 5322: 20.182077229967824\n",
      "Train Loss 5323: 20.181710061365997\n",
      "Train Loss 5324: 20.18134290360805\n",
      "Train Loss 5325: 20.18097575390567\n",
      "Train Loss 5326: 20.180608615840743\n",
      "Train Loss 5327: 20.180241489410765\n",
      "Train Loss 5328: 20.17987437461322\n",
      "Train Loss 5329: 20.179507271445605\n",
      "Train Loss 5330: 20.179140178714658\n",
      "Train Loss 5331: 20.178773095953115\n",
      "Train Loss 5332: 20.178406024819328\n",
      "Train Loss 5333: 20.178038965310797\n",
      "Train Loss 5334: 20.17767191742502\n",
      "Train Loss 5335: 20.177304881159476\n",
      "Train Loss 5336: 20.17693785651167\n",
      "Train Loss 5337: 20.176570843479105\n",
      "Train Loss 5338: 20.176203842059266\n",
      "Train Loss 5339: 20.175836852249667\n",
      "Train Loss 5340: 20.175469874047792\n",
      "Train Loss 5341: 20.17510290745116\n",
      "Train Loss 5342: 20.174735952457265\n",
      "Train Loss 5343: 20.17436901565423\n",
      "Train Loss 5344: 20.174002098958596\n",
      "Train Loss 5345: 20.173635193334377\n",
      "Train Loss 5346: 20.173268295347604\n",
      "Train Loss 5347: 20.172901408929338\n",
      "Train Loss 5348: 20.172534531118696\n",
      "Train Loss 5349: 20.172167660799303\n",
      "Train Loss 5350: 20.17180080205005\n",
      "Train Loss 5351: 20.171433954868473\n",
      "Train Loss 5352: 20.171067119252108\n",
      "Train Loss 5353: 20.170700295198493\n",
      "Train Loss 5354: 20.17033348246336\n",
      "Train Loss 5355: 20.169966681039504\n",
      "Train Loss 5356: 20.16959989117145\n",
      "Train Loss 5357: 20.169233111881\n",
      "Train Loss 5358: 20.168866341714946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 5359: 20.16849958310233\n",
      "Train Loss 5360: 20.16813283604069\n",
      "Train Loss 5361: 20.167766099902988\n",
      "Train Loss 5362: 20.167399363139943\n",
      "Train Loss 5363: 20.167032635797096\n",
      "Train Loss 5364: 20.166665919996184\n",
      "Train Loss 5365: 20.166299215734757\n",
      "Train Loss 5366: 20.165932523010373\n",
      "Train Loss 5367: 20.165565841820577\n",
      "Train Loss 5368: 20.16519917216293\n",
      "Train Loss 5369: 20.16483251403497\n",
      "Train Loss 5370: 20.16446586743428\n",
      "Train Loss 5371: 20.164099232358392\n",
      "Train Loss 5372: 20.163732608804878\n",
      "Train Loss 5373: 20.163365996771297\n",
      "Train Loss 5374: 20.162999395517907\n",
      "Train Loss 5375: 20.162632807993855\n",
      "Train Loss 5376: 20.162266239162033\n",
      "Train Loss 5377: 20.161899681827904\n",
      "Train Loss 5378: 20.161533135989025\n",
      "Train Loss 5379: 20.161166601642968\n",
      "Train Loss 5380: 20.160800078787283\n",
      "Train Loss 5381: 20.160433567419545\n",
      "Train Loss 5382: 20.160067065139035\n",
      "Train Loss 5383: 20.15970055625755\n",
      "Train Loss 5384: 20.159334057237906\n",
      "Train Loss 5385: 20.158967564818436\n",
      "Train Loss 5386: 20.158601071508496\n",
      "Train Loss 5387: 20.158234569139328\n",
      "Train Loss 5388: 20.157868078258563\n",
      "Train Loss 5389: 20.157501598863792\n",
      "Train Loss 5390: 20.1571351309526\n",
      "Train Loss 5391: 20.156768674522567\n",
      "Train Loss 5392: 20.15640222758498\n",
      "Train Loss 5393: 20.156035780250498\n",
      "Train Loss 5394: 20.155669335232442\n",
      "Train Loss 5395: 20.155302909009947\n",
      "Train Loss 5396: 20.15493649427086\n",
      "Train Loss 5397: 20.154570091012786\n",
      "Train Loss 5398: 20.154203699233335\n",
      "Train Loss 5399: 20.153837318930123\n",
      "Train Loss 5400: 20.15347095010076\n",
      "Train Loss 5401: 20.15310459274285\n",
      "Train Loss 5402: 20.15273824685402\n",
      "Train Loss 5403: 20.152371912431875\n",
      "Train Loss 5404: 20.15200558947404\n",
      "Train Loss 5405: 20.15163927797813\n",
      "Train Loss 5406: 20.151272977941762\n",
      "Train Loss 5407: 20.150906689362554\n",
      "Train Loss 5408: 20.150540412238133\n",
      "Train Loss 5409: 20.15017414656612\n",
      "Train Loss 5410: 20.149807892344135\n",
      "Train Loss 5411: 20.149441649569805\n",
      "Train Loss 5412: 20.149075418240752\n",
      "Train Loss 5413: 20.148709198313735\n",
      "Train Loss 5414: 20.148342985112638\n",
      "Train Loss 5415: 20.14797678335376\n",
      "Train Loss 5416: 20.14761059303472\n",
      "Train Loss 5417: 20.147244412333592\n",
      "Train Loss 5418: 20.14687824033241\n",
      "Train Loss 5419: 20.14651207976977\n",
      "Train Loss 5420: 20.146145930643296\n",
      "Train Loss 5421: 20.145779792950623\n",
      "Train Loss 5422: 20.145413665177806\n",
      "Train Loss 5423: 20.145047546210957\n",
      "Train Loss 5424: 20.144681438675814\n",
      "Train Loss 5425: 20.144315342569996\n",
      "Train Loss 5426: 20.14394925789113\n",
      "Train Loss 5427: 20.143583184636864\n",
      "Train Loss 5428: 20.143217122804817\n",
      "Train Loss 5429: 20.14285107239263\n",
      "Train Loss 5430: 20.142485033397925\n",
      "Train Loss 5431: 20.142119005818355\n",
      "Train Loss 5432: 20.141752989651543\n",
      "Train Loss 5433: 20.14138698489514\n",
      "Train Loss 5434: 20.141020991546775\n",
      "Train Loss 5435: 20.140655009604085\n",
      "Train Loss 5436: 20.140289038310996\n",
      "Train Loss 5437: 20.139923074853048\n",
      "Train Loss 5438: 20.139557122801513\n",
      "Train Loss 5439: 20.139191182154033\n",
      "Train Loss 5440: 20.138825252908248\n",
      "Train Loss 5441: 20.138459335061796\n",
      "Train Loss 5442: 20.138093428612322\n",
      "Train Loss 5443: 20.13772753355747\n",
      "Train Loss 5444: 20.137361639709916\n",
      "Train Loss 5445: 20.13699575707388\n",
      "Train Loss 5446: 20.136629916005393\n",
      "Train Loss 5447: 20.136264086275418\n",
      "Train Loss 5448: 20.135898267881633\n",
      "Train Loss 5449: 20.135532460821675\n",
      "Train Loss 5450: 20.135166664587814\n",
      "Train Loss 5451: 20.134800876533237\n",
      "Train Loss 5452: 20.134435097036622\n",
      "Train Loss 5453: 20.13406932344127\n",
      "Train Loss 5454: 20.133703561186614\n",
      "Train Loss 5455: 20.133337810270305\n",
      "Train Loss 5456: 20.132972068785666\n",
      "Train Loss 5457: 20.132606336126713\n",
      "Train Loss 5458: 20.13224061480463\n",
      "Train Loss 5459: 20.131874904817057\n",
      "Train Loss 5460: 20.131509206161653\n",
      "Train Loss 5461: 20.131143518836083\n",
      "Train Loss 5462: 20.130777842237\n",
      "Train Loss 5463: 20.130412172807297\n",
      "Train Loss 5464: 20.130046512113793\n",
      "Train Loss 5465: 20.129680862739406\n",
      "Train Loss 5466: 20.12931522348627\n",
      "Train Loss 5467: 20.128949594073553\n",
      "Train Loss 5468: 20.12858397597763\n",
      "Train Loss 5469: 20.128218369196173\n",
      "Train Loss 5470: 20.12785277201753\n",
      "Train Loss 5471: 20.127487183331084\n",
      "Train Loss 5472: 20.12712160637375\n",
      "Train Loss 5473: 20.126756041992486\n",
      "Train Loss 5474: 20.126390487930898\n",
      "Train Loss 5475: 20.126024943341594\n",
      "Train Loss 5476: 20.12565941005442\n",
      "Train Loss 5477: 20.12529391954694\n",
      "Train Loss 5478: 20.124928509255902\n",
      "Train Loss 5479: 20.124563110187733\n",
      "Train Loss 5480: 20.12419772234009\n",
      "Train Loss 5481: 20.123832345710618\n",
      "Train Loss 5482: 20.123466977798937\n",
      "Train Loss 5483: 20.12310161826808\n",
      "Train Loss 5484: 20.122736268126772\n",
      "Train Loss 5485: 20.12237092694635\n",
      "Train Loss 5486: 20.12200559698813\n",
      "Train Loss 5487: 20.121640280707286\n",
      "Train Loss 5488: 20.1212749814086\n",
      "Train Loss 5489: 20.120909692284354\n",
      "Train Loss 5490: 20.120544412361323\n",
      "Train Loss 5491: 20.12017914364057\n",
      "Train Loss 5492: 20.11981388592129\n",
      "Train Loss 5493: 20.11944863591633\n",
      "Train Loss 5494: 20.119083397110835\n",
      "Train Loss 5495: 20.118718169502465\n",
      "Train Loss 5496: 20.118352951996698\n",
      "Train Loss 5497: 20.11798774245718\n",
      "Train Loss 5498: 20.117622543205158\n",
      "Train Loss 5499: 20.117257345281914\n",
      "Train Loss 5500: 20.116892115419557\n",
      "Train Loss 5501: 20.116526896767613\n",
      "Train Loss 5502: 20.11616168932376\n",
      "Train Loss 5503: 20.115796493085654\n",
      "Train Loss 5504: 20.11543130805097\n",
      "Train Loss 5505: 20.11506613421738\n",
      "Train Loss 5506: 20.11470097158255\n",
      "Train Loss 5507: 20.114335820144156\n",
      "Train Loss 5508: 20.11397067953088\n",
      "Train Loss 5509: 20.113605548337016\n",
      "Train Loss 5510: 20.11324042832974\n",
      "Train Loss 5511: 20.112875319506735\n",
      "Train Loss 5512: 20.112510221865694\n",
      "Train Loss 5513: 20.1121451354043\n",
      "Train Loss 5514: 20.111780060120253\n",
      "Train Loss 5515: 20.11141499601122\n",
      "Train Loss 5516: 20.111049942156995\n",
      "Train Loss 5517: 20.11068489754054\n",
      "Train Loss 5518: 20.110319864097566\n",
      "Train Loss 5519: 20.10995484182576\n",
      "Train Loss 5520: 20.10958983072282\n",
      "Train Loss 5521: 20.109224830786427\n",
      "Train Loss 5522: 20.10885984157365\n",
      "Train Loss 5523: 20.108494859537277\n",
      "Train Loss 5524: 20.108129891694983\n",
      "Train Loss 5525: 20.107764973386782\n",
      "Train Loss 5526: 20.10740006436921\n",
      "Train Loss 5527: 20.10703516381857\n",
      "Train Loss 5528: 20.10667027045545\n",
      "Train Loss 5529: 20.106305373288283\n",
      "Train Loss 5530: 20.105940487272647\n",
      "Train Loss 5531: 20.10557561240626\n",
      "Train Loss 5532: 20.105210748686815\n",
      "Train Loss 5533: 20.10484589611202\n",
      "Train Loss 5534: 20.104481054679578\n",
      "Train Loss 5535: 20.1041162243872\n",
      "Train Loss 5536: 20.103751405232586\n",
      "Train Loss 5537: 20.103386597213447\n",
      "Train Loss 5538: 20.103021800327493\n",
      "Train Loss 5539: 20.102657014572436\n",
      "Train Loss 5540: 20.102292239945978\n",
      "Train Loss 5541: 20.101927476445844\n",
      "Train Loss 5542: 20.101562724069748\n",
      "Train Loss 5543: 20.10119798281539\n",
      "Train Loss 5544: 20.1008332526805\n",
      "Train Loss 5545: 20.10046853366279\n",
      "Train Loss 5546: 20.10010382575998\n",
      "Train Loss 5547: 20.09973912896979\n",
      "Train Loss 5548: 20.099374443289935\n",
      "Train Loss 5549: 20.09900976815639\n",
      "Train Loss 5550: 20.098645102014824\n",
      "Train Loss 5551: 20.098280446565354\n",
      "Train Loss 5552: 20.09791579889805\n",
      "Train Loss 5553: 20.0975511623416\n",
      "Train Loss 5554: 20.097186536893705\n",
      "Train Loss 5555: 20.096821922552092\n",
      "Train Loss 5556: 20.096457319314478\n",
      "Train Loss 5557: 20.09609271795894\n",
      "Train Loss 5558: 20.095728115749427\n",
      "Train Loss 5559: 20.095363523945913\n",
      "Train Loss 5560: 20.09499893996947\n",
      "Train Loss 5561: 20.09463436707497\n",
      "Train Loss 5562: 20.094269799373276\n",
      "Train Loss 5563: 20.093905243982988\n",
      "Train Loss 5564: 20.093540689523778\n",
      "Train Loss 5565: 20.093176133197556\n",
      "Train Loss 5566: 20.092811587956504\n",
      "Train Loss 5567: 20.092447053798352\n",
      "Train Loss 5568: 20.092082530720848\n",
      "Train Loss 5569: 20.091718018721725\n",
      "Train Loss 5570: 20.09135351779873\n",
      "Train Loss 5571: 20.09098902709625\n",
      "Train Loss 5572: 20.09062454390812\n",
      "Train Loss 5573: 20.09026006965053\n",
      "Train Loss 5574: 20.08989560013501\n",
      "Train Loss 5575: 20.089531129293086\n",
      "Train Loss 5576: 20.089166667317585\n",
      "Train Loss 5577: 20.08880221384886\n",
      "Train Loss 5578: 20.088437771467042\n",
      "Train Loss 5579: 20.088073340169853\n",
      "Train Loss 5580: 20.087708919955034\n",
      "Train Loss 5581: 20.087344510820337\n",
      "Train Loss 5582: 20.086980112763495\n",
      "Train Loss 5583: 20.08661571772922\n",
      "Train Loss 5584: 20.086251321573393\n",
      "Train Loss 5585: 20.085886936504988\n",
      "Train Loss 5586: 20.085522561600463\n",
      "Train Loss 5587: 20.085158192814784\n",
      "Train Loss 5588: 20.08479383511783\n",
      "Train Loss 5589: 20.084429488507332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 5590: 20.084065152981047\n",
      "Train Loss 5591: 20.083700828536717\n",
      "Train Loss 5592: 20.083336515172086\n",
      "Train Loss 5593: 20.0829722128849\n",
      "Train Loss 5594: 20.082607920110185\n",
      "Train Loss 5595: 20.082243622521986\n",
      "Train Loss 5596: 20.08187933602059\n",
      "Train Loss 5597: 20.08151506060377\n",
      "Train Loss 5598: 20.081150796269245\n",
      "Train Loss 5599: 20.080786543014792\n",
      "Train Loss 5600: 20.08042230083815\n",
      "Train Loss 5601: 20.08005806973708\n",
      "Train Loss 5602: 20.079693849411544\n",
      "Train Loss 5603: 20.07932963296396\n",
      "Train Loss 5604: 20.078965420309878\n",
      "Train Loss 5605: 20.078601218693837\n",
      "Train Loss 5606: 20.078237003067745\n",
      "Train Loss 5607: 20.077872778881396\n",
      "Train Loss 5608: 20.077508565804592\n",
      "Train Loss 5609: 20.07714436383508\n",
      "Train Loss 5610: 20.076780172379436\n",
      "Train Loss 5611: 20.076415987097818\n",
      "Train Loss 5612: 20.076051810630744\n",
      "Train Loss 5613: 20.075687635937634\n",
      "Train Loss 5614: 20.07532346696167\n",
      "Train Loss 5615: 20.074959295162355\n",
      "Train Loss 5616: 20.07459513447068\n",
      "Train Loss 5617: 20.074230984884423\n",
      "Train Loss 5618: 20.07386684640136\n",
      "Train Loss 5619: 20.073502714596795\n",
      "Train Loss 5620: 20.07313858137769\n",
      "Train Loss 5621: 20.072774459261094\n",
      "Train Loss 5622: 20.072410348244794\n",
      "Train Loss 5623: 20.072046248326572\n",
      "Train Loss 5624: 20.07168215950421\n",
      "Train Loss 5625: 20.07131808177549\n",
      "Train Loss 5626: 20.070954014431095\n",
      "Train Loss 5627: 20.07058995577631\n",
      "Train Loss 5628: 20.070225898697235\n",
      "Train Loss 5629: 20.069861815000415\n",
      "Train Loss 5630: 20.069497737553284\n",
      "Train Loss 5631: 20.069133671832944\n",
      "Train Loss 5632: 20.068769600732153\n",
      "Train Loss 5633: 20.06840554072744\n",
      "Train Loss 5634: 20.068041491816597\n",
      "Train Loss 5635: 20.067677453997415\n",
      "Train Loss 5636: 20.067313427267703\n",
      "Train Loss 5637: 20.06694941141942\n",
      "Train Loss 5638: 20.066585403296926\n",
      "Train Loss 5639: 20.066221406263285\n",
      "Train Loss 5640: 20.06585742031629\n",
      "Train Loss 5641: 20.065493445453743\n",
      "Train Loss 5642: 20.065129481673438\n",
      "Train Loss 5643: 20.064765528973176\n",
      "Train Loss 5644: 20.06440158735075\n",
      "Train Loss 5645: 20.06403765680397\n",
      "Train Loss 5646: 20.063673737330625\n",
      "Train Loss 5647: 20.06330982892853\n",
      "Train Loss 5648: 20.062945931171182\n",
      "Train Loss 5649: 20.06258203924536\n",
      "Train Loss 5650: 20.06221815752829\n",
      "Train Loss 5651: 20.061854286880365\n",
      "Train Loss 5652: 20.061490427299386\n",
      "Train Loss 5653: 20.061126578783163\n",
      "Train Loss 5654: 20.060762740999518\n",
      "Train Loss 5655: 20.060398910362064\n",
      "Train Loss 5656: 20.06003508779569\n",
      "Train Loss 5657: 20.059671268892192\n",
      "Train Loss 5658: 20.059307461057205\n",
      "Train Loss 5659: 20.05894366428852\n",
      "Train Loss 5660: 20.05857987858396\n",
      "Train Loss 5661: 20.058216100143724\n",
      "Train Loss 5662: 20.05785231235997\n",
      "Train Loss 5663: 20.05748853565686\n",
      "Train Loss 5664: 20.057124768567935\n",
      "Train Loss 5665: 20.05676100998731\n",
      "Train Loss 5666: 20.05639726170642\n",
      "Train Loss 5667: 20.056033521474884\n",
      "Train Loss 5668: 20.055669792324785\n",
      "Train Loss 5669: 20.05530607425393\n",
      "Train Loss 5670: 20.05494236726011\n",
      "Train Loss 5671: 20.054578670210365\n",
      "Train Loss 5672: 20.05421498122278\n",
      "Train Loss 5673: 20.053851303311102\n",
      "Train Loss 5674: 20.053487636473125\n",
      "Train Loss 5675: 20.053123982149053\n",
      "Train Loss 5676: 20.052760341674745\n",
      "Train Loss 5677: 20.05239671224394\n",
      "Train Loss 5678: 20.052033095728547\n",
      "Train Loss 5679: 20.051669596062826\n",
      "Train Loss 5680: 20.05130610735477\n",
      "Train Loss 5681: 20.05094262960216\n",
      "Train Loss 5682: 20.050579162802766\n",
      "Train Loss 5683: 20.050215706954365\n",
      "Train Loss 5684: 20.049852262054735\n",
      "Train Loss 5685: 20.04948882810165\n",
      "Train Loss 5686: 20.049125405092894\n",
      "Train Loss 5687: 20.048761993201037\n",
      "Train Loss 5688: 20.0483985962052\n",
      "Train Loss 5689: 20.04803521012461\n",
      "Train Loss 5690: 20.047671834223664\n",
      "Train Loss 5691: 20.047308464231822\n",
      "Train Loss 5692: 20.04694510515733\n",
      "Train Loss 5693: 20.046581756997984\n",
      "Train Loss 5694: 20.046218419751558\n",
      "Train Loss 5695: 20.04585509341583\n",
      "Train Loss 5696: 20.045491777988588\n",
      "Train Loss 5697: 20.04512847346761\n",
      "Train Loss 5698: 20.044765179850693\n",
      "Train Loss 5699: 20.044401897135607\n",
      "Train Loss 5700: 20.044038625320145\n",
      "Train Loss 5701: 20.0436753644021\n",
      "Train Loss 5702: 20.04331211437926\n",
      "Train Loss 5703: 20.0429488752494\n",
      "Train Loss 5704: 20.04258564701033\n",
      "Train Loss 5705: 20.04222242965983\n",
      "Train Loss 5706: 20.041859223195704\n",
      "Train Loss 5707: 20.041496027615732\n",
      "Train Loss 5708: 20.04113284291772\n",
      "Train Loss 5709: 20.040769669099454\n",
      "Train Loss 5710: 20.04040650615873\n",
      "Train Loss 5711: 20.04004335409336\n",
      "Train Loss 5712: 20.03968021290113\n",
      "Train Loss 5713: 20.039317075890946\n",
      "Train Loss 5714: 20.038953939905547\n",
      "Train Loss 5715: 20.038590814803037\n",
      "Train Loss 5716: 20.03822770058122\n",
      "Train Loss 5717: 20.037864597237903\n",
      "Train Loss 5718: 20.037501504770884\n",
      "Train Loss 5719: 20.037138423177964\n",
      "Train Loss 5720: 20.036775352456942\n",
      "Train Loss 5721: 20.036412292605636\n",
      "Train Loss 5722: 20.036049242422678\n",
      "Train Loss 5723: 20.03568619813645\n",
      "Train Loss 5724: 20.03532316472228\n",
      "Train Loss 5725: 20.03496014217796\n",
      "Train Loss 5726: 20.034597130501304\n",
      "Train Loss 5727: 20.034234129690113\n",
      "Train Loss 5728: 20.033871139742182\n",
      "Train Loss 5729: 20.03350816065533\n",
      "Train Loss 5730: 20.033145191107824\n",
      "Train Loss 5731: 20.0327822300477\n",
      "Train Loss 5732: 20.032419279218303\n",
      "Train Loss 5733: 20.032056336015703\n",
      "Train Loss 5734: 20.031693403674524\n",
      "Train Loss 5735: 20.031330482192576\n",
      "Train Loss 5736: 20.030967570617936\n",
      "Train Loss 5737: 20.030604666626804\n",
      "Train Loss 5738: 20.030241773493927\n",
      "Train Loss 5739: 20.029878890732473\n",
      "Train Loss 5740: 20.029516014878617\n",
      "Train Loss 5741: 20.029153149882394\n",
      "Train Loss 5742: 20.028790295741615\n",
      "Train Loss 5743: 20.028427452454086\n",
      "Train Loss 5744: 20.02806462037355\n",
      "Train Loss 5745: 20.02770180527509\n",
      "Train Loss 5746: 20.02733900101463\n",
      "Train Loss 5747: 20.026976210195503\n",
      "Train Loss 5748: 20.026613448580893\n",
      "Train Loss 5749: 20.02625068345627\n",
      "Train Loss 5750: 20.02588790708502\n",
      "Train Loss 5751: 20.025525141167627\n",
      "Train Loss 5752: 20.025162382376866\n",
      "Train Loss 5753: 20.02479963437182\n",
      "Train Loss 5754: 20.024436895919255\n",
      "Train Loss 5755: 20.02407416408274\n",
      "Train Loss 5756: 20.023711443030486\n",
      "Train Loss 5757: 20.02334873276031\n",
      "Train Loss 5758: 20.022986033270044\n",
      "Train Loss 5759: 20.022623344557502\n",
      "Train Loss 5760: 20.02226066662052\n",
      "Train Loss 5761: 20.021897999456925\n",
      "Train Loss 5762: 20.021535343064535\n",
      "Train Loss 5763: 20.021172697441187\n",
      "Train Loss 5764: 20.02081006258471\n",
      "Train Loss 5765: 20.020447438492933\n",
      "Train Loss 5766: 20.02008482516369\n",
      "Train Loss 5767: 20.019722222594805\n",
      "Train Loss 5768: 20.01935963078412\n",
      "Train Loss 5769: 20.018997049729467\n",
      "Train Loss 5770: 20.018634479428684\n",
      "Train Loss 5771: 20.018271919879606\n",
      "Train Loss 5772: 20.017909371080066\n",
      "Train Loss 5773: 20.01754683302791\n",
      "Train Loss 5774: 20.017184305393663\n",
      "Train Loss 5775: 20.01682178484504\n",
      "Train Loss 5776: 20.016459275041562\n",
      "Train Loss 5777: 20.01609677548092\n",
      "Train Loss 5778: 20.015734282870845\n",
      "Train Loss 5779: 20.015371800998597\n",
      "Train Loss 5780: 20.015009329862043\n",
      "Train Loss 5781: 20.01464686945903\n",
      "Train Loss 5782: 20.014284412782544\n",
      "Train Loss 5783: 20.013921943297408\n",
      "Train Loss 5784: 20.013559484563\n",
      "Train Loss 5785: 20.013197036577186\n",
      "Train Loss 5786: 20.012834599337815\n",
      "Train Loss 5787: 20.01247216166725\n",
      "Train Loss 5788: 20.01210972320756\n",
      "Train Loss 5789: 20.011747295509767\n",
      "Train Loss 5790: 20.011384878571736\n",
      "Train Loss 5791: 20.011022472391318\n",
      "Train Loss 5792: 20.01066007696637\n",
      "Train Loss 5793: 20.010297692294753\n",
      "Train Loss 5794: 20.00993531837434\n",
      "Train Loss 5795: 20.009572952560724\n",
      "Train Loss 5796: 20.009210595840294\n",
      "Train Loss 5797: 20.008848253206594\n",
      "Train Loss 5798: 20.008485924422725\n",
      "Train Loss 5799: 20.008123612906346\n",
      "Train Loss 5800: 20.00776131038039\n",
      "Train Loss 5801: 20.0073990164555\n",
      "Train Loss 5802: 20.0070367332333\n",
      "Train Loss 5803: 20.006674460711654\n",
      "Train Loss 5804: 20.00631219888847\n",
      "Train Loss 5805: 20.005949943395464\n",
      "Train Loss 5806: 20.00558768275144\n",
      "Train Loss 5807: 20.005225432821668\n",
      "Train Loss 5808: 20.004863193604038\n",
      "Train Loss 5809: 20.00450096509642\n",
      "Train Loss 5810: 20.004138747296714\n",
      "Train Loss 5811: 20.003776540202814\n",
      "Train Loss 5812: 20.003414343297315\n",
      "Train Loss 5813: 20.003052152496007\n",
      "Train Loss 5814: 20.002689968022764\n",
      "Train Loss 5815: 20.00232775715165\n",
      "Train Loss 5816: 20.001965556966436\n",
      "Train Loss 5817: 20.001603367465023\n",
      "Train Loss 5818: 20.001241188645288\n",
      "Train Loss 5819: 20.000879020505124\n",
      "Train Loss 5820: 20.000516856474643\n",
      "Train Loss 5821: 20.00015468228969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 5822: 19.99979251563569\n",
      "Train Loss 5823: 19.999430355195884\n",
      "Train Loss 5824: 19.999068205463338\n",
      "Train Loss 5825: 19.998706066435943\n",
      "Train Loss 5826: 19.998343945028854\n",
      "Train Loss 5827: 19.997981851906786\n",
      "Train Loss 5828: 19.997619761266563\n",
      "Train Loss 5829: 19.997257681287724\n",
      "Train Loss 5830: 19.996895611968206\n",
      "Train Loss 5831: 19.996533553305937\n",
      "Train Loss 5832: 19.996171505298847\n",
      "Train Loss 5833: 19.995809467944873\n",
      "Train Loss 5834: 19.995447441241947\n",
      "Train Loss 5835: 19.995085425188005\n",
      "Train Loss 5836: 19.99472341904863\n",
      "Train Loss 5837: 19.994361419395844\n",
      "Train Loss 5838: 19.993999430392734\n",
      "Train Loss 5839: 19.993637452037216\n",
      "Train Loss 5840: 19.993275484327242\n",
      "Train Loss 5841: 19.992913526544807\n",
      "Train Loss 5842: 19.99255157426358\n",
      "Train Loss 5843: 19.992189632626072\n",
      "Train Loss 5844: 19.991827701630204\n",
      "Train Loss 5845: 19.991465781273924\n",
      "Train Loss 5846: 19.991103871555165\n",
      "Train Loss 5847: 19.990741973761402\n",
      "Train Loss 5848: 19.99038008863438\n",
      "Train Loss 5849: 19.990018214131283\n",
      "Train Loss 5850: 19.989656350250037\n",
      "Train Loss 5851: 19.989294496988613\n",
      "Train Loss 5852: 19.988932654344943\n",
      "Train Loss 5853: 19.988570820728974\n",
      "Train Loss 5854: 19.988208994673425\n",
      "Train Loss 5855: 19.987847179237004\n",
      "Train Loss 5856: 19.98748537441767\n",
      "Train Loss 5857: 19.987123580213368\n",
      "Train Loss 5858: 19.98676179662204\n",
      "Train Loss 5859: 19.98640002364164\n",
      "Train Loss 5860: 19.986038261270124\n",
      "Train Loss 5861: 19.98567650950544\n",
      "Train Loss 5862: 19.98531476687162\n",
      "Train Loss 5863: 19.984953030781714\n",
      "Train Loss 5864: 19.98459130530064\n",
      "Train Loss 5865: 19.984229590426352\n",
      "Train Loss 5866: 19.983867886156805\n",
      "Train Loss 5867: 19.983506192489944\n",
      "Train Loss 5868: 19.98314450942372\n",
      "Train Loss 5869: 19.982782836956098\n",
      "Train Loss 5870: 19.982421175085022\n",
      "Train Loss 5871: 19.982059523808452\n",
      "Train Loss 5872: 19.981697883124344\n",
      "Train Loss 5873: 19.981336253030648\n",
      "Train Loss 5874: 19.98097463352533\n",
      "Train Loss 5875: 19.980613024606345\n",
      "Train Loss 5876: 19.980251426271657\n",
      "Train Loss 5877: 19.979889840401547\n",
      "Train Loss 5878: 19.97952826815831\n",
      "Train Loss 5879: 19.97916670569043\n",
      "Train Loss 5880: 19.97880515086151\n",
      "Train Loss 5881: 19.978443604152144\n",
      "Train Loss 5882: 19.978082041560253\n",
      "Train Loss 5883: 19.97772048741095\n",
      "Train Loss 5884: 19.977358943855826\n",
      "Train Loss 5885: 19.976997410892867\n",
      "Train Loss 5886: 19.97663588852003\n",
      "Train Loss 5887: 19.976274376735283\n",
      "Train Loss 5888: 19.97591287013949\n",
      "Train Loss 5889: 19.97555135889595\n",
      "Train Loss 5890: 19.975189858253458\n",
      "Train Loss 5891: 19.974828368209987\n",
      "Train Loss 5892: 19.9744668887635\n",
      "Train Loss 5893: 19.97410541991196\n",
      "Train Loss 5894: 19.973743961653344\n",
      "Train Loss 5895: 19.97338251398562\n",
      "Train Loss 5896: 19.973021076906743\n",
      "Train Loss 5897: 19.972659650414702\n",
      "Train Loss 5898: 19.97229822725236\n",
      "Train Loss 5899: 19.971936790283394\n",
      "Train Loss 5900: 19.971575363926174\n",
      "Train Loss 5901: 19.971213948178672\n",
      "Train Loss 5902: 19.970852543176196\n",
      "Train Loss 5903: 19.970491150577413\n",
      "Train Loss 5904: 19.970129768572807\n",
      "Train Loss 5905: 19.96976839716036\n",
      "Train Loss 5906: 19.96940703633804\n",
      "Train Loss 5907: 19.969045686103826\n",
      "Train Loss 5908: 19.9686843464557\n",
      "Train Loss 5909: 19.96832301739163\n",
      "Train Loss 5910: 19.967961698909612\n",
      "Train Loss 5911: 19.9676003910076\n",
      "Train Loss 5912: 19.9672390936836\n",
      "Train Loss 5913: 19.96687780693557\n",
      "Train Loss 5914: 19.966516528797417\n",
      "Train Loss 5915: 19.966155258591566\n",
      "Train Loss 5916: 19.965793998963104\n",
      "Train Loss 5917: 19.965432749910022\n",
      "Train Loss 5918: 19.96507151143029\n",
      "Train Loss 5919: 19.96471028352188\n",
      "Train Loss 5920: 19.9643490661828\n",
      "Train Loss 5921: 19.96398785941101\n",
      "Train Loss 5922: 19.9636266632045\n",
      "Train Loss 5923: 19.963265477561258\n",
      "Train Loss 5924: 19.962904302479256\n",
      "Train Loss 5925: 19.962543137956498\n",
      "Train Loss 5926: 19.96218198399096\n",
      "Train Loss 5927: 19.961820846250998\n",
      "Train Loss 5928: 19.961459739048934\n",
      "Train Loss 5929: 19.961098642359307\n",
      "Train Loss 5930: 19.960737556180156\n",
      "Train Loss 5931: 19.96037648050951\n",
      "Train Loss 5932: 19.960015415345403\n",
      "Train Loss 5933: 19.959654360685892\n",
      "Train Loss 5934: 19.959293316529\n",
      "Train Loss 5935: 19.958932282872766\n",
      "Train Loss 5936: 19.95857126173651\n",
      "Train Loss 5937: 19.958210249954192\n",
      "Train Loss 5938: 19.957849236072914\n",
      "Train Loss 5939: 19.957488232647464\n",
      "Train Loss 5940: 19.957127239675923\n",
      "Train Loss 5941: 19.956766256397508\n",
      "Train Loss 5942: 19.956405279554712\n",
      "Train Loss 5943: 19.956044313164863\n",
      "Train Loss 5944: 19.955683357226047\n",
      "Train Loss 5945: 19.955322411736326\n",
      "Train Loss 5946: 19.95496147669379\n",
      "Train Loss 5947: 19.954600552006617\n",
      "Train Loss 5948: 19.95423962802677\n",
      "Train Loss 5949: 19.953878704878182\n",
      "Train Loss 5950: 19.9535177921787\n",
      "Train Loss 5951: 19.953156889926426\n",
      "Train Loss 5952: 19.952795998119434\n",
      "Train Loss 5953: 19.952435116755808\n",
      "Train Loss 5954: 19.952074245833646\n",
      "Train Loss 5955: 19.951713385351034\n",
      "Train Loss 5956: 19.951352535306068\n",
      "Train Loss 5957: 19.950991695696832\n",
      "Train Loss 5958: 19.950630866521422\n",
      "Train Loss 5959: 19.950270047777924\n",
      "Train Loss 5960: 19.949909238262965\n",
      "Train Loss 5961: 19.949548444466085\n",
      "Train Loss 5962: 19.94918765922416\n",
      "Train Loss 5963: 19.94882689029716\n",
      "Train Loss 5964: 19.948466148641117\n",
      "Train Loss 5965: 19.94810541734803\n",
      "Train Loss 5966: 19.94774469641609\n",
      "Train Loss 5967: 19.94738398584349\n",
      "Train Loss 5968: 19.94702328562841\n",
      "Train Loss 5969: 19.94666259576904\n",
      "Train Loss 5970: 19.946301916263582\n",
      "Train Loss 5971: 19.945941247110216\n",
      "Train Loss 5972: 19.945580588307134\n",
      "Train Loss 5973: 19.94521993985254\n",
      "Train Loss 5974: 19.944859301323383\n",
      "Train Loss 5975: 19.9444986685982\n",
      "Train Loss 5976: 19.944138044608458\n",
      "Train Loss 5977: 19.943777429241496\n",
      "Train Loss 5978: 19.943416824227693\n",
      "Train Loss 5979: 19.943056229565254\n",
      "Train Loss 5980: 19.94269564525236\n",
      "Train Loss 5981: 19.942335071287197\n",
      "Train Loss 5982: 19.94197450625577\n",
      "Train Loss 5983: 19.941613949071726\n",
      "Train Loss 5984: 19.941253402236647\n",
      "Train Loss 5985: 19.94089286429259\n",
      "Train Loss 5986: 19.940532333995787\n",
      "Train Loss 5987: 19.940171814048654\n",
      "Train Loss 5988: 19.93981130444935\n",
      "Train Loss 5989: 19.93945080499693\n",
      "Train Loss 5990: 19.93909031407329\n",
      "Train Loss 5991: 19.938729833496648\n",
      "Train Loss 5992: 19.938369363265174\n",
      "Train Loss 5993: 19.93800890337706\n",
      "Train Loss 5994: 19.937648452427357\n",
      "Train Loss 5995: 19.93728800878752\n",
      "Train Loss 5996: 19.93692757549058\n",
      "Train Loss 5997: 19.936567152534728\n",
      "Train Loss 5998: 19.936206739918152\n",
      "Train Loss 5999: 19.935846337639028\n",
      "Train Loss 6000: 19.935485945695554\n",
      "Train Loss 6001: 19.935125564085904\n",
      "Train Loss 6002: 19.93476519280828\n",
      "Train Loss 6003: 19.93440483165042\n",
      "Train Loss 6004: 19.93404447692257\n",
      "Train Loss 6005: 19.933684132526757\n",
      "Train Loss 6006: 19.93332379846116\n",
      "Train Loss 6007: 19.93296346744229\n",
      "Train Loss 6008: 19.932603134271954\n",
      "Train Loss 6009: 19.93224280936506\n",
      "Train Loss 6010: 19.9318824916708\n",
      "Train Loss 6011: 19.93152218119861\n",
      "Train Loss 6012: 19.93116188102986\n",
      "Train Loss 6013: 19.930801591162748\n",
      "Train Loss 6014: 19.930441311595487\n",
      "Train Loss 6015: 19.930081042640094\n",
      "Train Loss 6016: 19.929720788973626\n",
      "Train Loss 6017: 19.929360582164723\n",
      "Train Loss 6018: 19.929000385615495\n",
      "Train Loss 6019: 19.92864019932415\n",
      "Train Loss 6020: 19.9282800232889\n",
      "Train Loss 6021: 19.927919856098537\n",
      "Train Loss 6022: 19.9275596949679\n",
      "Train Loss 6023: 19.927199519101396\n",
      "Train Loss 6024: 19.926839336021473\n",
      "Train Loss 6025: 19.926479161739543\n",
      "Train Loss 6026: 19.92611899774423\n",
      "Train Loss 6027: 19.925758844033737\n",
      "Train Loss 6028: 19.925398700606276\n",
      "Train Loss 6029: 19.925038567460057\n",
      "Train Loss 6030: 19.924678444593276\n",
      "Train Loss 6031: 19.924318332004155\n",
      "Train Loss 6032: 19.923958229690896\n",
      "Train Loss 6033: 19.92359813765172\n",
      "Train Loss 6034: 19.923238055012142\n",
      "Train Loss 6035: 19.92287800479116\n",
      "Train Loss 6036: 19.92251801891494\n",
      "Train Loss 6037: 19.92215804326109\n",
      "Train Loss 6038: 19.921798077827795\n",
      "Train Loss 6039: 19.921438122613257\n",
      "Train Loss 6040: 19.92107817761568\n",
      "Train Loss 6041: 19.920718242833264\n",
      "Train Loss 6042: 19.92035831826421\n",
      "Train Loss 6043: 19.919998403906725\n",
      "Train Loss 6044: 19.919638499759007\n",
      "Train Loss 6045: 19.91927860581927\n",
      "Train Loss 6046: 19.91891872208571\n",
      "Train Loss 6047: 19.918558848556536\n",
      "Train Loss 6048: 19.91819898522996\n",
      "Train Loss 6049: 19.917839132104177\n",
      "Train Loss 6050: 19.917479289177408\n",
      "Train Loss 6051: 19.91711945644786\n",
      "Train Loss 6052: 19.91675963391374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 6053: 19.91639982157325\n",
      "Train Loss 6054: 19.916040014502105\n",
      "Train Loss 6055: 19.915680205936127\n",
      "Train Loss 6056: 19.915320407565346\n",
      "Train Loss 6057: 19.914960617677966\n",
      "Train Loss 6058: 19.914600835405587\n",
      "Train Loss 6059: 19.914241063327825\n",
      "Train Loss 6060: 19.913881301442917\n",
      "Train Loss 6061: 19.913521549749074\n",
      "Train Loss 6062: 19.913161808244524\n",
      "Train Loss 6063: 19.912802076927484\n",
      "Train Loss 6064: 19.912442355309256\n",
      "Train Loss 6065: 19.91208263689575\n",
      "Train Loss 6066: 19.91172292866575\n",
      "Train Loss 6067: 19.911363230617486\n",
      "Train Loss 6068: 19.911003542749185\n",
      "Train Loss 6069: 19.910643865059093\n",
      "Train Loss 6070: 19.910284197545444\n",
      "Train Loss 6071: 19.909924540206468\n",
      "Train Loss 6072: 19.909564893040418\n",
      "Train Loss 6073: 19.909205256045524\n",
      "Train Loss 6074: 19.908845629220025\n",
      "Train Loss 6075: 19.908486012562168\n",
      "Train Loss 6076: 19.908126406070185\n",
      "Train Loss 6077: 19.907766809742323\n",
      "Train Loss 6078: 19.907407223576822\n",
      "Train Loss 6079: 19.907047647571932\n",
      "Train Loss 6080: 19.906688081725896\n",
      "Train Loss 6081: 19.906328526036944\n",
      "Train Loss 6082: 19.905968980503346\n",
      "Train Loss 6083: 19.90560944512333\n",
      "Train Loss 6084: 19.90524991989515\n",
      "Train Loss 6085: 19.90489040481705\n",
      "Train Loss 6086: 19.90453089978771\n",
      "Train Loss 6087: 19.90417140055918\n",
      "Train Loss 6088: 19.903811911480496\n",
      "Train Loss 6089: 19.903452432549912\n",
      "Train Loss 6090: 19.90309296376568\n",
      "Train Loss 6091: 19.90273350596784\n",
      "Train Loss 6092: 19.90237406029585\n",
      "Train Loss 6093: 19.902014624759524\n",
      "Train Loss 6094: 19.901655199357133\n",
      "Train Loss 6095: 19.90129578408693\n",
      "Train Loss 6096: 19.90093637894716\n",
      "Train Loss 6097: 19.900576983936094\n",
      "Train Loss 6098: 19.90021760319293\n",
      "Train Loss 6099: 19.899858237210378\n",
      "Train Loss 6100: 19.899498878407236\n",
      "Train Loss 6101: 19.899139526102573\n",
      "Train Loss 6102: 19.898780182079953\n",
      "Train Loss 6103: 19.89842084598082\n",
      "Train Loss 6104: 19.898061519988076\n",
      "Train Loss 6105: 19.897702204099996\n",
      "Train Loss 6106: 19.897342898314864\n",
      "Train Loss 6107: 19.896983602630968\n",
      "Train Loss 6108: 19.89662431704659\n",
      "Train Loss 6109: 19.896265041560007\n",
      "Train Loss 6110: 19.89590577616952\n",
      "Train Loss 6111: 19.895546520873403\n",
      "Train Loss 6112: 19.89518727566995\n",
      "Train Loss 6113: 19.89482804055745\n",
      "Train Loss 6114: 19.89446881423108\n",
      "Train Loss 6115: 19.894109595034973\n",
      "Train Loss 6116: 19.89375038593034\n",
      "Train Loss 6117: 19.89339118691547\n",
      "Train Loss 6118: 19.893031997988654\n",
      "Train Loss 6119: 19.89267281914818\n",
      "Train Loss 6120: 19.892313652145113\n",
      "Train Loss 6121: 19.89195449734843\n",
      "Train Loss 6122: 19.89159535261104\n",
      "Train Loss 6123: 19.891236217931244\n",
      "Train Loss 6124: 19.890877093307324\n",
      "Train Loss 6125: 19.890517975937108\n",
      "Train Loss 6126: 19.890158847639515\n",
      "Train Loss 6127: 19.88979971447569\n",
      "Train Loss 6128: 19.889440591383913\n",
      "Train Loss 6129: 19.889081478362478\n",
      "Train Loss 6130: 19.8887223754097\n",
      "Train Loss 6131: 19.888363282523873\n",
      "Train Loss 6132: 19.8880041997033\n",
      "Train Loss 6133: 19.88764512694629\n",
      "Train Loss 6134: 19.887286063828462\n",
      "Train Loss 6135: 19.886927009910124\n",
      "Train Loss 6136: 19.886567966045718\n",
      "Train Loss 6137: 19.886208932233558\n",
      "Train Loss 6138: 19.885849908471954\n",
      "Train Loss 6139: 19.885490894759222\n",
      "Train Loss 6140: 19.885131891093675\n",
      "Train Loss 6141: 19.884772897473635\n",
      "Train Loss 6142: 19.884413912699927\n",
      "Train Loss 6143: 19.884054935796634\n",
      "Train Loss 6144: 19.883695968938362\n",
      "Train Loss 6145: 19.88333701060741\n",
      "Train Loss 6146: 19.882978059180026\n",
      "Train Loss 6147: 19.882619127543556\n",
      "Train Loss 6148: 19.88226022691787\n",
      "Train Loss 6149: 19.881901332658593\n",
      "Train Loss 6150: 19.88154240977378\n",
      "Train Loss 6151: 19.881183496934053\n",
      "Train Loss 6152: 19.88082459413772\n",
      "Train Loss 6153: 19.880465701383105\n",
      "Train Loss 6154: 19.880106818668516\n",
      "Train Loss 6155: 19.879747945992268\n",
      "Train Loss 6156: 19.87938908335267\n",
      "Train Loss 6157: 19.879030230748057\n",
      "Train Loss 6158: 19.87867138817673\n",
      "Train Loss 6159: 19.878312555250517\n",
      "Train Loss 6160: 19.87795371638561\n",
      "Train Loss 6161: 19.877594884080008\n",
      "Train Loss 6162: 19.87723606181188\n",
      "Train Loss 6163: 19.876877249579557\n",
      "Train Loss 6164: 19.876518447381343\n",
      "Train Loss 6165: 19.87615965420479\n",
      "Train Loss 6166: 19.8758008552279\n",
      "Train Loss 6167: 19.875442066292674\n",
      "Train Loss 6168: 19.875083282438872\n",
      "Train Loss 6169: 19.874724487992477\n",
      "Train Loss 6170: 19.874365700603192\n",
      "Train Loss 6171: 19.87400692327665\n",
      "Train Loss 6172: 19.873648156011168\n",
      "Train Loss 6173: 19.873289398805078\n",
      "Train Loss 6174: 19.872930651656702\n",
      "Train Loss 6175: 19.872571914564364\n",
      "Train Loss 6176: 19.872213187526402\n",
      "Train Loss 6177: 19.871854470541138\n",
      "Train Loss 6178: 19.87149576360691\n",
      "Train Loss 6179: 19.871137066722028\n",
      "Train Loss 6180: 19.870778370027434\n",
      "Train Loss 6181: 19.870419664698552\n",
      "Train Loss 6182: 19.870060959485446\n",
      "Train Loss 6183: 19.86970224754369\n",
      "Train Loss 6184: 19.869343539914112\n",
      "Train Loss 6185: 19.86898484237975\n",
      "Train Loss 6186: 19.86862615493891\n",
      "Train Loss 6187: 19.868267477589924\n",
      "Train Loss 6188: 19.86790881033111\n",
      "Train Loss 6189: 19.867550153160778\n",
      "Train Loss 6190: 19.867191506443664\n",
      "Train Loss 6191: 19.866832873518117\n",
      "Train Loss 6192: 19.866474250654306\n",
      "Train Loss 6193: 19.86611563785056\n",
      "Train Loss 6194: 19.865757033682364\n",
      "Train Loss 6195: 19.865398420766113\n",
      "Train Loss 6196: 19.86503981737181\n",
      "Train Loss 6197: 19.864681237691563\n",
      "Train Loss 6198: 19.864322668450978\n",
      "Train Loss 6199: 19.86396411999577\n",
      "Train Loss 6200: 19.86360558428926\n",
      "Train Loss 6201: 19.86324705860492\n",
      "Train Loss 6202: 19.862888542903868\n",
      "Train Loss 6203: 19.862530032948193\n",
      "Train Loss 6204: 19.862171533015818\n",
      "Train Loss 6205: 19.861813043105062\n",
      "Train Loss 6206: 19.86145456321428\n",
      "Train Loss 6207: 19.861096093341807\n",
      "Train Loss 6208: 19.860737633485968\n",
      "Train Loss 6209: 19.86037918364511\n",
      "Train Loss 6210: 19.860020743817582\n",
      "Train Loss 6211: 19.859662314001707\n",
      "Train Loss 6212: 19.85930389419584\n",
      "Train Loss 6213: 19.858945484398298\n",
      "Train Loss 6214: 19.85858708460745\n",
      "Train Loss 6215: 19.858228694821626\n",
      "Train Loss 6216: 19.857870315039165\n",
      "Train Loss 6217: 19.857511945258423\n",
      "Train Loss 6218: 19.857153585477732\n",
      "Train Loss 6219: 19.856795235695444\n",
      "Train Loss 6220: 19.856436895909894\n",
      "Train Loss 6221: 19.856078566119443\n",
      "Train Loss 6222: 19.855720246322424\n",
      "Train Loss 6223: 19.855361936517195\n",
      "Train Loss 6224: 19.85500363670209\n",
      "Train Loss 6225: 19.854645346875476\n",
      "Train Loss 6226: 19.85428706703568\n",
      "Train Loss 6227: 19.853928797181073\n",
      "Train Loss 6228: 19.853570537309995\n",
      "Train Loss 6229: 19.853212287420796\n",
      "Train Loss 6230: 19.852854047511826\n",
      "Train Loss 6231: 19.852495817581442\n",
      "Train Loss 6232: 19.852137597627994\n",
      "Train Loss 6233: 19.85177938703261\n",
      "Train Loss 6234: 19.851421182031064\n",
      "Train Loss 6235: 19.85106298312708\n",
      "Train Loss 6236: 19.850704788670207\n",
      "Train Loss 6237: 19.85034660420186\n",
      "Train Loss 6238: 19.84998842972039\n",
      "Train Loss 6239: 19.849630265224143\n",
      "Train Loss 6240: 19.84927211071146\n",
      "Train Loss 6241: 19.848913965060575\n",
      "Train Loss 6242: 19.848555801383995\n",
      "Train Loss 6243: 19.848197647688696\n",
      "Train Loss 6244: 19.84783950397302\n",
      "Train Loss 6245: 19.847481370235315\n",
      "Train Loss 6246: 19.847123246473934\n",
      "Train Loss 6247: 19.846765132687228\n",
      "Train Loss 6248: 19.846407028873546\n",
      "Train Loss 6249: 19.84604893503124\n",
      "Train Loss 6250: 19.845690851158672\n",
      "Train Loss 6251: 19.845332777254182\n",
      "Train Loss 6252: 19.844974713316134\n",
      "Train Loss 6253: 19.844616659342872\n",
      "Train Loss 6254: 19.844258615829638\n",
      "Train Loss 6255: 19.84390058334948\n",
      "Train Loss 6256: 19.8435425603142\n",
      "Train Loss 6257: 19.84318454642143\n",
      "Train Loss 6258: 19.84282654247485\n",
      "Train Loss 6259: 19.84246854847283\n",
      "Train Loss 6260: 19.84211056441373\n",
      "Train Loss 6261: 19.84175259029594\n",
      "Train Loss 6262: 19.841394626117822\n",
      "Train Loss 6263: 19.84103667187775\n",
      "Train Loss 6264: 19.8406787224857\n",
      "Train Loss 6265: 19.840320782760113\n",
      "Train Loss 6266: 19.839962905807987\n",
      "Train Loss 6267: 19.839605038754424\n",
      "Train Loss 6268: 19.839247181597795\n",
      "Train Loss 6269: 19.83888933433647\n",
      "Train Loss 6270: 19.838531496968816\n",
      "Train Loss 6271: 19.838173669493205\n",
      "Train Loss 6272: 19.837815851908005\n",
      "Train Loss 6273: 19.837458044211594\n",
      "Train Loss 6274: 19.83710024640235\n",
      "Train Loss 6275: 19.836742458478636\n",
      "Train Loss 6276: 19.83638468043883\n",
      "Train Loss 6277: 19.836026912281305\n",
      "Train Loss 6278: 19.835669154004446\n",
      "Train Loss 6279: 19.835311405606618\n",
      "Train Loss 6280: 19.834953667086204\n",
      "Train Loss 6281: 19.834595938441588\n",
      "Train Loss 6282: 19.83423821967113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 6283: 19.83388051077322\n",
      "Train Loss 6284: 19.833522811746242\n",
      "Train Loss 6285: 19.833165122588568\n",
      "Train Loss 6286: 19.83280744329858\n",
      "Train Loss 6287: 19.832449773874664\n",
      "Train Loss 6288: 19.832092114315202\n",
      "Train Loss 6289: 19.831734464618574\n",
      "Train Loss 6290: 19.831376824783156\n",
      "Train Loss 6291: 19.83101919306426\n",
      "Train Loss 6292: 19.830661566755957\n",
      "Train Loss 6293: 19.83030395030856\n",
      "Train Loss 6294: 19.82994634372046\n",
      "Train Loss 6295: 19.829588746990048\n",
      "Train Loss 6296: 19.829231162794414\n",
      "Train Loss 6297: 19.82887360073102\n",
      "Train Loss 6298: 19.828516048510362\n",
      "Train Loss 6299: 19.82815850613085\n",
      "Train Loss 6300: 19.827800970961068\n",
      "Train Loss 6301: 19.82744342824318\n",
      "Train Loss 6302: 19.827085895365784\n",
      "Train Loss 6303: 19.82672837232726\n",
      "Train Loss 6304: 19.82637085912602\n",
      "Train Loss 6305: 19.826013353510852\n",
      "Train Loss 6306: 19.825655854498567\n",
      "Train Loss 6307: 19.825298365327004\n",
      "Train Loss 6308: 19.824940885994554\n",
      "Train Loss 6309: 19.824583416499618\n",
      "Train Loss 6310: 19.824225956840586\n",
      "Train Loss 6311: 19.823868510212762\n",
      "Train Loss 6312: 19.823511078896992\n",
      "Train Loss 6313: 19.823153657402784\n",
      "Train Loss 6314: 19.8227962473878\n",
      "Train Loss 6315: 19.822438856492408\n",
      "Train Loss 6316: 19.822081469077446\n",
      "Train Loss 6317: 19.821724091483667\n",
      "Train Loss 6318: 19.821366723709488\n",
      "Train Loss 6319: 19.821009365753298\n",
      "Train Loss 6320: 19.82065201761351\n",
      "Train Loss 6321: 19.820294679288544\n",
      "Train Loss 6322: 19.819937348556486\n",
      "Train Loss 6323: 19.81958002209532\n",
      "Train Loss 6324: 19.81922270544434\n",
      "Train Loss 6325: 19.81886539860197\n",
      "Train Loss 6326: 19.818508101566625\n",
      "Train Loss 6327: 19.81815081433671\n",
      "Train Loss 6328: 19.817793536910663\n",
      "Train Loss 6329: 19.817436269286894\n",
      "Train Loss 6330: 19.817079011463825\n",
      "Train Loss 6331: 19.816721762832138\n",
      "Train Loss 6332: 19.816364520932506\n",
      "Train Loss 6333: 19.816007288836012\n",
      "Train Loss 6334: 19.815650066541068\n",
      "Train Loss 6335: 19.815292854958265\n",
      "Train Loss 6336: 19.81493566155413\n",
      "Train Loss 6337: 19.814578477935036\n",
      "Train Loss 6338: 19.81422130382473\n",
      "Train Loss 6339: 19.813864134649457\n",
      "Train Loss 6340: 19.813506975258782\n",
      "Train Loss 6341: 19.813149825651124\n",
      "Train Loss 6342: 19.812792685824906\n",
      "Train Loss 6343: 19.812435555778542\n",
      "Train Loss 6344: 19.812078435510465\n",
      "Train Loss 6345: 19.811721333611793\n",
      "Train Loss 6346: 19.811364270255932\n",
      "Train Loss 6347: 19.811007216637435\n",
      "Train Loss 6348: 19.81065017275474\n",
      "Train Loss 6349: 19.81029313860631\n",
      "Train Loss 6350: 19.80993611419058\n",
      "Train Loss 6351: 19.809579099506017\n",
      "Train Loss 6352: 19.80922209455106\n",
      "Train Loss 6353: 19.80886509932417\n",
      "Train Loss 6354: 19.808508113823798\n",
      "Train Loss 6355: 19.80815113804839\n",
      "Train Loss 6356: 19.807794171996406\n",
      "Train Loss 6357: 19.8074372156663\n",
      "Train Loss 6358: 19.807080266930374\n",
      "Train Loss 6359: 19.80672332514568\n",
      "Train Loss 6360: 19.806366392291988\n",
      "Train Loss 6361: 19.806009465764895\n",
      "Train Loss 6362: 19.805652548962463\n",
      "Train Loss 6363: 19.805295641883138\n",
      "Train Loss 6364: 19.804938744525387\n",
      "Train Loss 6365: 19.804581856887644\n",
      "Train Loss 6366: 19.80422497896837\n",
      "Train Loss 6367: 19.803868110128352\n",
      "Train Loss 6368: 19.803511249496047\n",
      "Train Loss 6369: 19.80315440958158\n",
      "Train Loss 6370: 19.802797579370385\n",
      "Train Loss 6371: 19.802440752578423\n",
      "Train Loss 6372: 19.80208392702509\n",
      "Train Loss 6373: 19.80172711117933\n",
      "Train Loss 6374: 19.80137030503961\n",
      "Train Loss 6375: 19.801013508604406\n",
      "Train Loss 6376: 19.800656721872198\n",
      "Train Loss 6377: 19.800299944841456\n",
      "Train Loss 6378: 19.799943177510656\n",
      "Train Loss 6379: 19.79958641987828\n",
      "Train Loss 6380: 19.799229673915722\n",
      "Train Loss 6381: 19.7988729422605\n",
      "Train Loss 6382: 19.798516220315438\n",
      "Train Loss 6383: 19.79815951858226\n",
      "Train Loss 6384: 19.797802824546167\n",
      "Train Loss 6385: 19.797446138102448\n",
      "Train Loss 6386: 19.79708946133158\n",
      "Train Loss 6387: 19.796732794232053\n",
      "Train Loss 6388: 19.796376136802365\n",
      "Train Loss 6389: 19.796019489041008\n",
      "Train Loss 6390: 19.795662850946492\n",
      "Train Loss 6391: 19.795306222517297\n",
      "Train Loss 6392: 19.794949603751924\n",
      "Train Loss 6393: 19.79459299464887\n",
      "Train Loss 6394: 19.79423639520664\n",
      "Train Loss 6395: 19.793879805423725\n",
      "Train Loss 6396: 19.793523232667553\n",
      "Train Loss 6397: 19.793166699293554\n",
      "Train Loss 6398: 19.79281017555781\n",
      "Train Loss 6399: 19.792453661458836\n",
      "Train Loss 6400: 19.79209715699513\n",
      "Train Loss 6401: 19.791740662165196\n",
      "Train Loss 6402: 19.791384176967547\n",
      "Train Loss 6403: 19.79102770140069\n",
      "Train Loss 6404: 19.790671235463126\n",
      "Train Loss 6405: 19.790314779153384\n",
      "Train Loss 6406: 19.789958332469947\n",
      "Train Loss 6407: 19.78960189541135\n",
      "Train Loss 6408: 19.789245467976087\n",
      "Train Loss 6409: 19.78888905016268\n",
      "Train Loss 6410: 19.788532641969635\n",
      "Train Loss 6411: 19.788176243395466\n",
      "Train Loss 6412: 19.787819854207203\n",
      "Train Loss 6413: 19.78746347353917\n",
      "Train Loss 6414: 19.7871071024815\n",
      "Train Loss 6415: 19.786750741032705\n",
      "Train Loss 6416: 19.786394389191322\n",
      "Train Loss 6417: 19.786038046955863\n",
      "Train Loss 6418: 19.785681714324863\n",
      "Train Loss 6419: 19.785325391296844\n",
      "Train Loss 6420: 19.78496907787034\n",
      "Train Loss 6421: 19.78461277404387\n",
      "Train Loss 6422: 19.78425647981596\n",
      "Train Loss 6423: 19.783900194495068\n",
      "Train Loss 6424: 19.78354391474953\n",
      "Train Loss 6425: 19.783187644605814\n",
      "Train Loss 6426: 19.782831384062437\n",
      "Train Loss 6427: 19.78247513311793\n",
      "Train Loss 6428: 19.782118891419522\n",
      "Train Loss 6429: 19.78176265608061\n",
      "Train Loss 6430: 19.78140643034088\n",
      "Train Loss 6431: 19.781050214198864\n",
      "Train Loss 6432: 19.780694007653082\n",
      "Train Loss 6433: 19.780337810702058\n",
      "Train Loss 6434: 19.779981623344327\n",
      "Train Loss 6435: 19.77962544557841\n",
      "Train Loss 6436: 19.77926927740284\n",
      "Train Loss 6437: 19.778913118816135\n",
      "Train Loss 6438: 19.778556969816837\n",
      "Train Loss 6439: 19.778200830403467\n",
      "Train Loss 6440: 19.77784470057456\n",
      "Train Loss 6441: 19.77748858032864\n",
      "Train Loss 6442: 19.777132469664235\n",
      "Train Loss 6443: 19.77677636857989\n",
      "Train Loss 6444: 19.77642027707413\n",
      "Train Loss 6445: 19.776064195145494\n",
      "Train Loss 6446: 19.7757081227925\n",
      "Train Loss 6447: 19.775352060013702\n",
      "Train Loss 6448: 19.774996031185047\n",
      "Train Loss 6449: 19.774640068173795\n",
      "Train Loss 6450: 19.77428411468709\n",
      "Train Loss 6451: 19.77392817072346\n",
      "Train Loss 6452: 19.773572236281424\n",
      "Train Loss 6453: 19.77321631135951\n",
      "Train Loss 6454: 19.772860395956233\n",
      "Train Loss 6455: 19.772504490070126\n",
      "Train Loss 6456: 19.77214859369972\n",
      "Train Loss 6457: 19.771792706843527\n",
      "Train Loss 6458: 19.77143682950009\n",
      "Train Loss 6459: 19.771080961667927\n",
      "Train Loss 6460: 19.770725103345576\n",
      "Train Loss 6461: 19.770369254531555\n",
      "Train Loss 6462: 19.7700134152244\n",
      "Train Loss 6463: 19.76965758542264\n",
      "Train Loss 6464: 19.769301765124805\n",
      "Train Loss 6465: 19.768945952391896\n",
      "Train Loss 6466: 19.768590147076598\n",
      "Train Loss 6467: 19.76823434932211\n",
      "Train Loss 6468: 19.76787853799862\n",
      "Train Loss 6469: 19.767522736190912\n",
      "Train Loss 6470: 19.767166943897536\n",
      "Train Loss 6471: 19.766811161117023\n",
      "Train Loss 6472: 19.76645538784791\n",
      "Train Loss 6473: 19.766099618060554\n",
      "Train Loss 6474: 19.76574382305094\n",
      "Train Loss 6475: 19.765388037584607\n",
      "Train Loss 6476: 19.765032261660107\n",
      "Train Loss 6477: 19.764676495275967\n",
      "Train Loss 6478: 19.764320738430726\n",
      "Train Loss 6479: 19.76396499100157\n",
      "Train Loss 6480: 19.763609250949784\n",
      "Train Loss 6481: 19.763253520429377\n",
      "Train Loss 6482: 19.76289779943888\n",
      "Train Loss 6483: 19.762542087976843\n",
      "Train Loss 6484: 19.762186385774616\n",
      "Train Loss 6485: 19.76183069114283\n",
      "Train Loss 6486: 19.76147500602177\n",
      "Train Loss 6487: 19.761119330409958\n",
      "Train Loss 6488: 19.760763664305955\n",
      "Train Loss 6489: 19.760408007708307\n",
      "Train Loss 6490: 19.76005235943705\n",
      "Train Loss 6491: 19.75969671816233\n",
      "Train Loss 6492: 19.75934108639364\n",
      "Train Loss 6493: 19.75898546412952\n",
      "Train Loss 6494: 19.75862985136852\n",
      "Train Loss 6495: 19.758274248109185\n",
      "Train Loss 6496: 19.757918654350064\n",
      "Train Loss 6497: 19.7575630700897\n",
      "Train Loss 6498: 19.75720749532664\n",
      "Train Loss 6499: 19.756851929772143\n",
      "Train Loss 6500: 19.75649636932638\n",
      "Train Loss 6501: 19.756140818381088\n",
      "Train Loss 6502: 19.755785276934805\n",
      "Train Loss 6503: 19.755429744986092\n",
      "Train Loss 6504: 19.755074220934834\n",
      "Train Loss 6505: 19.75471870293105\n",
      "Train Loss 6506: 19.754363191282888\n",
      "Train Loss 6507: 19.754007689137374\n",
      "Train Loss 6508: 19.753652196493057\n",
      "Train Loss 6509: 19.753296713348472\n",
      "Train Loss 6510: 19.752941239702167\n",
      "Train Loss 6511: 19.752585775552678\n",
      "Train Loss 6512: 19.752230320898555\n",
      "Train Loss 6513: 19.751874875738338\n",
      "Train Loss 6514: 19.751519440070577\n",
      "Train Loss 6515: 19.751164013893806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 6516: 19.750808593833284\n",
      "Train Loss 6517: 19.750453166382556\n",
      "Train Loss 6518: 19.750097746876087\n",
      "Train Loss 6519: 19.749742318543746\n",
      "Train Loss 6520: 19.749386899695697\n",
      "Train Loss 6521: 19.749031490330484\n",
      "Train Loss 6522: 19.74867609133181\n",
      "Train Loss 6523: 19.748320711182934\n",
      "Train Loss 6524: 19.747965340499892\n",
      "Train Loss 6525: 19.74760997928124\n",
      "Train Loss 6526: 19.747254627525535\n",
      "Train Loss 6527: 19.746899285231358\n",
      "Train Loss 6528: 19.74654395239727\n",
      "Train Loss 6529: 19.74618862902184\n",
      "Train Loss 6530: 19.745833315103635\n",
      "Train Loss 6531: 19.74547801064123\n",
      "Train Loss 6532: 19.745122715633183\n",
      "Train Loss 6533: 19.744767430078078\n",
      "Train Loss 6534: 19.744412157400618\n",
      "Train Loss 6535: 19.744056902342056\n",
      "Train Loss 6536: 19.7437016567182\n",
      "Train Loss 6537: 19.743346420527644\n",
      "Train Loss 6538: 19.742991193768958\n",
      "Train Loss 6539: 19.742635970000688\n",
      "Train Loss 6540: 19.742280746843466\n",
      "Train Loss 6541: 19.74192553240283\n",
      "Train Loss 6542: 19.74157032254984\n",
      "Train Loss 6543: 19.741215122140005\n",
      "Train Loss 6544: 19.740859929722973\n",
      "Train Loss 6545: 19.74050474444136\n",
      "Train Loss 6546: 19.74014956860305\n",
      "Train Loss 6547: 19.73979440220663\n",
      "Train Loss 6548: 19.739439244305704\n",
      "Train Loss 6549: 19.739084093310105\n",
      "Train Loss 6550: 19.738728951756602\n",
      "Train Loss 6551: 19.73837381964377\n",
      "Train Loss 6552: 19.738018696970197\n",
      "Train Loss 6553: 19.73766358373446\n",
      "Train Loss 6554: 19.73730847993514\n",
      "Train Loss 6555: 19.736953385570835\n",
      "Train Loss 6556: 19.736598300640118\n",
      "Train Loss 6557: 19.736243225141575\n",
      "Train Loss 6558: 19.735888159073795\n",
      "Train Loss 6559: 19.73553310243536\n",
      "Train Loss 6560: 19.73517805522487\n",
      "Train Loss 6561: 19.7348230174409\n",
      "Train Loss 6562: 19.734467989082034\n",
      "Train Loss 6563: 19.734112970146874\n",
      "Train Loss 6564: 19.733757960633998\n",
      "Train Loss 6565: 19.733402960542\n",
      "Train Loss 6566: 19.733047969869478\n",
      "Train Loss 6567: 19.732692988615007\n",
      "Train Loss 6568: 19.73233801677719\n",
      "Train Loss 6569: 19.73198305481498\n",
      "Train Loss 6570: 19.731628104822942\n",
      "Train Loss 6571: 19.731273146415223\n",
      "Train Loss 6572: 19.730918174967456\n",
      "Train Loss 6573: 19.730563212966363\n",
      "Train Loss 6574: 19.730208260410524\n",
      "Train Loss 6575: 19.729853317298524\n",
      "Train Loss 6576: 19.72949838362895\n",
      "Train Loss 6577: 19.729143459400383\n",
      "Train Loss 6578: 19.72878854461141\n",
      "Train Loss 6579: 19.728433639260626\n",
      "Train Loss 6580: 19.728078753165097\n",
      "Train Loss 6581: 19.72772389904951\n",
      "Train Loss 6582: 19.72736905433934\n",
      "Train Loss 6583: 19.727014223118875\n",
      "Train Loss 6584: 19.726659407591935\n",
      "Train Loss 6585: 19.726304601452608\n",
      "Train Loss 6586: 19.725949804699514\n",
      "Train Loss 6587: 19.72559501733129\n",
      "Train Loss 6588: 19.725240239346558\n",
      "Train Loss 6589: 19.724885470743942\n",
      "Train Loss 6590: 19.72453071152207\n",
      "Train Loss 6591: 19.72417596167957\n",
      "Train Loss 6592: 19.72382122121507\n",
      "Train Loss 6593: 19.7234664901272\n",
      "Train Loss 6594: 19.72311176452241\n",
      "Train Loss 6595: 19.72275703709282\n",
      "Train Loss 6596: 19.722402319048356\n",
      "Train Loss 6597: 19.722047610387648\n",
      "Train Loss 6598: 19.721692911109322\n",
      "Train Loss 6599: 19.72133822121202\n",
      "Train Loss 6600: 19.72098354069436\n",
      "Train Loss 6601: 19.720628869554982\n",
      "Train Loss 6602: 19.720274207792524\n",
      "Train Loss 6603: 19.71991955540561\n",
      "Train Loss 6604: 19.719564912392883\n",
      "Train Loss 6605: 19.719210278752968\n",
      "Train Loss 6606: 19.71885565448451\n",
      "Train Loss 6607: 19.71850103958614\n",
      "Train Loss 6608: 19.718146434056493\n",
      "Train Loss 6609: 19.717791837894207\n",
      "Train Loss 6610: 19.717437251097916\n",
      "Train Loss 6611: 19.71708267366627\n",
      "Train Loss 6612: 19.716728105597888\n",
      "Train Loss 6613: 19.716373546891422\n",
      "Train Loss 6614: 19.716018996318347\n",
      "Train Loss 6615: 19.715664452028115\n",
      "Train Loss 6616: 19.715309917101997\n",
      "Train Loss 6617: 19.714955391538634\n",
      "Train Loss 6618: 19.71460087390154\n",
      "Train Loss 6619: 19.714246361108238\n",
      "Train Loss 6620: 19.713891857891213\n",
      "Train Loss 6621: 19.713537372494883\n",
      "Train Loss 6622: 19.713182895448742\n",
      "Train Loss 6623: 19.71282842626386\n",
      "Train Loss 6624: 19.71247396643965\n",
      "Train Loss 6625: 19.712119515974734\n",
      "Train Loss 6626: 19.711765074867753\n",
      "Train Loss 6627: 19.711410643117347\n",
      "Train Loss 6628: 19.71105622072215\n",
      "Train Loss 6629: 19.710701807680795\n",
      "Train Loss 6630: 19.71034740399192\n",
      "Train Loss 6631: 19.70999300965417\n",
      "Train Loss 6632: 19.709638624666177\n",
      "Train Loss 6633: 19.70928424902658\n",
      "Train Loss 6634: 19.70892988273402\n",
      "Train Loss 6635: 19.70857552578714\n",
      "Train Loss 6636: 19.70822117818457\n",
      "Train Loss 6637: 19.707866839924964\n",
      "Train Loss 6638: 19.707512509865463\n",
      "Train Loss 6639: 19.707158186801305\n",
      "Train Loss 6640: 19.706803873080677\n",
      "Train Loss 6641: 19.70644956870221\n",
      "Train Loss 6642: 19.70609527366456\n",
      "Train Loss 6643: 19.705740987966355\n",
      "Train Loss 6644: 19.705386711606238\n",
      "Train Loss 6645: 19.705032444582855\n",
      "Train Loss 6646: 19.704678186894856\n",
      "Train Loss 6647: 19.704323934493374\n",
      "Train Loss 6648: 19.70396968427844\n",
      "Train Loss 6649: 19.703615443401556\n",
      "Train Loss 6650: 19.703261211861353\n",
      "Train Loss 6651: 19.702906988186225\n",
      "Train Loss 6652: 19.70255277046389\n",
      "Train Loss 6653: 19.702198562080458\n",
      "Train Loss 6654: 19.701844363034564\n",
      "Train Loss 6655: 19.701490173324864\n",
      "Train Loss 6656: 19.701135991596665\n",
      "Train Loss 6657: 19.700781817079328\n",
      "Train Loss 6658: 19.700427651899833\n",
      "Train Loss 6659: 19.70007349605684\n",
      "Train Loss 6660: 19.69971934954897\n",
      "Train Loss 6661: 19.69936521224229\n",
      "Train Loss 6662: 19.69901108119325\n",
      "Train Loss 6663: 19.69865695948007\n",
      "Train Loss 6664: 19.69830284710139\n",
      "Train Loss 6665: 19.697948744055857\n",
      "Train Loss 6666: 19.697594650342104\n",
      "Train Loss 6667: 19.697240565958772\n",
      "Train Loss 6668: 19.69688649090451\n",
      "Train Loss 6669: 19.696532425177956\n",
      "Train Loss 6670: 19.69617836877776\n",
      "Train Loss 6671: 19.695824320223927\n",
      "Train Loss 6672: 19.69547027905361\n",
      "Train Loss 6673: 19.695116247210485\n",
      "Train Loss 6674: 19.694762224693203\n",
      "Train Loss 6675: 19.694408210067813\n",
      "Train Loss 6676: 19.694054190724703\n",
      "Train Loss 6677: 19.69370017800531\n",
      "Train Loss 6678: 19.693346174143333\n",
      "Train Loss 6679: 19.692992177907573\n",
      "Train Loss 6680: 19.69263818982747\n",
      "Train Loss 6681: 19.692284208965628\n",
      "Train Loss 6682: 19.69193023742155\n",
      "Train Loss 6683: 19.691576275193874\n",
      "Train Loss 6684: 19.69122232228125\n",
      "Train Loss 6685: 19.690868378682314\n",
      "Train Loss 6686: 19.690514444395724\n",
      "Train Loss 6687: 19.690160519420115\n",
      "Train Loss 6688: 19.689806603754135\n",
      "Train Loss 6689: 19.689452697396433\n",
      "Train Loss 6690: 19.689098800345658\n",
      "Train Loss 6691: 19.68874491260045\n",
      "Train Loss 6692: 19.68839103415945\n",
      "Train Loss 6693: 19.688037165021324\n",
      "Train Loss 6694: 19.687683305184716\n",
      "Train Loss 6695: 19.687329454648264\n",
      "Train Loss 6696: 19.68697561366914\n",
      "Train Loss 6697: 19.686621780514646\n",
      "Train Loss 6698: 19.686267943176396\n",
      "Train Loss 6699: 19.685914115130245\n",
      "Train Loss 6700: 19.685560296374856\n",
      "Train Loss 6701: 19.685206486908875\n",
      "Train Loss 6702: 19.684852686730956\n",
      "Train Loss 6703: 19.6844988957045\n",
      "Train Loss 6704: 19.684145110264655\n",
      "Train Loss 6705: 19.683791331837806\n",
      "Train Loss 6706: 19.68343756269806\n",
      "Train Loss 6707: 19.68308380284407\n",
      "Train Loss 6708: 19.682730052274497\n",
      "Train Loss 6709: 19.682376310987976\n",
      "Train Loss 6710: 19.682022578983172\n",
      "Train Loss 6711: 19.681668856258735\n",
      "Train Loss 6712: 19.681315142813315\n",
      "Train Loss 6713: 19.680961438645568\n",
      "Train Loss 6714: 19.68060774375414\n",
      "Train Loss 6715: 19.680254058137702\n",
      "Train Loss 6716: 19.6799003817949\n",
      "Train Loss 6717: 19.67954671472439\n",
      "Train Loss 6718: 19.679193056924824\n",
      "Train Loss 6719: 19.678839408394868\n",
      "Train Loss 6720: 19.67848576913317\n",
      "Train Loss 6721: 19.6781321391384\n",
      "Train Loss 6722: 19.677778518409205\n",
      "Train Loss 6723: 19.677424906944253\n",
      "Train Loss 6724: 19.677071304742196\n",
      "Train Loss 6725: 19.676717710289164\n",
      "Train Loss 6726: 19.676364123348964\n",
      "Train Loss 6727: 19.676010546843088\n",
      "Train Loss 6728: 19.675656979593533\n",
      "Train Loss 6729: 19.675303421598947\n",
      "Train Loss 6730: 19.674949870584896\n",
      "Train Loss 6731: 19.67459632474631\n",
      "Train Loss 6732: 19.67424278815713\n",
      "Train Loss 6733: 19.673889260816022\n",
      "Train Loss 6734: 19.67353574272167\n",
      "Train Loss 6735: 19.67318223387274\n",
      "Train Loss 6736: 19.672828737421632\n",
      "Train Loss 6737: 19.67247526031452\n",
      "Train Loss 6738: 19.67212179243713\n",
      "Train Loss 6739: 19.671768332438344\n",
      "Train Loss 6740: 19.67141487855361\n",
      "Train Loss 6741: 19.671061433902015\n",
      "Train Loss 6742: 19.670707998482243\n",
      "Train Loss 6743: 19.67035457229297\n",
      "Train Loss 6744: 19.67000115617963\n",
      "Train Loss 6745: 19.669647763331398\n",
      "Train Loss 6746: 19.669294379692488\n",
      "Train Loss 6747: 19.6689410052616\n",
      "Train Loss 6748: 19.66858764003744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 6749: 19.668234284018695\n",
      "Train Loss 6750: 19.66788093720407\n",
      "Train Loss 6751: 19.667527599592255\n",
      "Train Loss 6752: 19.66717427118196\n",
      "Train Loss 6753: 19.66682095197187\n",
      "Train Loss 6754: 19.666467641960708\n",
      "Train Loss 6755: 19.666114340276476\n",
      "Train Loss 6756: 19.6657610449403\n",
      "Train Loss 6757: 19.665407758803585\n",
      "Train Loss 6758: 19.66505448186502\n",
      "Train Loss 6759: 19.66470121412331\n",
      "Train Loss 6760: 19.66434795557716\n",
      "Train Loss 6761: 19.663994706225264\n",
      "Train Loss 6762: 19.663641464977776\n",
      "Train Loss 6763: 19.66328823169966\n",
      "Train Loss 6764: 19.66293500761554\n",
      "Train Loss 6765: 19.66258179272412\n",
      "Train Loss 6766: 19.662228584393244\n",
      "Train Loss 6767: 19.6618753738397\n",
      "Train Loss 6768: 19.661522172481295\n",
      "Train Loss 6769: 19.661168980316738\n",
      "Train Loss 6770: 19.66081579734474\n",
      "Train Loss 6771: 19.660462623564\n",
      "Train Loss 6772: 19.660109458973242\n",
      "Train Loss 6773: 19.659756303571168\n",
      "Train Loss 6774: 19.659403157356486\n",
      "Train Loss 6775: 19.65905002032791\n",
      "Train Loss 6776: 19.65869689248416\n",
      "Train Loss 6777: 19.65834377382393\n",
      "Train Loss 6778: 19.657990664345945\n",
      "Train Loss 6779: 19.65763756404892\n",
      "Train Loss 6780: 19.657284471912465\n",
      "Train Loss 6781: 19.6569313859188\n",
      "Train Loss 6782: 19.656578309106155\n",
      "Train Loss 6783: 19.65622524147324\n",
      "Train Loss 6784: 19.65587218301878\n",
      "Train Loss 6785: 19.65551913374148\n",
      "Train Loss 6786: 19.65516609364005\n",
      "Train Loss 6787: 19.65481306271322\n",
      "Train Loss 6788: 19.654460041592348\n",
      "Train Loss 6789: 19.65410703525689\n",
      "Train Loss 6790: 19.65375403808414\n",
      "Train Loss 6791: 19.653401050072826\n",
      "Train Loss 6792: 19.653048071221676\n",
      "Train Loss 6793: 19.6526951015294\n",
      "Train Loss 6794: 19.652342140994747\n",
      "Train Loss 6795: 19.651989189616437\n",
      "Train Loss 6796: 19.651636247393192\n",
      "Train Loss 6797: 19.65128331432375\n",
      "Train Loss 6798: 19.650930390406835\n",
      "Train Loss 6799: 19.650577475641175\n",
      "Train Loss 6800: 19.650224570025507\n",
      "Train Loss 6801: 19.649871673558565\n",
      "Train Loss 6802: 19.649518786239064\n",
      "Train Loss 6803: 19.64916590806575\n",
      "Train Loss 6804: 19.648813034371827\n",
      "Train Loss 6805: 19.64846015437066\n",
      "Train Loss 6806: 19.648107283529047\n",
      "Train Loss 6807: 19.647754421845715\n",
      "Train Loss 6808: 19.647401569319406\n",
      "Train Loss 6809: 19.64704871124603\n",
      "Train Loss 6810: 19.646695832360226\n",
      "Train Loss 6811: 19.646342962638002\n",
      "Train Loss 6812: 19.645990102078088\n",
      "Train Loss 6813: 19.645637250679233\n",
      "Train Loss 6814: 19.645284408440165\n",
      "Train Loss 6815: 19.644931575359635\n",
      "Train Loss 6816: 19.644578751436384\n",
      "Train Loss 6817: 19.644225936669145\n",
      "Train Loss 6818: 19.643873131056658\n",
      "Train Loss 6819: 19.643520334597678\n",
      "Train Loss 6820: 19.643167547290936\n",
      "Train Loss 6821: 19.642814769135178\n",
      "Train Loss 6822: 19.642462000129147\n",
      "Train Loss 6823: 19.642109240271594\n",
      "Train Loss 6824: 19.641756489561253\n",
      "Train Loss 6825: 19.641403747996872\n",
      "Train Loss 6826: 19.6410510155772\n",
      "Train Loss 6827: 19.640698292300982\n",
      "Train Loss 6828: 19.640345578166965\n",
      "Train Loss 6829: 19.639992872016784\n",
      "Train Loss 6830: 19.639640173390983\n",
      "Train Loss 6831: 19.639287483907108\n",
      "Train Loss 6832: 19.63893480356391\n",
      "Train Loss 6833: 19.638582132360117\n",
      "Train Loss 6834: 19.638229470294494\n",
      "Train Loss 6835: 19.637876817365783\n",
      "Train Loss 6836: 19.63752417357272\n",
      "Train Loss 6837: 19.637171538914075\n",
      "Train Loss 6838: 19.63681891338858\n",
      "Train Loss 6839: 19.63646629699499\n",
      "Train Loss 6840: 19.63611368973206\n",
      "Train Loss 6841: 19.635761091598525\n",
      "Train Loss 6842: 19.63540850259315\n",
      "Train Loss 6843: 19.635055922714688\n",
      "Train Loss 6844: 19.634703351961882\n",
      "Train Loss 6845: 19.634350790333485\n",
      "Train Loss 6846: 19.63399823782826\n",
      "Train Loss 6847: 19.633645694444954\n",
      "Train Loss 6848: 19.633293160182312\n",
      "Train Loss 6849: 19.632940635039105\n",
      "Train Loss 6850: 19.63258811901408\n",
      "Train Loss 6851: 19.63223561210599\n",
      "Train Loss 6852: 19.6318831143136\n",
      "Train Loss 6853: 19.631530625635662\n",
      "Train Loss 6854: 19.631178146070926\n",
      "Train Loss 6855: 19.630825675618162\n",
      "Train Loss 6856: 19.630473214276126\n",
      "Train Loss 6857: 19.630120762043568\n",
      "Train Loss 6858: 19.629768318919254\n",
      "Train Loss 6859: 19.629415884901945\n",
      "Train Loss 6860: 19.629063459990398\n",
      "Train Loss 6861: 19.628711044183376\n",
      "Train Loss 6862: 19.628358637479632\n",
      "Train Loss 6863: 19.628006239877944\n",
      "Train Loss 6864: 19.627653851377065\n",
      "Train Loss 6865: 19.627301471975763\n",
      "Train Loss 6866: 19.626949101672793\n",
      "Train Loss 6867: 19.62659674046692\n",
      "Train Loss 6868: 19.626244388356916\n",
      "Train Loss 6869: 19.625892045341544\n",
      "Train Loss 6870: 19.625539711419567\n",
      "Train Loss 6871: 19.625187386589754\n",
      "Train Loss 6872: 19.624835070850867\n",
      "Train Loss 6873: 19.624482764201684\n",
      "Train Loss 6874: 19.624130466640953\n",
      "Train Loss 6875: 19.62377817816746\n",
      "Train Loss 6876: 19.62342589877997\n",
      "Train Loss 6877: 19.623073628477247\n",
      "Train Loss 6878: 19.622721367258066\n",
      "Train Loss 6879: 19.6223691151212\n",
      "Train Loss 6880: 19.62201687206541\n",
      "Train Loss 6881: 19.621664638089474\n",
      "Train Loss 6882: 19.621312413192168\n",
      "Train Loss 6883: 19.620960197372256\n",
      "Train Loss 6884: 19.620607990628514\n",
      "Train Loss 6885: 19.620255792959714\n",
      "Train Loss 6886: 19.61990360436464\n",
      "Train Loss 6887: 19.619551424842054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c8ef8a8db599>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mwriteErrorCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trainloss.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-c8ef8a8db599>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_error_signal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_signal_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrorRate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_lambda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;31m#FeedBack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeedBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_error_signal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_signal_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_lambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Train Loss {0}: {1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-c8ef8a8db599>\u001b[0m in \u001b[0;36mfeedBack\u001b[1;34m(x_train, w1, w2, b1, b2, hidden_layer, output_error_signal, error_signal_hidden, r_lambda, learning_rate)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeedBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_error_signal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_signal_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_lambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0mgw1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_signal_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mgw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_error_signal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mgb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_signal_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.transform import resize\n",
    "\n",
    "def loadData(shape):\n",
    "    x = np.loadtxt(\"train_x.csv\", delimiter=\",\") # load from text \n",
    "    y = np.loadtxt(\"train_y.csv\", delimiter=\",\") \n",
    "    x_test = np.loadtxt(\"test_x.csv\", delimiter=\",\")\n",
    "    x = x.reshape(-1, 64, 64) # reshape \n",
    "    y = y.reshape(-1, 1)\n",
    "    x = preProcess(x,shape)\n",
    "    x = x.reshape((50000, shape**2))\n",
    "    y = y.reshape(50000)\n",
    "    return x,y, x_test\n",
    "\n",
    "def preProcess(x,shape): \n",
    "    resized = np.zeros(shape=(x.shape[0],shape,shape))\n",
    "    for n in range(x.shape[0]):\n",
    "        t = np.array(x[n])\n",
    "        t[t != 255] = 0\n",
    "        t[t == 255] = 1\n",
    "        label_image = label(t)\n",
    "        num = 0\n",
    "        max_region = regionprops(label_image)\n",
    "        for region in regionprops(label_image):\n",
    "            r0,c0,r1,c1 = region.bbox\n",
    "            length = max(abs(r0-r1),abs(c0-c1))\n",
    "            if length > num:\n",
    "                num = length\n",
    "                max_region = region\n",
    "        r0, c0, r1, c1 = max_region['BoundingBox']\n",
    "        cropped = t[min(r0,r1):max(r0,r1), min(c0,c1):max(c0,c1)]\n",
    "        resized[n] = resize(cropped, (shape,shape))\n",
    "        if n%5000 == 0:\n",
    "            print(\"On #: \", n)\n",
    "    return resized\n",
    "\n",
    "def encode_labels(y, outputs):\n",
    "    output = np.zeros(shape = (y.shape[0],outputs))\n",
    "    for i in range(y.shape[0]):\n",
    "        output[i, int(y[i]) ] = 1.0\n",
    "    return output\n",
    "\n",
    "def convertResult(x):\n",
    "    output = np.zeros(shape = (10))\n",
    "    t = np.argmax(x)\n",
    "    output[t] = 1\n",
    "    return output\n",
    "\n",
    "def getData(Classes, shape):\n",
    "    x,y, x_test = loadData(shape)\n",
    "    y = encode_labels(y,Classes)\n",
    "    split = int(x.shape[0] * .8)\n",
    "    x_test = x[split:,:]\n",
    "    y_test = y[split:,:]\n",
    "    x_train = x[:split,:]\n",
    "    y_train = y[:split,:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def writeErrorCSV(name, error):\n",
    "    with open(name, 'w') as a:\n",
    "            for line in error:\n",
    "                temp = np.array2string(line)\n",
    "                a.write(temp)\n",
    "                a.write(\"\\n\")\n",
    "\n",
    "def testResult(x_test, y_test,w1,w2,b1,b2):\n",
    "    active = relu_activation(np.dot(x_test, w1) + b1)\n",
    "    scores = np.dot(active, w2) + b2\n",
    "    probs = softmax(scores) \n",
    "    loss = cross_entropy_softmax_loss_array(probs, y_test)\n",
    "    return loss\n",
    "\n",
    "def initializeValues(inputs, hidden_nodes, outputs):\n",
    "    w1 = np.random.normal(0, 1, [inputs, hidden_nodes])\n",
    "    w2 = np.random.normal(0, 1, [hidden_nodes, outputs]) \n",
    "    b1 = np.zeros((1, hidden_nodes))\n",
    "    b2 = np.zeros((1, outputs))\n",
    "    return w1, w2, b1, b2             \n",
    "\n",
    "def relu_activation(data_array):\n",
    "    return np.maximum(data_array, 0)\n",
    "\n",
    "def softmax(output_array):\n",
    "    logits_exp = np.exp(output_array)\n",
    "    return logits_exp / np.sum(logits_exp, axis = 1, keepdims = True)\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy_softmax_loss_array(softmax_probs_array, y_onehot):\n",
    "    indices = np.argmax(y_onehot, axis = 1).astype(int)\n",
    "    predicted_probability = softmax_probs_array[np.arange(len(softmax_probs_array)), indices]\n",
    "    log_preds = np.log(predicted_probability)\n",
    "    loss = -1.0 * np.sum(log_preds) / len(log_preds)\n",
    "    return loss\n",
    "\n",
    "def regularization_L2_softmax_loss(r_lambda, weight1, weight2):\n",
    "    weight1_loss = 0.5 * r_lambda * np.sum(weight1 * weight1)\n",
    "    weight2_loss = 0.5 * r_lambda * np.sum(weight2 * weight2)\n",
    "    return weight1_loss + weight2_loss\n",
    "\n",
    "def feedForward(w1,w2,b1,b2,x_train):\n",
    "    input_layer = np.dot(x_train, w1)\n",
    "    hidden_layer = relu_activation(input_layer + b1)\n",
    "    output_layer = np.dot(hidden_layer, w2) + b2\n",
    "    output_probs = softmax(output_layer)\n",
    "    return input_layer, hidden_layer, output_layer, output_probs\n",
    "\n",
    "def errorRate(w1, w2, r_lambda,output_probs, y_train, hidden_layer):\n",
    "    loss = cross_entropy_softmax_loss_array(output_probs, y_train)\n",
    "    loss += regularization_L2_softmax_loss(r_lambda, w1, w2)\n",
    "    output_error_signal = (output_probs - y_train) / output_probs.shape[0]\n",
    "    error_signal_hidden = np.dot(output_error_signal, w2.T) \n",
    "    error_signal_hidden[hidden_layer <= 0] = 0\n",
    "    return loss, output_error_signal, error_signal_hidden\n",
    "\n",
    "def feedBack(x_train,w1,w2, b1,b2, hidden_layer, output_error_signal, error_signal_hidden, r_lambda, learning_rate):\n",
    "    gw1 = np.dot(x_train.T, error_signal_hidden)\n",
    "    gw2 = np.dot(hidden_layer.T, output_error_signal)\n",
    "    gb1 = np.sum(error_signal_hidden, axis = 0, keepdims = True)\n",
    "    gb2 = np.sum(output_error_signal, axis = 0, keepdims = True)\n",
    "    gw1 += r_lambda * w1                      \n",
    "    gw2 += r_lambda * w2\n",
    "    w1 -= learning_rate * gw1\n",
    "    w2 -= learning_rate * gw2\n",
    "    b1 -= learning_rate * gb1\n",
    "    b2 -= learning_rate * gb2\n",
    "    return w1, w2, b1, b2\n",
    "\n",
    "def main():\n",
    "    #Constants\n",
    "    nodes = 5\n",
    "    learning_rate = .001\n",
    "    r_lambda = .01\n",
    "    error = []\n",
    "    test = []\n",
    "    epoch = 50000\n",
    "    #Initialization\n",
    "    x_train, y_train, x_test, y_test = getData(10, 28)\n",
    "    w1, w2, b1, b2 = initializeValues(28**2, nodes, 10)\n",
    "    #BackPropagation\n",
    "    for step in range(epoch):\n",
    "        #feedForward\n",
    "        input_layer, hidden_layer, output_layer, output_probs = feedForward(w1,w2,b1,b2,x_train)\n",
    "        #Error Calculation        \n",
    "        loss, output_error_signal, error_signal_hidden = errorRate(w1, w2, r_lambda,output_probs, y_train, hidden_layer)\n",
    "        #FeedBack\n",
    "        w1, w2, b1, b2 = feedBack(x_train,w1,w2, b1,b2, hidden_layer, output_error_signal, error_signal_hidden, r_lambda, learning_rate)\n",
    "        error.append(loss)\n",
    "        print ('Train Loss {0}: {1}'.format(step, loss))\n",
    "        test.append(testResult(x_test, y_test,w1,w2,b1,b2))\n",
    "    writeErrorCSV(\"Trainloss.csv\", error)\n",
    "    writeErrorCSV(\"Testloss.csv\", test)\n",
    "\n",
    "\n",
    "#Initialization\n",
    "x_train, y_train, x_test, y_test = getData(10, 28)\n",
    "nodes = 5\n",
    "learning_rates = [1/i for i in range(1,11)]\n",
    "r_lambda = .01\n",
    "error = []\n",
    "test = []\n",
    "epoch = 10\n",
    "w1, w2, b1, b2 = initializeValues(28**2, nodes, 10)\n",
    "#BackPropagation\n",
    "learning_rate = learning_rates[0]\n",
    "for step in range(epoch):\n",
    "    #feedForward\n",
    "    input_layer, hidden_layer, output_layer, output_probs = feedForward(w1,w2,b1,b2,x_train)\n",
    "    #Error Calculation        \n",
    "    loss, output_error_signal, error_signal_hidden = errorRate(w1, w2, r_lambda,output_probs, y_train, hidden_layer)\n",
    "    #FeedBack\n",
    "    w1, w2, b1, b2 = feedBack(x_train,w1,w2, b1,b2, hidden_layer, output_error_signal, error_signal_hidden, r_lambda, learning_rate)\n",
    "    error.append(loss)\n",
    "    print ('Train Loss {0}: {1}'.format(step, loss))\n",
    "    testError = testResult(x_test, y_test,w1,w2,b1,b2)\n",
    "    print(testError)\n",
    "    test.append(testError)\n",
    "print(test)\n",
    "writeErrorCSV(\"Trainloss.csv\", error)\n",
    "writeErrorCSV(\"Testloss.csv\", test)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "781/781 [==============================] - 653s 836ms/step - loss: 0.4700 - acc: 0.8695 - val_loss: 0.5788 - val_acc: 0.8470\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 625s 800ms/step - loss: 0.3137 - acc: 0.9197 - val_loss: 0.3817 - val_acc: 0.9040\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "\n",
      "Test accuracy:  0.9041\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-24959ef72e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[0mcnn_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "x_train=re_x\n",
    "y_train=y\n",
    "x_test=re_xtest\n",
    "\n",
    "\n",
    "# 80-20 split \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train,y,test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "x_train=re_x\n",
    "y_train=y\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_valid = x_valid.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "\n",
    "\n",
    "number_of_classes = 10\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid, number_of_classes)\n",
    "\n",
    "\n",
    "#plt.imshow(re_x[1])\n",
    "\n",
    "number_of_classes = 10\n",
    "\n",
    "#y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "\n",
    "# =============================================================================\n",
    "# Adding a new part for only the model defination \n",
    "# =============================================================================\n",
    "\n",
    "# Three steps to create a CNN\n",
    "# 1. Convolution\n",
    "# 2. Activation\n",
    "# 3. Pooling\n",
    "# Repeat Steps 1,2,3 for adding more hidden layers\n",
    "\n",
    "# 4. After that make a fully connected network\n",
    "# This fully connected network gives ability to the CNN\n",
    "# to classify the samples\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  Compile\n",
    "# =============================================================================\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# =============================================================================\n",
    "# Imagegenerator \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator(    width_shift_range = 0.075,\n",
    "    height_shift_range = 0.075,\n",
    "    rotation_range = 12,\n",
    "    shear_range = 0.075,\n",
    "    zoom_range = 0.05,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 0)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(x_valid, y_valid, batch_size=64)\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=50000//64, epochs=2, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n",
    "\n",
    "\n",
    "score = model.evaluate(x_valid, y_valid)\n",
    "print()\n",
    "print('Validation accuracy: ', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "# predict + save test data\n",
    "predictions = model.predict_classes(x_test)\n",
    "\n",
    "cnn_results = np.zeros(shape=(10000))\n",
    "count = 0\n",
    "for p in predictions:\n",
    "    if count%1000 == 0:\n",
    "        print(count)\n",
    "    \n",
    "    cnn_results[count] = p\n",
    "    count += 1    \n",
    "    \n",
    "sav(predictions.astype(int),\"cnn_adam.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
